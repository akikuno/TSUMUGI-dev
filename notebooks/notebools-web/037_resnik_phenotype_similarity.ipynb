{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnik Phenotype Similarity (Simplified)\n",
    "\n",
    "このノートブックは、036_resnik_phenotype_similarity.ipynbをシンプルで可読性の高い実装にリファクタリングしたものです。\n",
    "- クラスを使わず関数ベースで実装\n",
    "- 煩雑な部分を簡素化\n",
    "- アノテーション（Genotype, Sex, Life stage）を考慮したResnik similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロジェクトルートに移動\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "while not Path(\"LICENSE\").exists():\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "print(f\"Project root: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MPOオントロジーの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mpo_obo(obo_file_path: str) -> dict:\n",
    "    \"\"\"MPO OBOファイルをパースしてオントロジー構造を返す\"\"\"\n",
    "    \n",
    "    with open(obo_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # ターム情報を格納\n",
    "    terms = {}  # MP_ID -> {name, is_a, ...}\n",
    "    name_to_id = {}  # name -> MP_ID\n",
    "    hierarchy = defaultdict(set)  # child_id -> {parent_ids}\n",
    "    \n",
    "    # Termブロックを分割\n",
    "    term_blocks = content.split(\"[Term]\")[1:]\n",
    "    \n",
    "    for block in term_blocks:\n",
    "        lines = [line.strip() for line in block.strip().split(\"\\n\") if line.strip()]\n",
    "        \n",
    "        term_data = {\"is_a\": [], \"is_obsolete\": False}\n",
    "        \n",
    "        for line in lines:\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            \n",
    "            key, value = line.split(\":\", 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            \n",
    "            if key == \"id\":\n",
    "                term_data[\"id\"] = value\n",
    "            elif key == \"name\":\n",
    "                term_data[\"name\"] = value\n",
    "            elif key == \"is_a\":\n",
    "                parent_id = value.split(\" !\")[0].strip()\n",
    "                term_data[\"is_a\"].append(parent_id)\n",
    "            elif key == \"is_obsolete\":\n",
    "                term_data[\"is_obsolete\"] = value.lower() == \"true\"\n",
    "        \n",
    "        # 有効なタームのみ追加\n",
    "        if \"id\" in term_data and \"name\" in term_data and not term_data[\"is_obsolete\"]:\n",
    "            term_id = term_data[\"id\"]\n",
    "            terms[term_id] = term_data\n",
    "            name_to_id[term_data[\"name\"]] = term_id\n",
    "            \n",
    "            # 階層関係を構築\n",
    "            for parent_id in term_data[\"is_a\"]:\n",
    "                hierarchy[term_id].add(parent_id)\n",
    "    \n",
    "    return {\n",
    "        \"terms\": terms,\n",
    "        \"name_to_id\": name_to_id,\n",
    "        \"hierarchy\": hierarchy\n",
    "    }\n",
    "\n",
    "\n",
    "# MPOオントロジーをパース\n",
    "mpo_data = parse_mpo_obo(\"data/ontology/mp.obo\")\n",
    "print(f\"Parsed {len(mpo_data['terms'])} MP terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 表現型頻度とIC値の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_phenotype_frequencies(symbol_mptermname_path: str) -> dict:\n",
    "    \"\"\"遺伝子→表現型マッピングから各表現型の出現頻度を計算\"\"\"\n",
    "    \n",
    "    with open(symbol_mptermname_path, \"r\") as f:\n",
    "        symbol_mptermname = json.load(f)\n",
    "    \n",
    "    phenotype_counts = Counter()\n",
    "    \n",
    "    for gene, phenotypes in symbol_mptermname.items():\n",
    "        if phenotypes:\n",
    "            for phenotype in phenotypes:\n",
    "                if phenotype.strip():\n",
    "                    phenotype_counts[phenotype.strip()] += 1\n",
    "    \n",
    "    return dict(phenotype_counts)\n",
    "\n",
    "\n",
    "def calculate_information_content(phenotype_frequencies: dict) -> dict:\n",
    "    \"\"\"各表現型のInformation Content (IC)を計算\"\"\"\n",
    "    \n",
    "    total_observations = sum(phenotype_frequencies.values())\n",
    "    ic_scores = {}\n",
    "    \n",
    "    for phenotype, frequency in phenotype_frequencies.items():\n",
    "        probability = frequency / total_observations\n",
    "        ic_score = -math.log(probability) if probability > 0 else 0.0\n",
    "        ic_scores[phenotype] = ic_score\n",
    "    \n",
    "    return ic_scores\n",
    "\n",
    "\n",
    "# 頻度とIC値を計算\n",
    "phenotype_frequencies = calculate_phenotype_frequencies(\"data/annotation/symbol_mptermname.json\")\n",
    "ic_scores = calculate_information_content(phenotype_frequencies)\n",
    "\n",
    "print(f\"Found {len(phenotype_frequencies)} unique phenotypes\")\n",
    "print(f\"Total phenotype observations: {sum(phenotype_frequencies.values())}\")\n",
    "\n",
    "# 頻出表現型TOP5を確認\n",
    "top_phenotypes = sorted(phenotype_frequencies.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"\\nTop 5 most frequent phenotypes:\")\n",
    "for phenotype, count in top_phenotypes:\n",
    "    print(f\"  {count:4d}: {phenotype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 表現型の解析とアノテーション分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_phenotype_annotations(phenotype: str) -> tuple:\n",
    "    \"\"\"表現型文字列から基本項目とアノテーションを分離\"\"\"\n",
    "    \n",
    "    # パターン: \"基本表現型 (アノテーション)\"\n",
    "    pattern = r\"^(.+?)\\s*\\(([^)]+)\\)$\"\n",
    "    match = re.match(pattern, phenotype.strip())\n",
    "    \n",
    "    if not match:\n",
    "        return phenotype.strip(), {}\n",
    "    \n",
    "    base_term = match.group(1).strip()\n",
    "    annotation_str = match.group(2).strip()\n",
    "    \n",
    "    # アノテーションを分類\n",
    "    annotations = {}\n",
    "    \n",
    "    # 複数アノテーションはカンマで区切られる\n",
    "    parts = [part.strip() for part in annotation_str.split(\",\")]\n",
    "    \n",
    "    for part in parts:\n",
    "        if part in [\"Homo\", \"Hetero\", \"Hemi\"]:\n",
    "            annotations[\"genotype\"] = part\n",
    "        elif part in [\"Male\", \"Female\"]:\n",
    "            annotations[\"sex\"] = part\n",
    "        elif part in [\"Early\", \"Late\", \"Embryo\", \"Interval\"]:\n",
    "            annotations[\"life_stage\"] = part\n",
    "    \n",
    "    return base_term, annotations\n",
    "\n",
    "\n",
    "# テスト\n",
    "test_phenotypes = [\n",
    "    \"preweaning lethality, complete penetrance (Homo, Early)\",\n",
    "    \"abnormal skin morphology (Homo, Early)\",\n",
    "    \"hyperactivity (Homo, Early)\"\n",
    "]\n",
    "\n",
    "print(\"表現型解析テスト:\")\n",
    "for phenotype in test_phenotypes:\n",
    "    base, annotations = parse_phenotype_annotations(phenotype)\n",
    "    print(f\"  {phenotype}\")\n",
    "    print(f\"    基本: '{base}'\")\n",
    "    print(f\"    アノテーション: {annotations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. オントロジー階層とLCA計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestors(term_id: str, hierarchy: dict) -> set:\n",
    "    \"\"\"指定されたtermの全祖先を取得\"\"\"\n",
    "    \n",
    "    ancestors = set()\n",
    "    stack = [term_id]\n",
    "    \n",
    "    while stack:\n",
    "        current = stack.pop()\n",
    "        for parent in hierarchy.get(current, set()):\n",
    "            if parent not in ancestors:\n",
    "                ancestors.add(parent)\n",
    "                stack.append(parent)\n",
    "    \n",
    "    return ancestors\n",
    "\n",
    "\n",
    "def calculate_term_depth(term_id: str, hierarchy: dict, depth_cache: dict = None) -> int:\n",
    "    \"\"\"ルートからの深さを計算（キャッシュ付き）\"\"\"\n",
    "    \n",
    "    if depth_cache is None:\n",
    "        depth_cache = {}\n",
    "    \n",
    "    if term_id in depth_cache:\n",
    "        return depth_cache[term_id]\n",
    "    \n",
    "    if not hierarchy.get(term_id):\n",
    "        depth_cache[term_id] = 0\n",
    "        return 0\n",
    "    \n",
    "    max_depth = 0\n",
    "    for parent in hierarchy[term_id]:\n",
    "        parent_depth = calculate_term_depth(parent, hierarchy, depth_cache)\n",
    "        max_depth = max(max_depth, parent_depth + 1)\n",
    "    \n",
    "    depth_cache[term_id] = max_depth\n",
    "    return max_depth\n",
    "\n",
    "\n",
    "def find_lowest_common_ancestor(term_a: str, term_b: str, mpo_data: dict) -> str | None:\n",
    "    \"\"\"2つのtermの最下位共通祖先（LCA）を見つける\"\"\"\n",
    "    \n",
    "    # 名前からIDに変換\n",
    "    id_a = mpo_data[\"name_to_id\"].get(term_a, term_a)\n",
    "    id_b = mpo_data[\"name_to_id\"].get(term_b, term_b)\n",
    "    \n",
    "    if id_a not in mpo_data[\"terms\"] or id_b not in mpo_data[\"terms\"]:\n",
    "        return None\n",
    "    \n",
    "    # 両方の祖先を取得\n",
    "    ancestors_a = get_ancestors(id_a, mpo_data[\"hierarchy\"])\n",
    "    ancestors_a.add(id_a)\n",
    "    \n",
    "    ancestors_b = get_ancestors(id_b, mpo_data[\"hierarchy\"])\n",
    "    ancestors_b.add(id_b)\n",
    "    \n",
    "    # 共通祖先\n",
    "    common_ancestors = ancestors_a & ancestors_b\n",
    "    \n",
    "    if not common_ancestors:\n",
    "        return None\n",
    "    \n",
    "    # 最も深い（具体的な）共通祖先を選択\n",
    "    depth_cache = {}\n",
    "    lca = max(common_ancestors, key=lambda x: calculate_term_depth(x, mpo_data[\"hierarchy\"], depth_cache))\n",
    "    \n",
    "    return lca\n",
    "\n",
    "\n",
    "# テスト\n",
    "print(\"LCA計算テスト:\")\n",
    "test_pairs = [\n",
    "    (\"cellular phenotype\", \"abnormal cell morphology\"),\n",
    "    (\"abnormal heart morphology\", \"abnormal blood vessel morphology\")\n",
    "]\n",
    "\n",
    "for term_a, term_b in test_pairs:\n",
    "    lca_id = find_lowest_common_ancestor(term_a, term_b, mpo_data)\n",
    "    if lca_id:\n",
    "        lca_name = mpo_data[\"terms\"][lca_id][\"name\"]\n",
    "        print(f\"  '{term_a}' & '{term_b}' -> LCA: {lca_name}\")\n",
    "    else:\n",
    "        print(f\"  '{term_a}' & '{term_b}' -> LCA: None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resnik Similarity計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_phenotype_ic(base_phenotype: str, ic_scores: dict) -> float:\n",
    "    \"\"\"基本表現型の最大IC値を取得\"\"\"\n",
    "    \n",
    "    max_ic = 0.0\n",
    "    \n",
    "    for phenotype, ic in ic_scores.items():\n",
    "        # アノテーション部分を除いた基本表現型を抽出\n",
    "        current_base, _ = parse_phenotype_annotations(phenotype)\n",
    "        if current_base == base_phenotype:\n",
    "            max_ic = max(max_ic, ic)\n",
    "    \n",
    "    return max_ic\n",
    "\n",
    "\n",
    "def calculate_string_similarity(term_a: str, term_b: str) -> float:\n",
    "    \"\"\"文字列類似度による補完計算\"\"\"\n",
    "    \n",
    "    # 共通の\"abnormal XXX morphology\"パターンチェック\n",
    "    pattern_morphology = r'^abnormal\\s+\\w+\\s+morphology$'\n",
    "    if (re.match(pattern_morphology, term_a) and \n",
    "        re.match(pattern_morphology, term_b)):\n",
    "        return 1.0  # 共通パターンには中程度の類似度\n",
    "    \n",
    "    # 単語レベルのJaccard類似度\n",
    "    words_a = set(term_a.lower().split())\n",
    "    words_b = set(term_b.lower().split())\n",
    "    \n",
    "    if not words_a or not words_b:\n",
    "        return 0.0\n",
    "    \n",
    "    common_words = words_a & words_b\n",
    "    total_words = words_a | words_b\n",
    "    \n",
    "    jaccard_sim = len(common_words) / len(total_words)\n",
    "    \n",
    "    # 重要な単語にボーナス\n",
    "    important_words = {'abnormal', 'morphology', 'increased', 'decreased'}\n",
    "    important_common = common_words & important_words\n",
    "    \n",
    "    if important_common:\n",
    "        bonus = len(important_common) * 0.3\n",
    "        jaccard_sim += bonus\n",
    "    \n",
    "    return min(jaccard_sim, 3.0)  # 最大3.0に制限\n",
    "\n",
    "\n",
    "def calculate_base_resnik_similarity(term_a: str, term_b: str, mpo_data: dict, ic_scores: dict) -> float:\n",
    "    \"\"\"基本表現型のResnik similarity計算\"\"\"\n",
    "    \n",
    "    # 同一項目の場合\n",
    "    if term_a == term_b:\n",
    "        return get_base_phenotype_ic(term_a, ic_scores)\n",
    "    \n",
    "    # MPOオントロジーでLCAを探す\n",
    "    lca_id = find_lowest_common_ancestor(term_a, term_b, mpo_data)\n",
    "\n",
    "    ontology_similarity = 0.0    \n",
    "    if lca_id is not None:\n",
    "        lca_name = mpo_data[\"terms\"][lca_id][\"name\"]\n",
    "        ontology_similarity = get_base_phenotype_ic(lca_name, ic_scores)\n",
    "    \n",
    "    # 文字列類似度による補完\n",
    "    string_similarity = calculate_string_similarity(term_a, term_b)\n",
    "    \n",
    "    # より高い類似度を採用\n",
    "    return max(ontology_similarity, string_similarity)\n",
    "\n",
    "\n",
    "# テスト\n",
    "print(\"基本Resnik similarity テスト:\")\n",
    "test_pairs = [\n",
    "    (\"preweaning lethality, complete penetrance\", \"abnormal heart morphology\"),\n",
    "    (\"abnormal skin morphology\", \"abnormal kidney morphology\"),\n",
    "    (\"abnormal spleen morphology\", \"abnormal kidney morphology\"),\n",
    "    (\"abnormal heart morphology\", \"abnormal blood vessel morphology\")\n",
    "\n",
    "]\n",
    "\n",
    "for term_a, term_b in test_pairs:\n",
    "    similarity = calculate_base_resnik_similarity(term_a, term_b, mpo_data, ic_scores)\n",
    "    print(f\"  '{term_a}' & '{term_b}' -> {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_id = find_lowest_common_ancestor(term_a, term_b, mpo_data)\n",
    "print(lca_id)\n",
    "ontology_similarity = 0.0    \n",
    "if lca_id is not None:\n",
    "    lca_name = mpo_data[\"terms\"][lca_id][\"name\"]\n",
    "    ontology_similarity = get_base_phenotype_ic(lca_name, ic_scores)\n",
    "print(lca_name)\n",
    "print(ontology_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. アノテーション類似度計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_partial_similarity(annotation_type: str, value_a: str, value_b: str) -> float:\n",
    "    \"\"\"アノテーション値間の部分的類似度\"\"\"\n",
    "    \n",
    "    if annotation_type == \"genotype\":\n",
    "        genotype_similarity = {\n",
    "            (\"Hetero\", \"Homo\"): 0.1,\n",
    "            (\"Hemi\", \"Homo\"): 0.05,\n",
    "            (\"Hemi\", \"Hetero\"): 0.05,\n",
    "        }\n",
    "        key = tuple(sorted([value_a, value_b]))\n",
    "        return genotype_similarity.get(key, 0.0)\n",
    "    \n",
    "    elif annotation_type == \"sex\":\n",
    "        return 0.0  # Male vs Female: 完全に異なる\n",
    "    \n",
    "    elif annotation_type == \"life_stage\":\n",
    "        life_stage_similarity = {\n",
    "            (\"Early\", \"Interval\"): 0.1,\n",
    "            (\"Early\", \"Late\"): 0.02,\n",
    "            (\"Early\", \"Embryo\"): 0.02,\n",
    "            (\"Interval\", \"Late\"): 0.2,\n",
    "            (\"Interval\", \"Embryo\"): 0.02,\n",
    "            (\"Late\", \"Embryo\"): 0.02,\n",
    "        }\n",
    "        key = tuple(sorted([value_a, value_b]))\n",
    "        return life_stage_similarity.get(key, 0.0)\n",
    "    \n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def calculate_annotation_similarity(annotations_a: dict, annotations_b: dict) -> float:\n",
    "    \"\"\"アノテーション間の類似度計算\"\"\"\n",
    "    \n",
    "    # 各アノテーションタイプの重み\n",
    "    annotation_weights = {\"genotype\": 0.5, \"sex\": 0.3, \"life_stage\": 0.2}\n",
    "    \n",
    "    total_weight = 0\n",
    "    similarity_sum = 0\n",
    "    \n",
    "    for annotation_type in [\"genotype\", \"sex\", \"life_stage\"]:\n",
    "        if annotation_type in annotations_a or annotation_type in annotations_b:\n",
    "            weight = annotation_weights[annotation_type]\n",
    "            total_weight += weight\n",
    "            \n",
    "            if annotation_type in annotations_a and annotation_type in annotations_b:\n",
    "                # 両方にアノテーション存在\n",
    "                if annotations_a[annotation_type] == annotations_b[annotation_type]:\n",
    "                    similarity_sum += weight * 1.0  # 完全一致\n",
    "                else:\n",
    "                    # 部分的類似度\n",
    "                    partial_sim = get_annotation_partial_similarity(\n",
    "                        annotation_type,\n",
    "                        annotations_a[annotation_type],\n",
    "                        annotations_b[annotation_type]\n",
    "                    )\n",
    "                    similarity_sum += weight * partial_sim\n",
    "            else:\n",
    "                # 片方のみにアノテーション存在 - 低いペナルティ\n",
    "                similarity_sum += weight * 0.01\n",
    "    \n",
    "    if total_weight == 0:\n",
    "        return 1.0  # 両方ともアノテーションなし\n",
    "    \n",
    "    return similarity_sum / total_weight\n",
    "\n",
    "\n",
    "# テスト\n",
    "print(\"アノテーション類似度テスト:\")\n",
    "test_cases = [\n",
    "    ({\"genotype\": \"Homo\", \"life_stage\": \"Early\"}, {\"genotype\": \"Homo\", \"life_stage\": \"Early\"}),\n",
    "    ({\"genotype\": \"Homo\", \"life_stage\": \"Early\"}, {\"genotype\": \"Hetero\", \"life_stage\": \"Early\"}),\n",
    "    ({\"genotype\": \"Homo\", \"sex\": \"Male\"}, {\"genotype\": \"Homo\", \"sex\": \"Female\"})\n",
    "]\n",
    "\n",
    "for ann_a, ann_b in test_cases:\n",
    "    similarity = calculate_annotation_similarity(ann_a, ann_b)\n",
    "    print(f\"  {ann_a} & {ann_b} -> {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 統合Resnik Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_resnik_similarity(phenotype_a: str, phenotype_b: str, mpo_data: dict, ic_scores: dict) -> float:\n",
    "    \"\"\"アノテーション考慮型Resnik similarity計算\"\"\"\n",
    "    \n",
    "    # 完全一致の場合\n",
    "    if phenotype_a == phenotype_b:\n",
    "        return ic_scores.get(phenotype_a, 0.0)\n",
    "    \n",
    "    # 表現型とアノテーションを分離\n",
    "    base_a, annotations_a = parse_phenotype_annotations(phenotype_a)\n",
    "    base_b, annotations_b = parse_phenotype_annotations(phenotype_b)\n",
    "    \n",
    "    # 基本表現型のResnik similarity\n",
    "    base_similarity = calculate_base_resnik_similarity(base_a, base_b, mpo_data, ic_scores)\n",
    "    \n",
    "    # アノテーション類似度\n",
    "    annotation_similarity = calculate_annotation_similarity(annotations_a, annotations_b)\n",
    "    \n",
    "    # 統合類似度計算（基本表現型を重視）\n",
    "    if base_similarity < 0.01:\n",
    "        # 基本表現型がほぼ異なる場合、アノテーションをほぼ無視\n",
    "        combined_similarity = 0.999 * base_similarity + 0.001 * annotation_similarity\n",
    "    elif base_similarity < 0.1:\n",
    "        # 基本表現型が少し類似する場合\n",
    "        combined_similarity = 0.99 * base_similarity + 0.01 * annotation_similarity\n",
    "    else:\n",
    "        # 通常の重み\n",
    "        combined_similarity = 0.98 * base_similarity + 0.02 * annotation_similarity\n",
    "    \n",
    "    return combined_similarity\n",
    "\n",
    "\n",
    "# テスト\n",
    "print(\"統合Resnik similarity テスト:\")\n",
    "test_phenotype_pairs = [\n",
    "    (\"preweaning lethality, complete penetrance (Homo, Early)\", \"abnormal heart morphology (Homo, Early)\"),\n",
    "    (\"abnormal skin morphology (Homo, Early)\", \"abnormal kidney morphology (Homo, Early)\"),\n",
    "    (\"abnormal spleen morphology (Homo, Early)\", \"abnormal kidney morphology (Homo, Early)\"),\n",
    "    (\"hyperactivity (Homo, Early)\", \"hyperactivity (Hetero, Early)\")  # 同じ基本表現型、異なるgenotype\n",
    "]\n",
    "\n",
    "print(\"\\n結果:\")\n",
    "for phenotype_a, phenotype_b in test_phenotype_pairs:\n",
    "    similarity = calculate_resnik_similarity(phenotype_a, phenotype_b, mpo_data, ic_scores)\n",
    "    \n",
    "    # 詳細情報も表示\n",
    "    base_a, ann_a = parse_phenotype_annotations(phenotype_a)\n",
    "    base_b, ann_b = parse_phenotype_annotations(phenotype_b)\n",
    "    base_sim = calculate_base_resnik_similarity(base_a, base_b, mpo_data, ic_scores)\n",
    "    ann_sim = calculate_annotation_similarity(ann_a, ann_b)\n",
    "    \n",
    "    print(f\"\\n📍 類似度: {similarity:.4f}\")\n",
    "    print(f\"   {phenotype_a}\")\n",
    "    print(f\"   vs\")\n",
    "    print(f\"   {phenotype_b}\")\n",
    "    print(f\"   基本類似度: {base_sim:.4f}, アノテーション類似度: {ann_sim:.4f}\")\n",
    "    \n",
    "    # 頻度情報\n",
    "    freq_a = phenotype_frequencies.get(phenotype_a, 0)\n",
    "    freq_b = phenotype_frequencies.get(phenotype_b, 0)\n",
    "    print(f\"   頻度: {freq_a} vs {freq_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. JaccardとResnikの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(phenotype_a: str, phenotype_b: str) -> float:\n",
    "    \"\"\"従来のJaccard similarity（参考用）\"\"\"\n",
    "    return 1.0 if phenotype_a == phenotype_b else 0.0\n",
    "\n",
    "\n",
    "print(\"Jaccard vs Resnik Similarity 比較\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_pairs = [\n",
    "    (\"preweaning lethality, complete penetrance (Homo, Early)\", \"abnormal heart morphology (Homo, Early)\"),\n",
    "    (\"abnormal skin morphology (Homo, Early)\", \"abnormal kidney morphology (Homo, Early)\"),\n",
    "    (\"abnormal spleen morphology (Homo, Early)\", \"abnormal kidney morphology (Homo, Early)\"),\n",
    "    (\"hyperactivity (Homo, Early)\", \"hyperactivity (Homo, Early)\")  # 同一表現型\n",
    "]\n",
    "\n",
    "for phenotype_a, phenotype_b in comparison_pairs:\n",
    "    jaccard_sim = jaccard_similarity(phenotype_a, phenotype_b)\n",
    "    resnik_sim = calculate_resnik_similarity(phenotype_a, phenotype_b, mpo_data, ic_scores)\n",
    "    \n",
    "    print(f\"\\n📍 {phenotype_a}\")\n",
    "    print(f\"   vs\")\n",
    "    print(f\"   {phenotype_b}\")\n",
    "    print(f\"   📊 Jaccard: {jaccard_sim:.4f}  |  Resnik: {resnik_sim:.4f}\")\n",
    "    \n",
    "    # 改善効果を評価\n",
    "    if jaccard_sim == 0.0 and resnik_sim < 0.1:\n",
    "        print(f\"   ✅ 改善成功: 非関連表現型の類似度が適切に低い\")\n",
    "    elif jaccard_sim == 0.0 and resnik_sim >= 0.1:\n",
    "        print(f\"   🔍 注目: 関連性のある表現型として検出\")\n",
    "    elif jaccard_sim == 1.0:\n",
    "        print(f\"   🎯 同一表現型: IC値を活用\")\n",
    "\n",
    "print(f\"\\n🎯 Resnik Similarity の利点:\")\n",
    "print(f\"   1. 頻出表現型（preweaning lethality等）の偏りを軽減\")\n",
    "print(f\"   2. オントロジー階層を考慮した意味的類似度\")\n",
    "print(f\"   3. アノテーション情報を適切に考慮\")\n",
    "print(f\"   4. 関連性のある表現型間で適切な類似度を提供\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 結果の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を保存\n",
    "output_dir = Path(\"data/resnik_similarity_simplified\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 1. MPOデータ保存\n",
    "with open(output_dir / \"mpo_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mpo_data, f)\n",
    "\n",
    "# 2. IC scores保存\n",
    "with open(output_dir / \"ic_scores.json\", \"w\") as f:\n",
    "    json.dump(ic_scores, f, indent=2)\n",
    "\n",
    "# 3. 頻度データ保存\n",
    "with open(output_dir / \"phenotype_frequencies.json\", \"w\") as f:\n",
    "    json.dump(phenotype_frequencies, f, indent=2)\n",
    "\n",
    "# 4. 使いやすい関数群をまとめた辞書を保存\n",
    "similarity_functions = {\n",
    "    \"calculate_resnik_similarity\": calculate_resnik_similarity,\n",
    "    \"parse_phenotype_annotations\": parse_phenotype_annotations,\n",
    "    \"calculate_base_resnik_similarity\": calculate_base_resnik_similarity,\n",
    "    \"calculate_annotation_similarity\": calculate_annotation_similarity\n",
    "}\n",
    "\n",
    "print(f\"Simplified Resnik similarity data saved to {output_dir}/\")\n",
    "print(f\"Files saved:\")\n",
    "for file_path in output_dir.glob(\"*\"):\n",
    "    print(f\"  - {file_path.name}\")\n",
    "\n",
    "print(f\"\\n✅ 簡略化実装完了!\")\n",
    "print(f\"主要関数:\")\n",
    "print(f\"  - calculate_resnik_similarity(): メイン関数\")\n",
    "print(f\"  - parse_phenotype_annotations(): 表現型解析\")\n",
    "print(f\"  - calculate_base_resnik_similarity(): 基本類似度\")\n",
    "print(f\"  - calculate_annotation_similarity(): アノテーション類似度\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tsumugi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
