{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnik Phenotype Similarity (Simplified)\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€036_resnik_phenotype_similarity.ipynbã‚’ã‚·ãƒ³ãƒ—ãƒ«ã§å¯èª­æ€§ã®é«˜ã„å®Ÿè£…ã«ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã—ãŸã‚‚ã®ã§ã™ã€‚\n",
    "- ã‚¯ãƒ©ã‚¹ã‚’ä½¿ã‚ãšé–¢æ•°ãƒ™ãƒ¼ã‚¹ã§å®Ÿè£…\n",
    "- ç…©é›‘ãªéƒ¨åˆ†ã‚’ç°¡ç´ åŒ–\n",
    "- ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆGenotype, Sex, Life stageï¼‰ã‚’è€ƒæ…®ã—ãŸResnik similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«ç§»å‹•\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "while not Path(\"LICENSE\").exists():\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "print(f\"Project root: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MPOã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mpo_obo(obo_file_path: str) -> dict:\n",
    "    \"\"\"MPO OBOãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼æ§‹é€ ã‚’è¿”ã™\"\"\"\n",
    "    \n",
    "    with open(obo_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # ã‚¿ãƒ¼ãƒ æƒ…å ±ã‚’æ ¼ç´\n",
    "    terms = {}  # MP_ID -> {name, is_a, ...}\n",
    "    name_to_id = {}  # name -> MP_ID\n",
    "    hierarchy = defaultdict(set)  # child_id -> {parent_ids}\n",
    "    \n",
    "    # Termãƒ–ãƒ­ãƒƒã‚¯ã‚’åˆ†å‰²\n",
    "    term_blocks = content.split(\"[Term]\")[1:]\n",
    "    \n",
    "    for block in term_blocks:\n",
    "        lines = [line.strip() for line in block.strip().split(\"\\n\") if line.strip()]\n",
    "        \n",
    "        term_data = {\"is_a\": [], \"is_obsolete\": False}\n",
    "        \n",
    "        for line in lines:\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            \n",
    "            key, value = line.split(\":\", 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            \n",
    "            if key == \"id\":\n",
    "                term_data[\"id\"] = value\n",
    "            elif key == \"name\":\n",
    "                term_data[\"name\"] = value\n",
    "            elif key == \"is_a\":\n",
    "                parent_id = value.split(\" !\")[0].strip()\n",
    "                term_data[\"is_a\"].append(parent_id)\n",
    "            elif key == \"is_obsolete\":\n",
    "                term_data[\"is_obsolete\"] = value.lower() == \"true\"\n",
    "        \n",
    "        # æœ‰åŠ¹ãªã‚¿ãƒ¼ãƒ ã®ã¿è¿½åŠ \n",
    "        if \"id\" in term_data and \"name\" in term_data and not term_data[\"is_obsolete\"]:\n",
    "            term_id = term_data[\"id\"]\n",
    "            terms[term_id] = term_data\n",
    "            name_to_id[term_data[\"name\"]] = term_id\n",
    "            \n",
    "            # éšå±¤é–¢ä¿‚ã‚’æ§‹ç¯‰\n",
    "            for parent_id in term_data[\"is_a\"]:\n",
    "                hierarchy[term_id].add(parent_id)\n",
    "    \n",
    "    return {\n",
    "        \"terms\": terms,\n",
    "        \"name_to_id\": name_to_id,\n",
    "        \"hierarchy\": hierarchy\n",
    "    }\n",
    "\n",
    "\n",
    "# MPOã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "mpo_data = parse_mpo_obo(\"data/ontology/mp.obo\")\n",
    "print(f\"Parsed {len(mpo_data['terms'])} MP terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. è¡¨ç¾å‹é »åº¦ã¨ICå€¤ã®è¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_phenotype_frequencies(symbol_mptermname_path: str) -> dict:\n",
    "    \"\"\"éºä¼å­â†’è¡¨ç¾å‹ãƒãƒƒãƒ”ãƒ³ã‚°ã‹ã‚‰å„è¡¨ç¾å‹ã®å‡ºç¾é »åº¦ã‚’è¨ˆç®—\"\"\"\n",
    "    \n",
    "    with open(symbol_mptermname_path, \"r\") as f:\n",
    "        symbol_mptermname = json.load(f)\n",
    "    \n",
    "    phenotype_counts = Counter()\n",
    "    \n",
    "    for gene, phenotypes in symbol_mptermname.items():\n",
    "        if phenotypes:\n",
    "            for phenotype in phenotypes:\n",
    "                if phenotype.strip():\n",
    "                    phenotype_counts[phenotype.strip()] += 1\n",
    "    \n",
    "    return dict(phenotype_counts)\n",
    "\n",
    "\n",
    "def calculate_information_content(phenotype_frequencies: dict) -> dict:\n",
    "    \"\"\"å„è¡¨ç¾å‹ã®Information Content (IC)ã‚’è¨ˆç®—\"\"\"\n",
    "    \n",
    "    total_observations = sum(phenotype_frequencies.values())\n",
    "    ic_scores = {}\n",
    "    \n",
    "    for phenotype, frequency in phenotype_frequencies.items():\n",
    "        probability = frequency / total_observations\n",
    "        ic_score = -math.log(probability) if probability > 0 else 0.0\n",
    "        ic_scores[phenotype] = ic_score\n",
    "    \n",
    "    return ic_scores\n",
    "\n",
    "\n",
    "# é »åº¦ã¨ICå€¤ã‚’è¨ˆç®—\n",
    "phenotype_frequencies = calculate_phenotype_frequencies(\"data/annotation/symbol_mptermname.json\")\n",
    "ic_scores = calculate_information_content(phenotype_frequencies)\n",
    "\n",
    "print(f\"Found {len(phenotype_frequencies)} unique phenotypes\")\n",
    "print(f\"Total phenotype observations: {sum(phenotype_frequencies.values())}\")\n",
    "\n",
    "# é »å‡ºè¡¨ç¾å‹TOP5ã‚’ç¢ºèª\n",
    "top_phenotypes = sorted(phenotype_frequencies.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"\\nTop 5 most frequent phenotypes:\")\n",
    "for phenotype, count in top_phenotypes:\n",
    "    print(f\"  {count:4d}: {phenotype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. è¡¨ç¾å‹ã®è§£æã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³åˆ†é›¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_phenotype_annotations(phenotype: str) -> tuple:\n",
    "    \"\"\"è¡¨ç¾å‹æ–‡å­—åˆ—ã‹ã‚‰åŸºæœ¬é …ç›®ã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åˆ†é›¢\"\"\"\n",
    "    \n",
    "    # ãƒ‘ã‚¿ãƒ¼ãƒ³: \"åŸºæœ¬è¡¨ç¾å‹ (ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³)\"\n",
    "    pattern = r\"^(.+?)\\s*\\(([^)]+)\\)$\"\n",
    "    match = re.match(pattern, phenotype.strip())\n",
    "    \n",
    "    if not match:\n",
    "        return phenotype.strip(), {}\n",
    "    \n",
    "    base_term = match.group(1).strip()\n",
    "    annotation_str = match.group(2).strip()\n",
    "    \n",
    "    # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åˆ†é¡\n",
    "    annotations = {}\n",
    "    \n",
    "    # è¤‡æ•°ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚«ãƒ³ãƒã§åŒºåˆ‡ã‚‰ã‚Œã‚‹\n",
    "    parts = [part.strip() for part in annotation_str.split(\",\")]\n",
    "    \n",
    "    for part in parts:\n",
    "        if part in [\"Homo\", \"Hetero\", \"Hemi\"]:\n",
    "            annotations[\"genotype\"] = part\n",
    "        elif part in [\"Male\", \"Female\"]:\n",
    "            annotations[\"sex\"] = part\n",
    "        elif part in [\"Early\", \"Late\", \"Embryo\", \"Interval\"]:\n",
    "            annotations[\"life_stage\"] = part\n",
    "    \n",
    "    return base_term, annotations\n",
    "\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆ\n",
    "test_phenotypes = [\n",
    "    \"preweaning lethality, complete penetrance (Homo, Early)\",\n",
    "    \"abnormal skin morphology (Homo, Early)\",\n",
    "    \"hyperactivity (Homo, Early)\"\n",
    "]\n",
    "\n",
    "print(\"è¡¨ç¾å‹è§£æãƒ†ã‚¹ãƒˆ:\")\n",
    "for phenotype in test_phenotypes:\n",
    "    base, annotations = parse_phenotype_annotations(phenotype)\n",
    "    print(f\"  {phenotype}\")\n",
    "    print(f\"    åŸºæœ¬: '{base}'\")\n",
    "    print(f\"    ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {annotations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼éšå±¤ã¨LCAè¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestors(term_id: str, hierarchy: dict) -> set:\n",
    "    \"\"\"æŒ‡å®šã•ã‚ŒãŸtermã®å…¨ç¥–å…ˆã‚’å–å¾—\"\"\"\n",
    "    \n",
    "    ancestors = set()\n",
    "    stack = [term_id]\n",
    "    \n",
    "    while stack:\n",
    "        current = stack.pop()\n",
    "        for parent in hierarchy.get(current, set()):\n",
    "            if parent not in ancestors:\n",
    "                ancestors.add(parent)\n",
    "                stack.append(parent)\n",
    "    \n",
    "    return ancestors\n",
    "\n",
    "\n",
    "def calculate_term_depth(term_id: str, hierarchy: dict, depth_cache: dict = None) -> int:\n",
    "    \"\"\"ãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®æ·±ã•ã‚’è¨ˆç®—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰\"\"\"\n",
    "    \n",
    "    if depth_cache is None:\n",
    "        depth_cache = {}\n",
    "    \n",
    "    if term_id in depth_cache:\n",
    "        return depth_cache[term_id]\n",
    "    \n",
    "    if not hierarchy.get(term_id):\n",
    "        depth_cache[term_id] = 0\n",
    "        return 0\n",
    "    \n",
    "    max_depth = 0\n",
    "    for parent in hierarchy[term_id]:\n",
    "        parent_depth = calculate_term_depth(parent, hierarchy, depth_cache)\n",
    "        max_depth = max(max_depth, parent_depth + 1)\n",
    "    \n",
    "    depth_cache[term_id] = max_depth\n",
    "    return max_depth\n",
    "\n",
    "\n",
    "def find_lowest_common_ancestor(term_a: str, term_b: str, mpo_data: dict) -> str | None:\n",
    "    \"\"\"2ã¤ã®termã®æœ€ä¸‹ä½å…±é€šç¥–å…ˆï¼ˆLCAï¼‰ã‚’è¦‹ã¤ã‘ã‚‹\"\"\"\n",
    "    \n",
    "    # åå‰ã‹ã‚‰IDã«å¤‰æ›\n",
    "    id_a = mpo_data[\"name_to_id\"].get(term_a, term_a)\n",
    "    id_b = mpo_data[\"name_to_id\"].get(term_b, term_b)\n",
    "    \n",
    "    if id_a not in mpo_data[\"terms\"] or id_b not in mpo_data[\"terms\"]:\n",
    "        return None\n",
    "    \n",
    "    # ä¸¡æ–¹ã®ç¥–å…ˆã‚’å–å¾—\n",
    "    ancestors_a = get_ancestors(id_a, mpo_data[\"hierarchy\"])\n",
    "    ancestors_a.add(id_a)\n",
    "    \n",
    "    ancestors_b = get_ancestors(id_b, mpo_data[\"hierarchy\"])\n",
    "    ancestors_b.add(id_b)\n",
    "    \n",
    "    # å…±é€šç¥–å…ˆ\n",
    "    common_ancestors = ancestors_a & ancestors_b\n",
    "    \n",
    "    if not common_ancestors:\n",
    "        return None\n",
    "    \n",
    "    # æœ€ã‚‚æ·±ã„ï¼ˆå…·ä½“çš„ãªï¼‰å…±é€šç¥–å…ˆã‚’é¸æŠ\n",
    "    depth_cache = {}\n",
    "    lca = max(common_ancestors, key=lambda x: calculate_term_depth(x, mpo_data[\"hierarchy\"], depth_cache))\n",
    "    \n",
    "    return lca\n",
    "\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆ\n",
    "print(\"LCAè¨ˆç®—ãƒ†ã‚¹ãƒˆ:\")\n",
    "test_pairs = [\n",
    "    (\"cellular phenotype\", \"abnormal cell morphology\"),\n",
    "    (\"abnormal heart morphology\", \"abnormal blood vessel morphology\")\n",
    "]\n",
    "\n",
    "for term_a, term_b in test_pairs:\n",
    "    lca_id = find_lowest_common_ancestor(term_a, term_b, mpo_data)\n",
    "    if lca_id:\n",
    "        lca_name = mpo_data[\"terms\"][lca_id][\"name\"]\n",
    "        print(f\"  '{term_a}' & '{term_b}' -> LCA: {lca_name}\")\n",
    "    else:\n",
    "        print(f\"  '{term_a}' & '{term_b}' -> LCA: None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resnik Similarityè¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_phenotype_ic(base_phenotype: str, ic_scores: dict) -> float:\n",
    "    \"\"\"åŸºæœ¬è¡¨ç¾å‹ã®æœ€å¤§ICå€¤ã‚’å–å¾—\"\"\"\n",
    "    \n",
    "    max_ic = 0.0\n",
    "    \n",
    "    for phenotype, ic in ic_scores.items():\n",
    "        # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³éƒ¨åˆ†ã‚’é™¤ã„ãŸåŸºæœ¬è¡¨ç¾å‹ã‚’æŠ½å‡º\n",
    "        current_base, _ = parse_phenotype_annotations(phenotype)\n",
    "        if current_base == base_phenotype:\n",
    "            max_ic = max(max_ic, ic)\n",
    "    \n",
    "    return max_ic\n",
    "\n",
    "\n",
    "def calculate_string_similarity(term_a: str, term_b: str) -> float:\n",
    "    \"\"\"æ–‡å­—åˆ—é¡ä¼¼åº¦ã«ã‚ˆã‚‹è£œå®Œè¨ˆç®—\"\"\"\n",
    "    \n",
    "    # å…±é€šã®\"abnormal XXX morphology\"ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯\n",
    "    pattern_morphology = r'^abnormal\\s+\\w+\\s+morphology$'\n",
    "    if (re.match(pattern_morphology, term_a) and \n",
    "        re.match(pattern_morphology, term_b)):\n",
    "        return 1.0  # å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã¯ä¸­ç¨‹åº¦ã®é¡ä¼¼åº¦\n",
    "    \n",
    "    # å˜èªãƒ¬ãƒ™ãƒ«ã®Jaccardé¡ä¼¼åº¦\n",
    "    words_a = set(term_a.lower().split())\n",
    "    words_b = set(term_b.lower().split())\n",
    "    \n",
    "    if not words_a or not words_b:\n",
    "        return 0.0\n",
    "    \n",
    "    common_words = words_a & words_b\n",
    "    total_words = words_a | words_b\n",
    "    \n",
    "    jaccard_sim = len(common_words) / len(total_words)\n",
    "    \n",
    "    # é‡è¦ãªå˜èªã«ãƒœãƒ¼ãƒŠã‚¹\n",
    "    important_words = {'abnormal', 'morphology', 'increased', 'decreased'}\n",
    "    important_common = common_words & important_words\n",
    "    \n",
    "    if important_common:\n",
    "        bonus = len(important_common) * 0.3\n",
    "        jaccard_sim += bonus\n",
    "    \n",
    "    return min(jaccard_sim, 3.0)  # æœ€å¤§3.0ã«åˆ¶é™\n",
    "\n",
    "\n",
    "def calculate_base_resnik_similarity(term_a: str, term_b: str, mpo_data: dict, ic_scores: dict) -> float:\n",
    "    \"\"\"åŸºæœ¬è¡¨ç¾å‹ã®Resnik similarityè¨ˆç®—\"\"\"\n",
    "    \n",
    "    # åŒä¸€é …ç›®ã®å ´åˆ\n",
    "    if term_a == term_b:\n",
    "        return get_base_phenotype_ic(term_a, ic_scores)\n",
    "    \n",
    "    # MPOã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ã§LCAã‚’æ¢ã™\n",
    "    lca_id = find_lowest_common_ancestor(term_a, term_b, mpo_data)\n",
    "\n",
    "    ontology_similarity = 0.0    \n",
    "    if lca_id is not None:\n",
    "        lca_name = mpo_data[\"terms\"][lca_id][\"name\"]\n",
    "        ontology_similarity = get_base_phenotype_ic(lca_name, ic_scores)\n",
    "    \n",
    "    # æ–‡å­—åˆ—é¡ä¼¼åº¦ã«ã‚ˆã‚‹è£œå®Œ\n",
    "    string_similarity = calculate_string_similarity(term_a, term_b)\n",
    "    \n",
    "    # ã‚ˆã‚Šé«˜ã„é¡ä¼¼åº¦ã‚’æ¡ç”¨\n",
    "    return max(ontology_similarity, string_similarity)\n",
    "\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆ\n",
    "print(\"åŸºæœ¬Resnik similarity ãƒ†ã‚¹ãƒˆ:\")\n",
    "test_pairs = [\n",
    "    (\"preweaning lethality, complete penetrance\", \"abnormal heart morphology\"),\n",
    "    (\"abnormal skin morphology\", \"abnormal kidney morphology\"),\n",
    "    (\"abnormal spleen morphology\", \"abnormal kidney morphology\"),\n",
    "    (\"abnormal heart morphology\", \"abnormal blood vessel morphology\")\n",
    "\n",
    "]\n",
    "\n",
    "for term_a, term_b in test_pairs:\n",
    "    similarity = calculate_base_resnik_similarity(term_a, term_b, mpo_data, ic_scores)\n",
    "    print(f\"  '{term_a}' & '{term_b}' -> {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_id = find_lowest_common_ancestor(term_a, term_b, mpo_data)\n",
    "print(lca_id)\n",
    "ontology_similarity = 0.0    \n",
    "if lca_id is not None:\n",
    "    lca_name = mpo_data[\"terms\"][lca_id][\"name\"]\n",
    "    ontology_similarity = get_base_phenotype_ic(lca_name, ic_scores)\n",
    "print(lca_name)\n",
    "print(ontology_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é¡ä¼¼åº¦è¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_partial_similarity(annotation_type: str, value_a: str, value_b: str) -> float:\n",
    "    \"\"\"ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å€¤é–“ã®éƒ¨åˆ†çš„é¡ä¼¼åº¦\"\"\"\n",
    "    \n",
    "    if annotation_type == \"genotype\":\n",
    "        genotype_similarity = {\n",
    "            (\"Hetero\", \"Homo\"): 0.1,\n",
    "            (\"Hemi\", \"Homo\"): 0.05,\n",
    "            (\"Hemi\", \"Hetero\"): 0.05,\n",
    "        }\n",
    "        key = tuple(sorted([value_a, value_b]))\n",
    "        return genotype_similarity.get(key, 0.0)\n",
    "    \n",
    "    elif annotation_type == \"sex\":\n",
    "        return 0.0  # Male vs Female: å®Œå…¨ã«ç•°ãªã‚‹\n",
    "    \n",
    "    elif annotation_type == \"life_stage\":\n",
    "        life_stage_similarity = {\n",
    "            (\"Early\", \"Interval\"): 0.1,\n",
    "            (\"Early\", \"Late\"): 0.02,\n",
    "            (\"Early\", \"Embryo\"): 0.02,\n",
    "            (\"Interval\", \"Late\"): 0.2,\n",
    "            (\"Interval\", \"Embryo\"): 0.02,\n",
    "            (\"Late\", \"Embryo\"): 0.02,\n",
    "        }\n",
    "        key = tuple(sorted([value_a, value_b]))\n",
    "        return life_stage_similarity.get(key, 0.0)\n",
    "    \n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def calculate_annotation_similarity(annotations_a: dict, annotations_b: dict) -> float:\n",
    "    \"\"\"ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–“ã®é¡ä¼¼åº¦è¨ˆç®—\"\"\"\n",
    "    \n",
    "    # å„ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã®é‡ã¿\n",
    "    annotation_weights = {\"genotype\": 0.5, \"sex\": 0.3, \"life_stage\": 0.2}\n",
    "    \n",
    "    total_weight = 0\n",
    "    similarity_sum = 0\n",
    "    \n",
    "    for annotation_type in [\"genotype\", \"sex\", \"life_stage\"]:\n",
    "        if annotation_type in annotations_a or annotation_type in annotations_b:\n",
    "            weight = annotation_weights[annotation_type]\n",
    "            total_weight += weight\n",
    "            \n",
    "            if annotation_type in annotations_a and annotation_type in annotations_b:\n",
    "                # ä¸¡æ–¹ã«ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å­˜åœ¨\n",
    "                if annotations_a[annotation_type] == annotations_b[annotation_type]:\n",
    "                    similarity_sum += weight * 1.0  # å®Œå…¨ä¸€è‡´\n",
    "                else:\n",
    "                    # éƒ¨åˆ†çš„é¡ä¼¼åº¦\n",
    "                    partial_sim = get_annotation_partial_similarity(\n",
    "                        annotation_type,\n",
    "                        annotations_a[annotation_type],\n",
    "                        annotations_b[annotation_type]\n",
    "                    )\n",
    "                    similarity_sum += weight * partial_sim\n",
    "            else:\n",
    "                # ç‰‡æ–¹ã®ã¿ã«ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å­˜åœ¨ - ä½ã„ãƒšãƒŠãƒ«ãƒ†ã‚£\n",
    "                similarity_sum += weight * 0.01\n",
    "    \n",
    "    if total_weight == 0:\n",
    "        return 1.0  # ä¸¡æ–¹ã¨ã‚‚ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãªã—\n",
    "    \n",
    "    return similarity_sum / total_weight\n",
    "\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆ\n",
    "print(\"ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é¡ä¼¼åº¦ãƒ†ã‚¹ãƒˆ:\")\n",
    "test_cases = [\n",
    "    ({\"genotype\": \"Homo\", \"life_stage\": \"Early\"}, {\"genotype\": \"Homo\", \"life_stage\": \"Early\"}),\n",
    "    ({\"genotype\": \"Homo\", \"life_stage\": \"Early\"}, {\"genotype\": \"Hetero\", \"life_stage\": \"Early\"}),\n",
    "    ({\"genotype\": \"Homo\", \"sex\": \"Male\"}, {\"genotype\": \"Homo\", \"sex\": \"Female\"})\n",
    "]\n",
    "\n",
    "for ann_a, ann_b in test_cases:\n",
    "    similarity = calculate_annotation_similarity(ann_a, ann_b)\n",
    "    print(f\"  {ann_a} & {ann_b} -> {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. çµ±åˆResnik Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_resnik_similarity(phenotype_a: str, phenotype_b: str, mpo_data: dict, ic_scores: dict) -> float:\n",
    "    \"\"\"ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è€ƒæ…®å‹Resnik similarityè¨ˆç®—\"\"\"\n",
    "    \n",
    "    # å®Œå…¨ä¸€è‡´ã®å ´åˆ\n",
    "    if phenotype_a == phenotype_b:\n",
    "        return ic_scores.get(phenotype_a, 0.0)\n",
    "    \n",
    "    # è¡¨ç¾å‹ã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åˆ†é›¢\n",
    "    base_a, annotations_a = parse_phenotype_annotations(phenotype_a)\n",
    "    base_b, annotations_b = parse_phenotype_annotations(phenotype_b)\n",
    "    \n",
    "    # åŸºæœ¬è¡¨ç¾å‹ã®Resnik similarity\n",
    "    base_similarity = calculate_base_resnik_similarity(base_a, base_b, mpo_data, ic_scores)\n",
    "    \n",
    "    # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é¡ä¼¼åº¦\n",
    "    annotation_similarity = calculate_annotation_similarity(annotations_a, annotations_b)\n",
    "    \n",
    "    # çµ±åˆé¡ä¼¼åº¦è¨ˆç®—ï¼ˆåŸºæœ¬è¡¨ç¾å‹ã‚’é‡è¦–ï¼‰\n",
    "    if base_similarity < 0.01:\n",
    "        # åŸºæœ¬è¡¨ç¾å‹ãŒã»ã¼ç•°ãªã‚‹å ´åˆã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã»ã¼ç„¡è¦–\n",
    "        combined_similarity = 0.999 * base_similarity + 0.001 * annotation_similarity\n",
    "    elif base_similarity < 0.1:\n",
    "        # åŸºæœ¬è¡¨ç¾å‹ãŒå°‘ã—é¡ä¼¼ã™ã‚‹å ´åˆ\n",
    "        combined_similarity = 0.99 * base_similarity + 0.01 * annotation_similarity\n",
    "    else:\n",
    "        # é€šå¸¸ã®é‡ã¿\n",
    "        combined_similarity = 0.98 * base_similarity + 0.02 * annotation_similarity\n",
    "    \n",
    "    return combined_similarity\n",
    "\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆ\n",
    "print(\"çµ±åˆResnik similarity ãƒ†ã‚¹ãƒˆ:\")\n",
    "test_phenotype_pairs = [\n",
    "    (\"preweaning lethality, complete penetrance (Homo, Early)\", \"abnormal heart morphology (Homo, Early)\"),\n",
    "    (\"abnormal skin morphology (Homo, Early)\", \"abnormal kidney morphology (Homo, Early)\"),\n",
    "    (\"abnormal spleen morphology (Homo, Early)\", \"abnormal kidney morphology (Homo, Early)\"),\n",
    "    (\"hyperactivity (Homo, Early)\", \"hyperactivity (Hetero, Early)\")  # åŒã˜åŸºæœ¬è¡¨ç¾å‹ã€ç•°ãªã‚‹genotype\n",
    "]\n",
    "\n",
    "print(\"\\nçµæœ:\")\n",
    "for phenotype_a, phenotype_b in test_phenotype_pairs:\n",
    "    similarity = calculate_resnik_similarity(phenotype_a, phenotype_b, mpo_data, ic_scores)\n",
    "    \n",
    "    # è©³ç´°æƒ…å ±ã‚‚è¡¨ç¤º\n",
    "    base_a, ann_a = parse_phenotype_annotations(phenotype_a)\n",
    "    base_b, ann_b = parse_phenotype_annotations(phenotype_b)\n",
    "    base_sim = calculate_base_resnik_similarity(base_a, base_b, mpo_data, ic_scores)\n",
    "    ann_sim = calculate_annotation_similarity(ann_a, ann_b)\n",
    "    \n",
    "    print(f\"\\nğŸ“ é¡ä¼¼åº¦: {similarity:.4f}\")\n",
    "    print(f\"   {phenotype_a}\")\n",
    "    print(f\"   vs\")\n",
    "    print(f\"   {phenotype_b}\")\n",
    "    print(f\"   åŸºæœ¬é¡ä¼¼åº¦: {base_sim:.4f}, ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é¡ä¼¼åº¦: {ann_sim:.4f}\")\n",
    "    \n",
    "    # é »åº¦æƒ…å ±\n",
    "    freq_a = phenotype_frequencies.get(phenotype_a, 0)\n",
    "    freq_b = phenotype_frequencies.get(phenotype_b, 0)\n",
    "    print(f\"   é »åº¦: {freq_a} vs {freq_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Jaccardã¨Resnikã®æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(phenotype_a: str, phenotype_b: str) -> float:\n",
    "    \"\"\"å¾“æ¥ã®Jaccard similarityï¼ˆå‚è€ƒç”¨ï¼‰\"\"\"\n",
    "    return 1.0 if phenotype_a == phenotype_b else 0.0\n",
    "\n",
    "\n",
    "print(\"Jaccard vs Resnik Similarity æ¯”è¼ƒ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_pairs = [\n",
    "    (\"preweaning lethality, complete penetrance (Homo, Early)\", \"abnormal heart morphology (Homo, Early)\"),\n",
    "    (\"abnormal skin morphology (Homo, Early)\", \"abnormal kidney morphology (Homo, Early)\"),\n",
    "    (\"abnormal spleen morphology (Homo, Early)\", \"abnormal kidney morphology (Homo, Early)\"),\n",
    "    (\"hyperactivity (Homo, Early)\", \"hyperactivity (Homo, Early)\")  # åŒä¸€è¡¨ç¾å‹\n",
    "]\n",
    "\n",
    "for phenotype_a, phenotype_b in comparison_pairs:\n",
    "    jaccard_sim = jaccard_similarity(phenotype_a, phenotype_b)\n",
    "    resnik_sim = calculate_resnik_similarity(phenotype_a, phenotype_b, mpo_data, ic_scores)\n",
    "    \n",
    "    print(f\"\\nğŸ“ {phenotype_a}\")\n",
    "    print(f\"   vs\")\n",
    "    print(f\"   {phenotype_b}\")\n",
    "    print(f\"   ğŸ“Š Jaccard: {jaccard_sim:.4f}  |  Resnik: {resnik_sim:.4f}\")\n",
    "    \n",
    "    # æ”¹å–„åŠ¹æœã‚’è©•ä¾¡\n",
    "    if jaccard_sim == 0.0 and resnik_sim < 0.1:\n",
    "        print(f\"   âœ… æ”¹å–„æˆåŠŸ: éé–¢é€£è¡¨ç¾å‹ã®é¡ä¼¼åº¦ãŒé©åˆ‡ã«ä½ã„\")\n",
    "    elif jaccard_sim == 0.0 and resnik_sim >= 0.1:\n",
    "        print(f\"   ğŸ” æ³¨ç›®: é–¢é€£æ€§ã®ã‚ã‚‹è¡¨ç¾å‹ã¨ã—ã¦æ¤œå‡º\")\n",
    "    elif jaccard_sim == 1.0:\n",
    "        print(f\"   ğŸ¯ åŒä¸€è¡¨ç¾å‹: ICå€¤ã‚’æ´»ç”¨\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Resnik Similarity ã®åˆ©ç‚¹:\")\n",
    "print(f\"   1. é »å‡ºè¡¨ç¾å‹ï¼ˆpreweaning lethalityç­‰ï¼‰ã®åã‚Šã‚’è»½æ¸›\")\n",
    "print(f\"   2. ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼éšå±¤ã‚’è€ƒæ…®ã—ãŸæ„å‘³çš„é¡ä¼¼åº¦\")\n",
    "print(f\"   3. ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’é©åˆ‡ã«è€ƒæ…®\")\n",
    "print(f\"   4. é–¢é€£æ€§ã®ã‚ã‚‹è¡¨ç¾å‹é–“ã§é©åˆ‡ãªé¡ä¼¼åº¦ã‚’æä¾›\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. çµæœã®ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã‚’ä¿å­˜\n",
    "output_dir = Path(\"data/resnik_similarity_simplified\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 1. MPOãƒ‡ãƒ¼ã‚¿ä¿å­˜\n",
    "with open(output_dir / \"mpo_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mpo_data, f)\n",
    "\n",
    "# 2. IC scoresä¿å­˜\n",
    "with open(output_dir / \"ic_scores.json\", \"w\") as f:\n",
    "    json.dump(ic_scores, f, indent=2)\n",
    "\n",
    "# 3. é »åº¦ãƒ‡ãƒ¼ã‚¿ä¿å­˜\n",
    "with open(output_dir / \"phenotype_frequencies.json\", \"w\") as f:\n",
    "    json.dump(phenotype_frequencies, f, indent=2)\n",
    "\n",
    "# 4. ä½¿ã„ã‚„ã™ã„é–¢æ•°ç¾¤ã‚’ã¾ã¨ã‚ãŸè¾æ›¸ã‚’ä¿å­˜\n",
    "similarity_functions = {\n",
    "    \"calculate_resnik_similarity\": calculate_resnik_similarity,\n",
    "    \"parse_phenotype_annotations\": parse_phenotype_annotations,\n",
    "    \"calculate_base_resnik_similarity\": calculate_base_resnik_similarity,\n",
    "    \"calculate_annotation_similarity\": calculate_annotation_similarity\n",
    "}\n",
    "\n",
    "print(f\"Simplified Resnik similarity data saved to {output_dir}/\")\n",
    "print(f\"Files saved:\")\n",
    "for file_path in output_dir.glob(\"*\"):\n",
    "    print(f\"  - {file_path.name}\")\n",
    "\n",
    "print(f\"\\nâœ… ç°¡ç•¥åŒ–å®Ÿè£…å®Œäº†!\")\n",
    "print(f\"ä¸»è¦é–¢æ•°:\")\n",
    "print(f\"  - calculate_resnik_similarity(): ãƒ¡ã‚¤ãƒ³é–¢æ•°\")\n",
    "print(f\"  - parse_phenotype_annotations(): è¡¨ç¾å‹è§£æ\")\n",
    "print(f\"  - calculate_base_resnik_similarity(): åŸºæœ¬é¡ä¼¼åº¦\")\n",
    "print(f\"  - calculate_annotation_similarity(): ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é¡ä¼¼åº¦\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tsumugi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
