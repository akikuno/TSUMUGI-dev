{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run allですべてのデータを準備する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEASE = 23.0\n",
    "\n",
    "columns = [\"marker_symbol\", \"marker_accession_id\", \"mp_term_name\", \"mp_term_id\", \"p_value\", \"sex_effect_p_value\", \"female_ko_effect_p_value\", \"male_ko_effect_p_value\", \"zygosity\", \"effect_size\",]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download IMPC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up to top directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "while not Path(\"LICENSE\").exists():\n",
    "    os.chdir('../')\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = print\n",
    "from pprint import pprint as PP\n",
    "from collections import Counter as C\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import shutil\n",
    "import pickle\n",
    "import json\n",
    "import gzip\n",
    "import networkx as nx\n",
    "import datetime\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# パスの設定\n",
    "data_dir = Path(\"data/impc\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_path = data_dir / f\"statistical-results-ALL-{RELEASE}.csv\"\n",
    "readme_path = data_dir / \"README.md\"\n",
    "\n",
    "# ファイルが存在しない場合にダウンロードして解凍\n",
    "if not csv_path.exists():\n",
    "    # ダウンロード URL\n",
    "    url = f\"https://ftp.ebi.ac.uk/pub/databases/impc/all-data-releases/release-{RELEASE}/results/statistical-results-ALL.csv.gz\"\n",
    "\n",
    "    print(f\"Downloading and extracting: {url}\")\n",
    "\n",
    "    # URL からファイルサイズ取得（tqdmのため）\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        total_size = int(response.info().get(\"Content-Length\", -1))\n",
    "        with tqdm.wrapattr(response, \"read\", total=total_size, desc=\"Downloading\", unit=\"B\", unit_scale=True) as r:\n",
    "            with gzip.GzipFile(fileobj=r) as uncompressed:\n",
    "                with open(csv_path, 'wb') as out_file:\n",
    "                    shutil.copyfileobj(uncompressed, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# wc -l data/impc/statistical-results*.csv\n",
    "# Release 22.1: 3165335\n",
    "# Release 23.0: 2159931\n",
    "# 1 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter dataset by P value < 0.0001 (10^-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"data\", \"impc\", f\"statistical-results-ALL-{RELEASE}.csv\")\n",
    "data = pd.read_csv(path_data)\n",
    "data = data[columns]\n",
    "# 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))\n",
    "# Release 21.1: 2062772\n",
    "# Release 22.0: 3165334\n",
    "# Release 23.0: 2159930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by p_value < 0.0001\n",
    "threshold = 0.0001\n",
    "filter_pvalue = data[\"p_value\"] < threshold\n",
    "filter_female_ko_pvalue = data[\"female_ko_effect_p_value\"] < threshold\n",
    "filter_male_ko_pvalue = data[\"male_ko_effect_p_value\"] < threshold\n",
    "\n",
    "data_filtered = data[filter_pvalue | filter_male_ko_pvalue | filter_male_ko_pvalue]\n",
    "\n",
    "# Filter by mp_term_id and mp_term_name are not NaN\n",
    "data_filtered = data_filtered.dropna(subset=[\"mp_term_id\"])\n",
    "data_filtered = data_filtered.dropna(subset=[\"mp_term_name\"])\n",
    "\n",
    "# Filter by effect_size is not NaN\n",
    "data_filtered = data_filtered.dropna(subset=[\"effect_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_filtered))\n",
    "# Release 22.0: 54059 rows\n",
    "# Release 22.1: 54059 rows\n",
    "# Release 23.0: 48963 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered.to_csv(f\"data/statistical_filtered-{RELEASE}.csv\", index=False) # 2 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data by mp_term_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/mp_term_nameを作成\n",
    "\n",
    "output_path = Path(\"data\", \"mp_term_name\")\n",
    "if output_path.exists():\n",
    "    shutil.rmtree(output_path)\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 名前をクリーンにする関数を定義\n",
    "def clean_name(name):\n",
    "    return name.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "# mp_term_nameをクリーニングし、ユニークな値を取得\n",
    "unique_mp_term_names = data['mp_term_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユニークなmp_term_nameごとにフィルタリングしてCSVに保存: 5 sec\n",
    "for mp_term_name in unique_mp_term_names:\n",
    "    filtered_df = data[data['mp_term_name'] == mp_term_name]\n",
    "    clean_mp_term_name = clean_name(mp_term_name)\n",
    "    filtered_df.to_csv(f\"data/mp_term_name/{clean_mp_term_name}.csv\", index=False)\n",
    "# 5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TSUMUGIに必要なアノテーション情報を整理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"data/statistical_filtered-{RELEASE}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate life stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# life_stageの初期割り当て\n",
    "def assign_life_stage(pipeline_name):\n",
    "    if pd.isna(pipeline_name):\n",
    "        return \"Early\"\n",
    "    if \"Interval\" in pipeline_name or \"interval\" in pipeline_name:\n",
    "        return \"Interval\"\n",
    "    elif \"Late\" in pipeline_name or \"late\" in pipeline_name:\n",
    "        return \"Late\"\n",
    "    else:\n",
    "        return \"Early\"\n",
    "\n",
    "data[\"life_stage\"] = data[\"pipeline_name\"].apply(assign_life_stage)\n",
    "\n",
    "# Embryo 表現型に該当する procedure_name の一覧\n",
    "embryo_phenotyping = [\n",
    "    \"Gross Morphology Embryo E9.5\",\n",
    "    \"Viability E9.5 Secondary Screen\",\n",
    "    \"OPT E9.5\",\n",
    "    \"MicroCT E9.5\",\n",
    "    \"Gross Morphology Placenta E9.5\",\n",
    "    \"Gross Morphology Embryo E12.5\",\n",
    "    \"Embryo LacZ\",\n",
    "    \"Gross Morphology Placenta E12.5\",\n",
    "    \"Viability E12.5 Secondary Screen\",\n",
    "    \"Viability E14.5-E15.5 Secondary Screen\",\n",
    "    \"Gross Morphology Placenta E14.5-E15.5\",\n",
    "    \"MicroCT E14.5-E15.5\",\n",
    "    \"Gross Morphology Embryo E14.5-E15.5\",\n",
    "    \"Viability E18.5 Secondary Screen\",\n",
    "    \"MicroCT E18.5\",\n",
    "    \"Gross Morphology Embryo E18.5\",\n",
    "    \"Gross Morphology Placenta E18.5\"\n",
    "]\n",
    "\n",
    "# life_stageをEmbryoに上書き\n",
    "data.loc[data[\"procedure_name\"].isin(embryo_phenotyping), \"life_stage\"] = \"Embryo\"\n",
    "data_annotated = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_annotated))\n",
    "print(data_annotated[\"life_stage\"].value_counts())\n",
    "# 54059\n",
    "# life_stage\n",
    "# Early       45724\n",
    "# Embryo       4253\n",
    "# Late         4024\n",
    "# Interval       58\n",
    "# Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate Sex differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0001\n",
    "\n",
    "# 条件リスト\n",
    "conditions = [\n",
    "    (data_annotated[\"sex_effect_p_value\"] < threshold) & (data_annotated[\"female_ko_effect_p_value\"] < threshold) & (data_annotated[\"male_ko_effect_p_value\"] > threshold),\n",
    "    (data_annotated[\"sex_effect_p_value\"] < threshold) & (data_annotated[\"male_ko_effect_p_value\"] < threshold) & (data_annotated[\"female_ko_effect_p_value\"] > threshold)\n",
    "]\n",
    "\n",
    "# 条件に対応する値\n",
    "choices = [\"female\", \"male\"]\n",
    "\n",
    "# np.selectで列を設定\n",
    "data_annotated[\"sexdual_dimorphism\"] = np.select(conditions, choices, default=None)\n",
    "data_annotated = data_annotated.reset_index(drop=True)\n",
    "\n",
    "# 結果を確認\n",
    "print(RELEASE)\n",
    "print(data_annotated[\"sexdual_dimorphism\"].value_counts())\n",
    "\n",
    "# RELEASE 22.1\n",
    "# sexdual_dimorphism\n",
    "# male      4915\n",
    "# female    4146\n",
    "\n",
    "print(len(data_annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "data_annotated.dropna(subset=[\"sexdual_dimorphism\"])[[\"p_value\", \"sexdual_dimorphism\", \"effect_size\", \"genotype_effect_parameter_estimate\", \"female_ko_parameter_estimate\", \"male_ko_parameter_estimate\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 遺伝型、性差、ライフステージのアノテーションを統合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_annotated[\"zygosity\"].value_counts())\n",
    "# zygosity\n",
    "# homozygote      41444\n",
    "# heterozygote    11921\n",
    "# hemizygote        694\n",
    "# Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmuns = [\"marker_symbol\", \"marker_accession_id\", \"mp_term_name\", \"mp_term_id\", \"p_value\", \"female_ko_effect_p_value\", \"male_ko_effect_p_value\", \"sexdual_dimorphism\", \"zygosity\", \"life_stage\", \"effect_size\",]\n",
    "\n",
    "data_annotated = data_annotated[colmuns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_term = \"increased fasting circulating glucose level\".strip()\n",
    "# data_annotated[\n",
    "#     (data_annotated[\"marker_symbol\"] == \"Dnase1l2\") &\n",
    "#     (data_annotated[\"mp_term_name\"] == mp_term)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーション列を追加（inplace）\n",
    "def make_annotation(row):\n",
    "    # 遺伝型\n",
    "    if row['zygosity'] == 'homozygote':\n",
    "        annotate = \"Homo\"\n",
    "    elif row['zygosity'] == 'heterozygote':\n",
    "        annotate = \"Hetero\"\n",
    "    else:\n",
    "        annotate = \"Hemi\"\n",
    "\n",
    "    # 性別\n",
    "    if row['sexdual_dimorphism'] == \"female\":\n",
    "        annotate += \", Female\"\n",
    "    elif row['sexdual_dimorphism'] == \"male\":\n",
    "        annotate += \", Male\"\n",
    "\n",
    "    # life_stage\n",
    "    if row['life_stage'] in {\"Embryo\", \"Early\", \"Interval\", \"Late\"}:\n",
    "        annotate += f\", {row['life_stage']}\"\n",
    "\n",
    "    return f\"{row['mp_term_name']} ({annotate})\"\n",
    "\n",
    "data_annotated[\"annotation\"] = data_annotated.apply(make_annotation, axis=1)\n",
    "\n",
    "# marker_symbol ごとに annotation をリスト化＆ソート\n",
    "marker_annotation_map = (\n",
    "    data_annotated\n",
    "    .groupby(\"marker_symbol\")[\"annotation\"]\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例：Rhdの注釈を表示\n",
    "print(marker_annotation_map[\"Rhd\"])\n",
    "# 例：Amtの注釈を表示 (Embryo)\n",
    "print(marker_annotation_map[\"Amt\"])\n",
    "# 例：Spag4の注釈を表示 (重複が削除されているか)\n",
    "print(marker_annotation_map[\"Spag4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Path(\"data/annotation\").mkdir(exist_ok=True, parents=True)\n",
    "file_path = \"data/annotation/symbol_mptermname.json\"\n",
    "marker_annotation_map.to_json(file_path, indent=4)\n",
    "\n",
    "# json.dump(marker_annotation_map, open(file_path, \"w\"), indent=4, sort_keys=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "grep -c \"Male\" data/annotation/symbol_mptermname.json | sed \"s|^|Male: |\"\n",
    "grep -c \"Female\" data/annotation/symbol_mptermname.json | sed \"s|^|Feale: |\"\n",
    "\n",
    "grep -c \"Homo\" data/annotation/symbol_mptermname.json | sed \"s|^|Homo: |\"\n",
    "grep -c \"Hetero\" data/annotation/symbol_mptermname.json | sed \"s|^|Hetero: |\"\n",
    "grep -c \"Hemi\" data/annotation/symbol_mptermname.json | sed \"s|^|Hemi: |\"\n",
    "\n",
    "grep -c \"Embryo\" data/annotation/symbol_mptermname.json | sed \"s|^|Embryo: |\"\n",
    "grep -c \"Early\" data/annotation/symbol_mptermname.json | sed \"s|^|Early: |\"\n",
    "grep -c \"Interval\" data/annotation/symbol_mptermname.json | sed \"s|^|Interval: |\"\n",
    "grep -c \"Late\" data/annotation/symbol_mptermname.json | sed \"s|^|Late: |\"\n",
    "\n",
    "# Male: 4915\n",
    "# Feale: 4146\n",
    "# Homo: 41444\n",
    "# Hetero: 11921\n",
    "# Hemi: 694\n",
    "# Embryo: 4253\n",
    "# Early: 45724\n",
    "# Interval: 58\n",
    "# Late: 4024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mp term nameとIMPCのPhenotype URLを紐付ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = data[['mp_term_id', 'mp_term_name']].drop_duplicates()\n",
    "# data_select = data[['marker_symbol', 'marker_accession_id', 'mp_term_name', 'mp_term_id']].drop_duplicates()\n",
    "data_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_url = dict()\n",
    "for index, row in data_select.iterrows():\n",
    "    mp_tern_id = row['mp_term_id']\n",
    "    impc_url = f\"https://www.mousephenotype.org/data/phenotypes/{mp_tern_id}\"\n",
    "    mp_term_name = row['mp_term_name']\n",
    "    data_dict_url[mp_term_name] = impc_url\n",
    "\n",
    "print(data_dict_url[\"small lymph nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/annotation/mptermname_phenotypeurl.tsv', 'w') as f:\n",
    "    for term, url in data_dict_url.items():\n",
    "        f.write(f\"{term}\\t{url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "head -n 3 data/annotation/mptermname_phenotypeurl.tsv\n",
    "wc -l data/annotation/mptermname_phenotypeurl.tsv\n",
    "# Release 22.0: 664\n",
    "# Release 23.0: 659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### marker symbolとMGI accession idを紐付ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = data[['marker_symbol', 'marker_accession_id']].drop_duplicates()\n",
    "# data_select = data[['marker_symbol', 'marker_accession_id', 'mp_term_name', 'mp_term_id']].drop_duplicates()\n",
    "data_select\n",
    "# Release 22.1: 7746 rows\n",
    "# Release 23.0: 7934 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "for index, row in data_select.iterrows():\n",
    "    data_dict[row['marker_symbol']] = row['marker_accession_id']\n",
    "print(data_dict[\"Ncam1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data_dict, open(\"data/annotation/symbol_mgiid.json\", \"w\"), indent=4, sort_keys=True)\n",
    "Path(\"data/annotation/symbol_mgiid.tsv\").write_text(\"\\n\".join([f\"{k}\\t{v}\" for k, v in data_dict.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 3 data/annotation/symbol_mgiid.json\n",
    "head -n 3 data/annotation/symbol_mgiid.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 表現型の類似度を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"data\", \"annotation\", \"symbol_mptermname.json\")\n",
    "\n",
    "symbol_mptermname = json.load(open(file_path))\n",
    "print(symbol_mptermname[\"Dpf2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_mptermname = {k: set(v) for k, v in symbol_mptermname.items() if v}\n",
    "print(symbol_mptermname[\"Dpf2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard係数で集合の類似度を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overlapped_ratios_all = []\n",
    "\n",
    "for a, b in combinations(symbol_mptermname, 2):\n",
    "    overlapped_mp = sorted(symbol_mptermname[a] & symbol_mptermname[b])\n",
    "    overlapped_mp_number = len(overlapped_mp)\n",
    "    union_mp_number = len(symbol_mptermname[a] | symbol_mptermname[b])\n",
    "    overlap_ratio = overlapped_mp_number / union_mp_number\n",
    "\n",
    "    overlapped_ratios_all.append([a, b, round(overlap_ratio, 3), overlapped_mp_number, overlapped_mp])\n",
    "\n",
    "## 46s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overlapped_ratios_all[:3])\n",
    "print(len(overlapped_ratios_all))\n",
    "# Release 22.0: 29996385\n",
    "# Release 22.1: 29996385\n",
    "# Release 23.0: 31470211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重複する表現型が閾値以上のものを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "similarity_threshold = 0.5\n",
    "num_overlapped_mp = 3\n",
    "\n",
    "overlapped_ratios_filtered = []\n",
    "for record in overlapped_ratios_all:\n",
    "    if record[2] >= similarity_threshold or record[3] >= num_overlapped_mp:\n",
    "        overlapped_ratios_filtered.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overlapped_ratios_filtered[:3])\n",
    "print(len(overlapped_ratios_filtered))\n",
    "# Release 21.1: 134880\n",
    "# Release 22.0: 133281 <- Homo/Hetero/Hemiおよび♂・♀の完全一致を考慮するようになったため、減少\n",
    "# Release 22.1: 133281\n",
    "# v0.3.0: 261216 <- Similarity_threshodのor条件をつけたため、増加\n",
    "# Release 23.0 TSUMUGI v0.3.2: 241645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data\", \"overlap\").mkdir(exist_ok=True, parents=True)\n",
    "pickle.dump(overlapped_ratios_all, open(\"data/overlap/overlapped_ratios_all.pkl\", \"wb\"))\n",
    "pickle.dump(overlapped_ratios_filtered, open(\"data/overlap/overlapped_ratios_filtered.pkl\", \"wb\"))\n",
    "\n",
    "# 18 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生データをCSV形式で出力 （ダウンロード用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.DataFrame(overlapped_ratios_all)\n",
    "df_overlap.columns = [\"Gene1\", \"Gene2\", \"Jaccard Similarity\", \"Number of shared phenotype\", \"List of shared phenotypes\"]\n",
    "df_overlap.reindex(\n",
    "    columns=[\"Gene1\", \"Gene2\", \"Number of shared phenotype\", \"Jaccard Similarity\", \"List of shared phenotypes\"]\n",
    ")\n",
    "df_overlap[\"List of shared phenotypes\"] = df_overlap[\"List of shared phenotypes\"].apply(json.dumps)\n",
    "df_overlap\n",
    "# 30 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"data/TSUMUGI_raw_data.csv.gz\")\n",
    "\n",
    "def get_head1000_hash(df: pd.DataFrame) -> str:\n",
    "    # head(1000)だけを対象にハッシュ化\n",
    "    csv_bytes = df.head(1000).to_csv(index=False, lineterminator='\\n').encode('utf-8')\n",
    "    return hashlib.md5(csv_bytes).hexdigest()\n",
    "\n",
    "def file_head1000_hash(path: Path) -> str | None:\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        lines = [next(f) for _ in range(1001)]  # 1行目がヘッダー\n",
    "        csv_content = ''.join(lines).encode('utf-8')\n",
    "        return hashlib.md5(csv_content).hexdigest()\n",
    "\n",
    "# 比較\n",
    "new_hash = get_head1000_hash(df_overlap)\n",
    "existing_hash = file_head1000_hash(output_path)\n",
    "\n",
    "if new_hash != existing_hash:\n",
    "    df_overlap.to_csv(output_path, index=False, compression=\"gzip\", lineterminator='\\n')\n",
    "    print(\"🔄 ファイルを更新しました\") # 3 min\n",
    "else:\n",
    "    print(\"✅ 内容に変更がないためスキップしました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap_filtered = pd.DataFrame(overlapped_ratios_filtered)\n",
    "df_overlap_filtered.columns = [\"Gene1\", \"Gene2\", \"Jaccard Similarity\", \"Number of shared phenotype\", \"List of shared phenotypes\"]\n",
    "df_overlap_filtered.reindex(\n",
    "    columns=[\"Gene1\", \"Gene2\", \"Number of shared phenotype\", \"Jaccard Similarity\", \"List of shared phenotypes\"]\n",
    ")\n",
    "df_overlap_filtered[\"List of shared phenotypes\"] = df_overlap_filtered[\"List of shared phenotypes\"].apply(json.dumps)\n",
    "\n",
    "df_overlap_filtered.to_csv(\"data/TSUMUGI_filtered_data.csv.gz\", index=False, compression=\"gzip\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表現型ごとのネットワークを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapped_ratios_filtered = pickle.load(open(\"data/overlap/overlapped_ratios_filtered.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.DataFrame(\n",
    "    overlapped_ratios_filtered, columns=[\"marker1\", \"marker2\", \"overlap_ratio\", \"overlapped_mp_number\", \"overlapped_mp\"]\n",
    ")\n",
    "df_overlap\n",
    "# version 0.2.2: 133281  rows × 5 columns\n",
    "# version 0.3.0: 261216  rows × 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_mp = json.load(open(\"data/annotation/symbol_mptermname.json\"))\n",
    "marker_mp = pd.DataFrame(marker_mp.items(), columns=[\"marker_symbol\", \"mp_term_name\"])\n",
    "marker_mp\n",
    "# version 0.2.2: 7626 rows × 2 columns\n",
    "# version 0.3.0: 7746 rows × 2 columns\n",
    "# version 0.3.1: 7746 rows × 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_mp_terms = list(Path(\"data\", \"mp_term_name\").glob(\"*.csv\"))\n",
    "# for path_mp_term in path_mp_terms:\n",
    "#     mp_term = path_mp_term.stem\n",
    "#     if mp_term == \"increased_fasting_circulating_glucose_level\":\n",
    "#         break\n",
    "# mp_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_marker_effect = pd.read_csv(path_mp_term)\n",
    "\n",
    "# # effect sizeの絶対値が最大の行を取得\n",
    "# df_marker_effect = df_marker_effect[[\"marker_symbol\", \"effect_size\"]].loc[\n",
    "#     df_marker_effect.groupby(\"marker_symbol\")[\"effect_size\"].apply(lambda x: x.abs().idxmax())\n",
    "# ].reset_index(drop=True)\n",
    "\n",
    "# df_marker_effect\n",
    "# # df_marker_effect[df_marker_effect[\"marker_symbol\"] == \"Abcd3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Absolute value of effect size\n",
    "# df_marker_effect.loc[:, \"effect_size\"] = df_marker_effect[\"effect_size\"].abs()\n",
    "\n",
    "# df_filtered = df_overlap[\n",
    "#     (df_overlap['marker1'].isin(df_marker_effect['marker_symbol'])) &\n",
    "#     (df_overlap['marker2'].isin(df_marker_effect['marker_symbol']))\n",
    "# ]\n",
    "\n",
    "# number_of_nodes = 200\n",
    "# # 二分探索の範囲\n",
    "# low, high = df_filtered[\"overlap_ratio\"].min(), df_filtered[\"overlap_ratio\"].max()\n",
    "# best_overlap_ratio = None\n",
    "\n",
    "# while low <= high:\n",
    "#     mid = (low + high) / 2\n",
    "\n",
    "#     # overlap_ratio >= mid のデータをフィルタリング\n",
    "#     df_mid = df_filtered[df_filtered[\"overlap_ratio\"] >= mid]\n",
    "\n",
    "#     ## 出力\n",
    "#     ### Nodeを作成する\n",
    "#     df_marker1 = df_mid[[\"marker1\"]]\n",
    "#     df_marker2 = df_mid[[\"marker2\"]]\n",
    "#     df_node_marker1 = pd.merge(df_marker1, df_marker_effect, left_on='marker1', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "#     df_node_marker2 = pd.merge(df_marker2, df_marker_effect, left_on='marker2', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "#     df_node = pd.concat([df_node_marker1, df_node_marker2], axis=0).drop_duplicates()\n",
    "#     df_node = pd.merge(df_node, marker_mp, how='inner', on='marker_symbol')\n",
    "#     df_node = pd.merge(df_node, df_marker_effect, how='inner', on='marker_symbol')\n",
    "\n",
    "#     node_count = len(df_node)\n",
    "#     # ターゲット列数に近い場合、結果を保存\n",
    "#     if number_of_nodes - 25 < node_count < number_of_nodes + 25:\n",
    "#         best_overlap_ratio = mid\n",
    "#         break\n",
    "#     elif node_count > number_of_nodes:\n",
    "#         # 列数が多い場合、範囲を上げる\n",
    "#         best_overlap_ratio = mid\n",
    "#         low = mid + 1e-6\n",
    "#     else:\n",
    "#         # 列数が少ない場合、範囲を下げる\n",
    "#         best_overlap_ratio = mid\n",
    "#         high = mid - 1e-6\n",
    "\n",
    "# df_filtered = df_filtered[df_filtered[\"overlap_ratio\"] >= best_overlap_ratio]\n",
    "\n",
    "# ## 出力\n",
    "# ### Nodeを作成する\n",
    "# df_marker1 = df_filtered[[\"marker1\"]]\n",
    "# df_marker2 = df_filtered[[\"marker2\"]]\n",
    "# df_node_marker1 = pd.merge(df_marker1, df_marker_effect, left_on='marker1', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "# df_node_marker2 = pd.merge(df_marker2, df_marker_effect, left_on='marker2', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "\n",
    "# df_node = pd.concat([df_node_marker1, df_node_marker2], axis=0).drop_duplicates()\n",
    "# df_node = pd.merge(df_node, marker_mp, how='inner', on='marker_symbol')\n",
    "# df_node = pd.merge(df_node, df_marker_effect, how='inner', on='marker_symbol')\n",
    "\n",
    "# df_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_node[df_node[\"marker_symbol\"] == \"Abcd3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"data/network/mp_term_name\")\n",
    "# remove network directory\n",
    "if output_dir.exists():\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mp_terms = list(Path(\"data\", \"mp_term_name\").glob(\"*.csv\"))\n",
    "# print(path_mp_terms[:3])\n",
    "# print(len(path_mp_terms))\n",
    "# path_mp_term = Path(\"data\", \"mp_term_name\", \"increasing_circulating_glucose_level.csv\")\n",
    "\n",
    "\"\"\"\n",
    "ノードが多すぎるとWebページが描画できない問題を回避するため、\n",
    "ノード数を200以下にするために最適なoverlap_ratioを求める\n",
    "\"\"\"\n",
    "number_of_nodes = 200\n",
    "\n",
    "for path_mp_term in path_mp_terms:\n",
    "    mp_term = path_mp_term.stem\n",
    "    # print(mp_term)\n",
    "\n",
    "    df_marker_effect = pd.read_csv(path_mp_term)\n",
    "    df_marker_effect = df_marker_effect.dropna(subset=[\"effect_size\"])\n",
    "    # Absolute value of effect size\n",
    "    df_marker_effect.loc[:, \"effect_size\"] = df_marker_effect[\"effect_size\"].abs()\n",
    "\n",
    "    # * effect sizeの絶対値が最大の行を取得 (Homo/Heteroで異なる効果量がある場合に、ひとまず最大値を採用する← 今後の考慮事項)\n",
    "    df_marker_effect = df_marker_effect[[\"marker_symbol\", \"effect_size\"]].loc[\n",
    "        df_marker_effect.groupby(\"marker_symbol\")[\"effect_size\"].idxmax()\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    df_filtered = df_overlap[\n",
    "        (df_overlap['marker1'].isin(df_marker_effect['marker_symbol'])) &\n",
    "        (df_overlap['marker2'].isin(df_marker_effect['marker_symbol'])) &\n",
    "        (df_overlap['overlapped_mp'].apply(lambda lst: any(mp_term.replace(\"_\", \" \") in term for term in lst)))\n",
    "    ]\n",
    "    # 二分探索の範囲\n",
    "    low, high = df_filtered[\"overlap_ratio\"].min(), df_filtered[\"overlap_ratio\"].max()\n",
    "    best_overlap_ratio = None\n",
    "\n",
    "    while low <= high:\n",
    "        mid = (low + high) / 2\n",
    "\n",
    "        # overlap_ratio >= mid のデータをフィルタリング\n",
    "        df_mid = df_filtered[df_filtered[\"overlap_ratio\"] >= mid]\n",
    "\n",
    "        ## 出力\n",
    "        ### Nodeを作成する\n",
    "        df_marker1 = df_mid[[\"marker1\"]]\n",
    "        df_marker2 = df_mid[[\"marker2\"]]\n",
    "        df_node_marker1 = pd.merge(df_marker1, df_marker_effect, left_on='marker1', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "        df_node_marker2 = pd.merge(df_marker2, df_marker_effect, left_on='marker2', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "        df_node = pd.concat([df_node_marker1, df_node_marker2], axis=0).drop_duplicates()\n",
    "        df_node = pd.merge(df_node, marker_mp, how='inner', on='marker_symbol')\n",
    "        df_node = pd.merge(df_node, df_marker_effect, how='inner', on='marker_symbol')\n",
    "\n",
    "        node_count = len(df_node)\n",
    "        # ターゲット列数に近い場合、結果を保存\n",
    "        if number_of_nodes - 25 < node_count < number_of_nodes + 25:\n",
    "            best_overlap_ratio = mid\n",
    "            break\n",
    "        elif node_count > number_of_nodes:\n",
    "            # 列数が多い場合、範囲を上げる\n",
    "            best_overlap_ratio = mid\n",
    "            low = mid + 1e-6\n",
    "        else:\n",
    "            # 列数が少ない場合、範囲を下げる\n",
    "            best_overlap_ratio = mid\n",
    "            high = mid - 1e-6\n",
    "\n",
    "    df_filtered = df_filtered[df_filtered[\"overlap_ratio\"] >= best_overlap_ratio]\n",
    "\n",
    "    ## 出力\n",
    "    ### Nodeを作成する\n",
    "    df_marker1 = df_filtered[[\"marker1\"]]\n",
    "    df_marker2 = df_filtered[[\"marker2\"]]\n",
    "    df_node_marker1 = pd.merge(df_marker1, df_marker_effect, left_on='marker1', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "    df_node_marker2 = pd.merge(df_marker2, df_marker_effect, left_on='marker2', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "\n",
    "    df_node = pd.concat([df_node_marker1, df_node_marker2], axis=0).drop_duplicates()\n",
    "    df_node = pd.merge(df_node, marker_mp, how='inner', on='marker_symbol')\n",
    "    df_node = pd.merge(df_node, df_marker_effect, how='inner', on='marker_symbol')\n",
    "\n",
    "    if len(df_node) == 0:\n",
    "        continue\n",
    "\n",
    "    # print(mp_term, len(df_node))\n",
    "\n",
    "    # NodeをJSON形式に変換\n",
    "    node_json = []\n",
    "    for _, row in df_node.iterrows():\n",
    "        node_json.append({\n",
    "            \"data\": {\n",
    "                \"id\": row['marker_symbol'],\n",
    "                \"label\": row['marker_symbol'],\n",
    "                \"annotation\": row['mp_term_name'],\n",
    "                \"node_color\": row['effect_size']\n",
    "            }\n",
    "        })\n",
    "    ### Edgeを作成する\n",
    "    df_edge = df_filtered[[\"marker1\", \"marker2\", \"overlap_ratio\", \"overlapped_mp\"]]\n",
    "    # EdgeをJSON形式に変換\n",
    "    edge_json = []\n",
    "    for _, row in df_edge.iterrows():\n",
    "        edge_json.append({\n",
    "            \"data\": {\n",
    "                \"source\": row['marker1'],\n",
    "                \"target\": row['marker2'],\n",
    "                \"annotation\": row['overlapped_mp'],\n",
    "                \"edge_size\": row['overlap_ratio']\n",
    "            }\n",
    "        })\n",
    "\n",
    "    ### EdgeとNodeを統合して、出力\n",
    "    # Combine node and edge\n",
    "\n",
    "    network_json = node_json + edge_json\n",
    "\n",
    "    # Output as JSON\n",
    "    if network_json:\n",
    "        output_json = output_dir / f\"{mp_term}.json.gz\"\n",
    "        with gzip.open(output_json, \"wt\", encoding=\"utf-8\") as f:\n",
    "            json.dump(network_json, f, indent=4)\n",
    "\n",
    "# 1m30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -lhS data/network/mp_term_name/ | head -n 5\n",
    "\n",
    "# version 0.2.2: total 5.3M\n",
    "# version 0.3.0: total 5.5M\n",
    "# version 0.3.1: total 5.1M <- 該当の表現型を含むネットワークのみを表示 （Issue: #54）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遺伝子ごとのネットワークを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_mp_dict = dict(zip(marker_mp.marker_symbol, marker_mp.mp_term_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_symbols = df_overlap.marker1.unique().tolist()\n",
    "gene_symbols += df_overlap.marker2.unique().tolist()\n",
    "gene_symbols = list(set(gene_symbols))\n",
    "gene_symbols.sort()  # 以下のfor文で、どこまで遺伝子が処理されたのか途中経過を見積もるためのソート\n",
    "P(gene_symbols[:3])\n",
    "P(len(gene_symbols))  # 6003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"data\", \"network\", \"gene_symbol\")\n",
    "# remove network directory\n",
    "if output_dir.exists():\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene_symbol in gene_symbols:\n",
    "    \"\"\"\n",
    "    ノードが多すぎるとWebページが描画できない問題を回避するため、\n",
    "    ノード数を200以下にするために最適なoverlap_ratioを求める\n",
    "    \"\"\"\n",
    "    # 今の処理\n",
    "    df_filtered = df_overlap[(df_overlap[\"marker1\"] == gene_symbol) | (df_overlap[\"marker2\"] == gene_symbol)]\n",
    "\n",
    "    G = nx.from_pandas_edgelist(df_filtered, \"marker1\", \"marker2\")\n",
    "\n",
    "    # ノードAと直接つながっているノードのみを取得\n",
    "    neighbors = list(G.neighbors(gene_symbol))\n",
    "    subgraph_nodes = [gene_symbol] + neighbors\n",
    "    subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "    target_number_of_nodes = 200\n",
    "    if len(subgraph.nodes) > target_number_of_nodes:\n",
    "        # 二分探索の範囲\n",
    "        low, high = df_filtered[\"overlap_ratio\"].min(), df_filtered[\"overlap_ratio\"].max()\n",
    "        best_overlap_ratio = None\n",
    "\n",
    "        while low <= high:\n",
    "            mid = (low + high) / 2\n",
    "\n",
    "            # overlap_ratio >= mid のデータをフィルタリング\n",
    "            df_mid = df_filtered[df_filtered[\"overlap_ratio\"] >= mid]\n",
    "\n",
    "            G = nx.from_pandas_edgelist(df_mid, \"marker1\", \"marker2\")\n",
    "            # ノードAと直接つながっているノードのみを取得\n",
    "            try:\n",
    "                neighbors = list(G.neighbors(gene_symbol))\n",
    "            except:\n",
    "                high = mid - 1e-6\n",
    "                continue\n",
    "            subgraph_nodes = [gene_symbol] + neighbors\n",
    "            subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "            row_count = len(subgraph.nodes)\n",
    "            # ターゲット列数に近い場合、結果を保存\n",
    "            if target_number_of_nodes - 25 < row_count < target_number_of_nodes + 25:\n",
    "                best_overlap_ratio = mid\n",
    "                break\n",
    "            elif row_count > target_number_of_nodes:\n",
    "                # 列数が多い場合、範囲を上げる\n",
    "                best_overlap_ratio = mid\n",
    "                low = mid + 1e-6\n",
    "            else:\n",
    "                # 列数が少ない場合、範囲を下げる\n",
    "                best_overlap_ratio = mid\n",
    "                high = mid - 1e-6\n",
    "\n",
    "        df_nodes = df_filtered[df_filtered[\"overlap_ratio\"] >= best_overlap_ratio]\n",
    "        G = nx.from_pandas_edgelist(df_nodes, \"marker1\", \"marker2\")\n",
    "        # ノードAと直接つながっているノードのみを取得\n",
    "        neighbors = list(G.neighbors(gene_symbol))\n",
    "        subgraph_nodes = [gene_symbol] + neighbors\n",
    "        subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "    # nodesを用意\n",
    "    node_json = []\n",
    "    for node in subgraph.nodes():\n",
    "        annotation = marker_mp_dict[node]\n",
    "        node_color = 1 if node == gene_symbol else 0\n",
    "        node_json.append({\"data\": {\"id\": node, \"label\": node, \"node_color\": node_color, \"annotation\": annotation}})\n",
    "\n",
    "    # edgesを用意\n",
    "    df_edge = df_overlap[\n",
    "        (df_overlap[\"marker1\"].isin(subgraph.nodes())) & (df_overlap[\"marker2\"].isin(subgraph.nodes()))\n",
    "    ]\n",
    "\n",
    "    edge_json = []\n",
    "    for edge in df_edge.itertuples():\n",
    "        edge_json.append(\n",
    "            {\n",
    "                \"data\": {\n",
    "                    \"source\": edge.marker1,\n",
    "                    \"target\": edge.marker2,\n",
    "                    \"edge_size\": edge.overlap_ratio,\n",
    "                    \"annotation\": edge.overlapped_mp,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    network_json = node_json + edge_json\n",
    "\n",
    "    # Output as JSON\n",
    "    if network_json:\n",
    "        output_json = output_dir / f\"{gene_symbol}.json.gz\"\n",
    "        with gzip.open(output_json, \"wt\", encoding=\"utf-8\") as f:\n",
    "            json.dump(network_json, f, indent=4)\n",
    "\n",
    "# 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lhS data/network/gene_symbol/ | head -n 5\n",
    "# version 0.3.0: total 170M\n",
    "# version 0.3.1: total 168M\n",
    "# version 0.3.2: total 145M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data/overlap/available_gene_symbols.txt\").write_text(\"\\n\".join(gene_symbols) + \"\\n\")\n",
    "print(len(gene_symbols))  # 4416 -> 4244 → 6003 → 4139\n",
    "# version 0.2.2: 4139\n",
    "# version 0.3.0: 6812 (Life stageを考慮 + 類似度を追加)\n",
    "# version 0.3.1: 6812\n",
    "# version 0.3.2: 6904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "uname -a # OS name\n",
    "date +\"%Y/%m/%d %H:%M:%S\" # Last update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tsumugi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
