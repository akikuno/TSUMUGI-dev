{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run allですべてのデータを準備する\n",
    "\n",
    "* URL: https://ftp.ebi.ac.uk/pub/databases/impc/all-data-releases/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEASE = 23.0\n",
    "\n",
    "columns = [\"marker_symbol\", \"marker_accession_id\", \"mp_term_name\", \"mp_term_id\", \"p_value\", \"effect_size\",\n",
    "           \"female_ko_effect_p_value\", \"male_ko_effect_p_value\", \"female_ko_parameter_estimate\",\"sex_effect_p_value\", \"male_ko_parameter_estimate\", # sex differences\n",
    "           \"genotype_effect_p_value\", \"genotype_effect_parameter_estimate\",\n",
    "           \"zygosity\", # zygosity\n",
    "           \"pipeline_name\", \"procedure_name\", # life-stage\n",
    "           \"allele_symbol\", # map to Phendigm\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download IMPC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = print\n",
    "from pprint import pprint as PP\n",
    "from collections import Counter as C\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import shutil\n",
    "import pickle\n",
    "import json\n",
    "import gzip\n",
    "import networkx as nx\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up to top directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "while not Path(\"LICENSE\").exists():\n",
    "    os.chdir('../')\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenodigm dataが存在していない場合には、ダウンロードを促す\n",
    "\n",
    "if not Path(\"data\", \"phenodigm\", \"impc_phenodigm.csv\").exists():\n",
    "    raise FileNotFoundError(\"Please download impc phenodigm data from https://diseasemodels.research.its.qmul.ac.uk/.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パスの設定\n",
    "data_dir = Path(\"data/impc\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_path = data_dir / f\"statistical-results-ALL-{RELEASE}.csv\"\n",
    "\n",
    "# ファイルが存在しない場合にダウンロードして解凍\n",
    "if not csv_path.exists():\n",
    "    # ダウンロード URL\n",
    "    url = f\"https://ftp.ebi.ac.uk/pub/databases/impc/all-data-releases/release-{RELEASE}/results/statistical-results-ALL.csv.gz\"\n",
    "\n",
    "    print(f\"Downloading and extracting: {url}\")\n",
    "\n",
    "    # URL からファイルサイズ取得（tqdmのため）\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        total_size = int(response.info().get(\"Content-Length\", -1))\n",
    "        with tqdm.wrapattr(response, \"read\", total=total_size, desc=\"Downloading\", unit=\"B\", unit_scale=True) as r:\n",
    "            with gzip.GzipFile(fileobj=r) as uncompressed:\n",
    "                with open(csv_path, 'wb') as out_file:\n",
    "                    shutil.copyfileobj(uncompressed, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# wc -l data/impc/statistical-results*.csv\n",
    "# Release 22.1: 3165335\n",
    "# Release 23.0: 2159931\n",
    "\n",
    "# 1 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter dataset by P value < 0.0001 (10^-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"data\", \"impc\", f\"statistical-results-ALL-{RELEASE}.csv\")\n",
    "data = pd.read_csv(path_data)\n",
    "data = data[columns]\n",
    "# 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))\n",
    "# Release 21.1: 2062772\n",
    "# Release 22.0: 3165334\n",
    "# Release 23.0: 2159930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by p_value < 0.0001\n",
    "threshold = 0.0001\n",
    "filter_pvalue = data[\"p_value\"] < threshold\n",
    "filter_female_ko_pvalue = data[\"female_ko_effect_p_value\"] < threshold\n",
    "filter_male_ko_pvalue = data[\"male_ko_effect_p_value\"] < threshold\n",
    "\n",
    "data_filtered = data[filter_pvalue | filter_female_ko_pvalue | filter_male_ko_pvalue] #! 要確認！！！\n",
    "\n",
    "# Filter by mp_term_id and mp_term_name are not NaN\n",
    "data_filtered = data_filtered.dropna(subset=[\"mp_term_id\"])\n",
    "data_filtered = data_filtered.dropna(subset=[\"mp_term_name\"])\n",
    "\n",
    "# Filter by effect_size is not NaN\n",
    "data_filtered = data_filtered.dropna(subset=[\"effect_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_filtered))\n",
    "# Release 22.0: 54059 rows\n",
    "# Release 22.1: 54059 rows\n",
    "# Release 23.0: 49299 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered.to_csv(f\"data/statistical_filtered-{RELEASE}.csv\", index=False) # 2 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data by mp_term_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"data/statistical_filtered-{RELEASE}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/mp_term_nameを作成\n",
    "\n",
    "output_path = Path(\"data\", \"mp_term_name\")\n",
    "if output_path.exists():\n",
    "    shutil.rmtree(output_path)\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 名前をクリーンにする関数を定義\n",
    "def clean_name(name):\n",
    "    return name.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "# mp_term_nameをクリーニングし、ユニークな値を取得\n",
    "unique_mp_term_names = data['mp_term_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユニークなmp_term_nameごとにフィルタリングしてCSVに保存: 5 sec\n",
    "for mp_term_name in unique_mp_term_names:\n",
    "    filtered_df = data[data['mp_term_name'] == mp_term_name]\n",
    "    clean_mp_term_name = clean_name(mp_term_name)\n",
    "    filtered_df.to_csv(f\"data/mp_term_name/{clean_mp_term_name}.csv\", index=False)\n",
    "# 5 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TSUMUGIに必要なアノテーション情報を整理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistical_filtered = pd.read_csv(f\"data/statistical_filtered-{RELEASE}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate life stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# life_stageの初期割り当て\n",
    "def assign_life_stage(pipeline_name):\n",
    "    if pd.isna(pipeline_name):\n",
    "        return \"Early\"\n",
    "    if \"Interval\" in pipeline_name or \"interval\" in pipeline_name:\n",
    "        return \"Interval\"\n",
    "    elif \"Late\" in pipeline_name or \"late\" in pipeline_name:\n",
    "        return \"Late\"\n",
    "    else:\n",
    "        return \"Early\"\n",
    "\n",
    "df_statistical_filtered[\"life_stage\"] = df_statistical_filtered[\"pipeline_name\"].apply(assign_life_stage)\n",
    "\n",
    "# Embryo 表現型に該当する procedure_name の一覧\n",
    "embryo_phenotyping = [\n",
    "    \"Gross Morphology Embryo E9.5\",\n",
    "    \"Viability E9.5 Secondary Screen\",\n",
    "    \"OPT E9.5\",\n",
    "    \"MicroCT E9.5\",\n",
    "    \"Gross Morphology Placenta E9.5\",\n",
    "    \"Gross Morphology Embryo E12.5\",\n",
    "    \"Embryo LacZ\",\n",
    "    \"Gross Morphology Placenta E12.5\",\n",
    "    \"Viability E12.5 Secondary Screen\",\n",
    "    \"Viability E14.5-E15.5 Secondary Screen\",\n",
    "    \"Gross Morphology Placenta E14.5-E15.5\",\n",
    "    \"MicroCT E14.5-E15.5\",\n",
    "    \"Gross Morphology Embryo E14.5-E15.5\",\n",
    "    \"Viability E18.5 Secondary Screen\",\n",
    "    \"MicroCT E18.5\",\n",
    "    \"Gross Morphology Embryo E18.5\",\n",
    "    \"Gross Morphology Placenta E18.5\"\n",
    "]\n",
    "\n",
    "# life_stageをEmbryoに上書き\n",
    "df_statistical_filtered.loc[df_statistical_filtered[\"procedure_name\"].isin(embryo_phenotyping), \"life_stage\"] = \"Embryo\"\n",
    "df_annotated = df_statistical_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_annotated))\n",
    "print(df_annotated[\"life_stage\"].value_counts())\n",
    "# 54059\n",
    "# life_stage\n",
    "# Early       45724\n",
    "# Embryo       4253\n",
    "# Late         4024\n",
    "# Interval       58\n",
    "# Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate Sex differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0001\n",
    "\n",
    "# 条件リスト\n",
    "conditions = [\n",
    "    (df_annotated[\"sex_effect_p_value\"] < threshold) & (df_annotated[\"female_ko_effect_p_value\"] < threshold) & (df_annotated[\"male_ko_effect_p_value\"] > threshold),\n",
    "    (df_annotated[\"sex_effect_p_value\"] < threshold) & (df_annotated[\"male_ko_effect_p_value\"] < threshold) & (df_annotated[\"female_ko_effect_p_value\"] > threshold)\n",
    "]\n",
    "\n",
    "# 条件に対応する値\n",
    "choices = [\"female\", \"male\"]\n",
    "\n",
    "# np.selectで列を設定\n",
    "df_annotated[\"sexdual_dimorphism\"] = np.select(conditions, choices, default=None)\n",
    "df_annotated = df_annotated.reset_index(drop=True)\n",
    "\n",
    "# 結果を確認\n",
    "print(RELEASE)\n",
    "print(df_annotated[\"sexdual_dimorphism\"].value_counts())\n",
    "\n",
    "# RELEASE 22.1\n",
    "# male      4915\n",
    "# female    4146\n",
    "\n",
    "# RELEASE 23.0\n",
    "# male      5026\n",
    "# female    4344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "df_annotated.dropna(subset=[\"sexdual_dimorphism\"])[[\"p_value\", \"sexdual_dimorphism\", \"effect_size\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Phenodigmスコアを結合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenodigm = pd.read_csv(Path(\"data\", \"phenodigm\", \"impc_phenodigm.csv\"))\n",
    "P(len(df_phenodigm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各行について空白の数をカウント\n",
    "space_counts = df_phenodigm['Mouse model description'].str.count(' ')\n",
    "\n",
    "# 空白の数が2でない行を抽出（== split して3つにならない行）\n",
    "invalid_rows = df_phenodigm[space_counts != 2]\n",
    "\n",
    "# 結果表示\n",
    "print(f\"全体の件数: {len(df_phenodigm)}\")\n",
    "print(f\"空白がちょうど2つでない行数: {len(invalid_rows)}\")\n",
    "print(invalid_rows.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenodigm = df_phenodigm[space_counts == 2]\n",
    "P(len(df_phenodigm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenodigm[['allele_symbol', 'zygosity', 'life_stage']] = df_phenodigm['Mouse model description'].str.split(' ', n=2, expand=True)\n",
    "df_phenodigm = df_phenodigm.drop(columns=['Mouse model description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(df_phenodigm.columns)\n",
    "P(df_phenodigm[\"allele_symbol\"].head(3))\n",
    "P(df_phenodigm[\"zygosity\"].head(3))\n",
    "P(df_phenodigm[\"life_stage\"].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phenodigmの表記とimpcデータの表記を揃える\n",
    "\n",
    "df_phenodigm = df_phenodigm.replace({'zygosity': {'hom': 'homozygote', 'het': 'heterozygote','hem': 'hemizygote'}})\n",
    "df_phenodigm['life_stage'] = df_phenodigm['life_stage'].str.capitalize()\n",
    "print(df_phenodigm[\"zygosity\"].value_counts())\n",
    "print(df_phenodigm[\"life_stage\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated = \\\n",
    "    df_annotated.set_index(['allele_symbol','life_stage','zygosity']) \\\n",
    "    .join(df_phenodigm.set_index(['allele_symbol','life_stage','zygosity']), how='left', rsuffix='_phenodigm') \\\n",
    "    .reset_index()\n",
    "print(len(df_annotated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 遺伝型、性差、ライフステージ、Phenodigmのアノテーションを統合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_annotated[\"zygosity\"].value_counts())\n",
    "# RELEASE 22.1\n",
    "# zygosity\n",
    "# homozygote      41444\n",
    "# heterozygote    11921\n",
    "# hemizygote        694\n",
    "\n",
    "# RELEASE 23.0\n",
    "# homozygote      48037\n",
    "# heterozygote    14706\n",
    "# hemizygote        902\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colmuns = [\"marker_symbol\", \"marker_accession_id\", \"mp_term_name\", \"mp_term_id\", \"p_value\", \"female_ko_effect_p_value\", \"male_ko_effect_p_value\", \"sexdual_dimorphism\", \"zygosity\", \"life_stage\", \"effect_size\",]\n",
    "\n",
    "# df_annotated = df_annotated[colmuns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_term = \"increased fasting circulating glucose level\".strip()\n",
    "# df_annotated[\n",
    "#     (df_annotated[\"marker_symbol\"] == \"Dnase1l2\") &\n",
    "#     (df_annotated[\"mp_term_name\"] == mp_term)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーション列を追加（inplace）\n",
    "def make_annotation(row) -> list[str]:\n",
    "    # 遺伝型\n",
    "    if row['zygosity'] == 'homozygote':\n",
    "        annotate = \"Homo\"\n",
    "    elif row['zygosity'] == 'heterozygote':\n",
    "        annotate = \"Hetero\"\n",
    "    else:\n",
    "        annotate = \"Hemi\"\n",
    "\n",
    "    # 性別\n",
    "    if row['sexdual_dimorphism'] == \"female\":\n",
    "        annotate += \", Female\"\n",
    "    elif row['sexdual_dimorphism'] == \"male\":\n",
    "        annotate += \", Male\"\n",
    "\n",
    "    # life stage\n",
    "    if row['life_stage'] in {\"Embryo\", \"Early\", \"Interval\", \"Late\"}:\n",
    "        annotate += f\", {row['life_stage']}\"\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    # mp_term_name は常に追加\n",
    "    annotations.append(f\"{row['mp_term_name']} ({annotate})\")\n",
    "\n",
    "    # Disorder name があれば追加\n",
    "    # Disorder nameであることがわかるように、頭に\"@\"を付ける\n",
    "    if pd.notna(row[\"Disorder name\"]) and str(row[\"Disorder name\"]).strip() != \"\":\n",
    "        annotations.append(f\"@{row['Disorder name']} ({annotate})\")\n",
    "\n",
    "    return annotations\n",
    "\n",
    "df_annotated[\"annotation\"] = df_annotated.apply(make_annotation, axis=1)\n",
    "\n",
    "df_exploded = df_annotated.explode(\"annotation\").reset_index(drop=True)\n",
    "\n",
    "# marker_symbol ごとに annotation をリスト化＆ソート\n",
    "marker_annotation_map = (\n",
    "    df_exploded\n",
    "    .groupby(\"marker_symbol\")[\"annotation\"]\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例：Rhdの注釈を表示\n",
    "print(marker_annotation_map[\"Rhd\"])\n",
    "# 例：Amtの注釈を表示 (Embryo)\n",
    "print(marker_annotation_map[\"Amt\"])\n",
    "# 例：Spag4の注釈を表示 (重複が削除されているか)\n",
    "print(marker_annotation_map[\"Spag4\"])\n",
    "# 例：Phenodigmの注釈を表示 (Embryo)\n",
    "print(marker_annotation_map[\"Arhgap31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data/annotation\").mkdir(exist_ok=True, parents=True)\n",
    "file_path = \"data/annotation/symbol_mptermname.json\"\n",
    "marker_annotation_map.to_json(file_path, indent=4)\n",
    "\n",
    "# json.dump(marker_annotation_map, open(file_path, \"w\"), indent=4, sort_keys=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "grep -c \"Male\" data/annotation/symbol_mptermname.json | sed \"s|^|Male: |\"\n",
    "grep -c \"Female\" data/annotation/symbol_mptermname.json | sed \"s|^|Feale: |\"\n",
    "\n",
    "grep -c \"Homo\" data/annotation/symbol_mptermname.json | sed \"s|^|Homo: |\"\n",
    "grep -c \"Hetero\" data/annotation/symbol_mptermname.json | sed \"s|^|Hetero: |\"\n",
    "grep -c \"Hemi\" data/annotation/symbol_mptermname.json | sed \"s|^|Hemi: |\"\n",
    "\n",
    "grep -c \"Embryo\" data/annotation/symbol_mptermname.json | sed \"s|^|Embryo: |\"\n",
    "grep -c \"Early\" data/annotation/symbol_mptermname.json | sed \"s|^|Early: |\"\n",
    "grep -c \"Interval\" data/annotation/symbol_mptermname.json | sed \"s|^|Interval: |\"\n",
    "grep -c \"Late\" data/annotation/symbol_mptermname.json | sed \"s|^|Late: |\"\n",
    "\n",
    "grep -c \"@\" data/annotation/symbol_mptermname.json | sed \"s|^|Disease: |\"\n",
    "\n",
    "# RELEASE 22.1\n",
    "# Male: 4915\n",
    "# Feale: 4146\n",
    "# Homo: 41444\n",
    "# Hetero: 11921\n",
    "# Hemi: 694\n",
    "# Embryo: 4253\n",
    "# Early: 45724\n",
    "# Interval: 58\n",
    "# Late: 4024\n",
    "\n",
    "# RELEASE 23.0\n",
    "# Male: 4480\n",
    "# Feale: 3557\n",
    "# Homo: 30977\n",
    "# Hetero: 9625\n",
    "# Hemi: 492\n",
    "# Embryo: 4207\n",
    "# Early: 34324\n",
    "# Interval: 54\n",
    "# Late: 2509"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mp term nameとIMPCのPhenotype URLを紐付ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_statistical_filtered[['mp_term_id', 'mp_term_name']].drop_duplicates()\n",
    "# df_select = data[['marker_symbol', 'marker_accession_id', 'mp_term_name', 'mp_term_id']].drop_duplicates()\n",
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_phenotype_url = dict()\n",
    "for index, row in df_select.iterrows():\n",
    "    mp_tern_id = row['mp_term_id']\n",
    "    impc_url = f\"https://www.mousephenotype.org/data/phenotypes/{mp_tern_id}\"\n",
    "    mp_term_name = row['mp_term_name']\n",
    "    dict_phenotype_url[mp_term_name] = impc_url\n",
    "\n",
    "print(dict_phenotype_url[\"small lymph nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/annotation/mptermname_phenotypeurl.tsv', 'w') as f:\n",
    "    for term, url in dict_phenotype_url.items():\n",
    "        f.write(f\"{term}\\t{url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "head -n 3 data/annotation/mptermname_phenotypeurl.tsv\n",
    "wc -l data/annotation/mptermname_phenotypeurl.tsv\n",
    "# Release 22.0: 664\n",
    "# Release 23.0: 659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### marker symbolとMGI accession idを紐付ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = data[['marker_symbol', 'marker_accession_id']].drop_duplicates()\n",
    "# data_select = data[['marker_symbol', 'marker_accession_id', 'mp_term_name', 'mp_term_id']].drop_duplicates()\n",
    "data_select\n",
    "# Release 22.1: 7746 rows\n",
    "# Release 23.0: 7934 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "for index, row in data_select.iterrows():\n",
    "    data_dict[row['marker_symbol']] = row['marker_accession_id']\n",
    "print(data_dict[\"Ncam1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data_dict, open(\"data/annotation/symbol_mgiid.json\", \"w\"), indent=4, sort_keys=True)\n",
    "Path(\"data/annotation/symbol_mgiid.tsv\").write_text(\"\\n\".join([f\"{k}\\t{v}\" for k, v in data_dict.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 3 data/annotation/symbol_mgiid.json\n",
    "head -n 3 data/annotation/symbol_mgiid.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 表現型の類似度を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"data\", \"annotation\", \"symbol_mptermname.json\")\n",
    "\n",
    "symbol_mptermname = json.load(open(file_path))\n",
    "print(symbol_mptermname[\"Dpf2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_mptermname = {k: set(v) for k, v in symbol_mptermname.items() if v}\n",
    "print(symbol_mptermname[\"Dpf2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard係数で集合の類似度を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overlapped_ratios_all = []\n",
    "\n",
    "for a, b in combinations(symbol_mptermname, 2):\n",
    "    overlapped_mp = sorted(symbol_mptermname[a] & symbol_mptermname[b])\n",
    "    overlapped_mp_number = len(overlapped_mp)\n",
    "    union_mp_number = len(symbol_mptermname[a] | symbol_mptermname[b])\n",
    "    overlap_ratio = overlapped_mp_number / union_mp_number\n",
    "\n",
    "    overlapped_ratios_all.append([a, b, round(overlap_ratio, 3), overlapped_mp_number, overlapped_mp])\n",
    "\n",
    "## 46s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overlapped_ratios_all[:3])\n",
    "print(len(overlapped_ratios_all))\n",
    "# Release 22.0: 29996385\n",
    "# Release 22.1: 29996385\n",
    "# Release 23.0: 31470211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重複する表現型が閾値以上のものを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "similarity_threshold = 0.5\n",
    "num_overlapped_mp = 3\n",
    "\n",
    "overlapped_ratios_filtered = []\n",
    "for record in overlapped_ratios_all:\n",
    "    if record[2] >= similarity_threshold or record[3] >= num_overlapped_mp:\n",
    "        overlapped_ratios_filtered.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overlapped_ratios_filtered[:3])\n",
    "print(len(overlapped_ratios_filtered))\n",
    "# Release 21.1: 134880\n",
    "# Release 22.0: 133281 <- Homo/Hetero/Hemiおよび♂・♀の完全一致を考慮するようになったため、減少\n",
    "# Release 22.1: 133281\n",
    "# v0.3.0: 261216 <- Similarity_threshodのor条件をつけたため、増加\n",
    "# Release 23.0 TSUMUGI v0.3.2: 241645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data\", \"overlap\").mkdir(exist_ok=True, parents=True)\n",
    "pickle.dump(overlapped_ratios_all, open(\"data/overlap/overlapped_ratios_all.pkl\", \"wb\"))\n",
    "pickle.dump(overlapped_ratios_filtered, open(\"data/overlap/overlapped_ratios_filtered.pkl\", \"wb\"))\n",
    "\n",
    "# 18 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生データをCSV形式で出力 （ダウンロード用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.DataFrame(overlapped_ratios_all)\n",
    "df_overlap.columns = [\"Gene1\", \"Gene2\", \"Jaccard Similarity\", \"Number of shared phenotype\", \"List of shared phenotypes\"]\n",
    "df_overlap.reindex(\n",
    "    columns=[\"Gene1\", \"Gene2\", \"Number of shared phenotype\", \"Jaccard Similarity\", \"List of shared phenotypes\"]\n",
    ")\n",
    "df_overlap[\"List of shared phenotypes\"] = df_overlap[\"List of shared phenotypes\"].apply(json.dumps)\n",
    "df_overlap\n",
    "# 30 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"data/TSUMUGI_raw_data.csv.gz\")\n",
    "\n",
    "def get_head1000_hash(df: pd.DataFrame) -> str:\n",
    "    # head(1000)だけを対象にハッシュ化\n",
    "    csv_bytes = df.head(1000).to_csv(index=False, lineterminator='\\n').encode('utf-8')\n",
    "    return hashlib.md5(csv_bytes).hexdigest()\n",
    "\n",
    "def file_head1000_hash(path: Path) -> str | None:\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        lines = [next(f) for _ in range(1001)]  # 1行目がヘッダー\n",
    "        csv_content = ''.join(lines).encode('utf-8')\n",
    "        return hashlib.md5(csv_content).hexdigest()\n",
    "\n",
    "# 比較\n",
    "new_hash = get_head1000_hash(df_overlap)\n",
    "existing_hash = file_head1000_hash(output_path)\n",
    "\n",
    "if new_hash != existing_hash:\n",
    "    df_overlap.to_csv(output_path, index=False, compression=\"gzip\", lineterminator='\\n')\n",
    "    print(\"🔄 ファイルを更新しました\") # 3 min\n",
    "else:\n",
    "    print(\"✅ 内容に変更がないためスキップしました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap_filtered = pd.DataFrame(overlapped_ratios_filtered)\n",
    "df_overlap_filtered.columns = [\"Gene1\", \"Gene2\", \"Jaccard Similarity\", \"Number of shared phenotype\", \"List of shared phenotypes\"]\n",
    "df_overlap_filtered.reindex(\n",
    "    columns=[\"Gene1\", \"Gene2\", \"Number of shared phenotype\", \"Jaccard Similarity\", \"List of shared phenotypes\"]\n",
    ")\n",
    "df_overlap_filtered[\"List of shared phenotypes\"] = df_overlap_filtered[\"List of shared phenotypes\"].apply(json.dumps)\n",
    "\n",
    "df_overlap_filtered.to_csv(\"data/TSUMUGI_filtered_data.csv.gz\", index=False, compression=\"gzip\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表現型ごとのネットワークを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapped_ratios_filtered = pickle.load(open(\"data/overlap/overlapped_ratios_filtered.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.DataFrame(\n",
    "    overlapped_ratios_filtered, columns=[\"marker1\", \"marker2\", \"overlap_ratio\", \"overlapped_mp_number\", \"overlapped_mp\"]\n",
    ")\n",
    "df_overlap\n",
    "# version 0.2.2: 133281  rows × 5 columns\n",
    "# version 0.3.0: 261216  rows × 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_mp = json.load(open(\"data/annotation/symbol_mptermname.json\"))\n",
    "marker_mp = pd.DataFrame(marker_mp.items(), columns=[\"marker_symbol\", \"mp_term_name\"])\n",
    "marker_mp\n",
    "# version 0.2.2: 7626 rows × 2 columns\n",
    "# version 0.3.0: 7746 rows × 2 columns\n",
    "# version 0.3.1: 7746 rows × 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"data/network/mp_term_name\")\n",
    "# remove network directory\n",
    "if output_dir.exists():\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mp_terms = list(Path(\"data\", \"mp_term_name\").glob(\"*.csv\"))\n",
    "# print(path_mp_terms[:3])\n",
    "# print(len(path_mp_terms))\n",
    "# path_mp_term = Path(\"data\", \"mp_term_name\", \"increasing_circulating_glucose_level.csv\")\n",
    "\n",
    "\"\"\"\n",
    "ノードが多すぎるとWebページが描画できない問題を回避するため、\n",
    "ノード数を200以下にするために最適なoverlap_ratioを求める\n",
    "\"\"\"\n",
    "number_of_nodes = 200\n",
    "tolerance = 25\n",
    "\n",
    "for path_mp_term in path_mp_terms:\n",
    "\n",
    "    df_marker_effect = pd.read_csv(path_mp_term).dropna(subset=[\"effect_size\"])\n",
    "\n",
    "    # Absolute value of effect size\n",
    "    df_marker_effect[\"effect_size\"] = df_marker_effect[\"effect_size\"].abs()\n",
    "\n",
    "    # * effect sizeの絶対値が最大の行を取得 (Homo/Heteroで異なる効果量がある場合に、ひとまず最大値を採用する← 今後の考慮事項)\n",
    "    df_marker_effect = (\n",
    "        df_marker_effect[[\"marker_symbol\", \"effect_size\"]]  # 必要な列だけ抽出\n",
    "        .loc[df_marker_effect.groupby(\"marker_symbol\")[\"effect_size\"].idxmax()]  # 各 marker_symbol ごとの effect_size 最大値の行を取得\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    mp_term = path_mp_term.stem\n",
    "    target_mp = mp_term.replace(\"_\", \" \")\n",
    "    valid_markers = df_marker_effect['marker_symbol']\n",
    "\n",
    "    df_filtered = df_overlap[\n",
    "        df_overlap['marker1'].isin(valid_markers) &\n",
    "        df_overlap['marker2'].isin(valid_markers) &\n",
    "        df_overlap['overlapped_mp'].apply(lambda lst: any(target_mp in term for term in lst))\n",
    "    ]\n",
    "\n",
    "    # 二分探索の範囲\n",
    "    low, high = df_filtered[\"overlap_ratio\"].min(), df_filtered[\"overlap_ratio\"].max()\n",
    "    best_overlap_ratio = 0\n",
    "\n",
    "    while low <= high:\n",
    "        mid = (low + high) / 2\n",
    "\n",
    "        # overlap_ratio >= mid のデータをフィルタリング\n",
    "        df_mid = df_filtered[df_filtered[\"overlap_ratio\"] >= mid]\n",
    "\n",
    "        # Nodeを作成する\n",
    "        df_marker1 = df_mid[[\"marker1\"]]\n",
    "        df_marker2 = df_mid[[\"marker2\"]]\n",
    "        df_node_marker1 = pd.merge(df_marker1, df_marker_effect, left_on='marker1', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "        df_node_marker2 = pd.merge(df_marker2, df_marker_effect, left_on='marker2', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "        df_node = pd.concat([df_node_marker1, df_node_marker2], axis=0).drop_duplicates()\n",
    "        df_node = pd.merge(df_node, marker_mp, how='inner', on='marker_symbol')\n",
    "        df_node = pd.merge(df_node, df_marker_effect, how='inner', on='marker_symbol')\n",
    "\n",
    "        node_count = len(df_node)\n",
    "        # ターゲットノード数に近い場合、結果を保存\n",
    "        if number_of_nodes - tolerance < node_count < number_of_nodes + tolerance:\n",
    "            best_overlap_ratio = mid\n",
    "            break\n",
    "        elif node_count > number_of_nodes:\n",
    "            # ノード数が多い場合、範囲を上げる\n",
    "            best_overlap_ratio = mid\n",
    "            low = mid + 1e-6\n",
    "        else:\n",
    "            # ノード数が少ない場合、範囲を下げる\n",
    "            best_overlap_ratio = mid\n",
    "            high = mid - 1e-6\n",
    "\n",
    "    df_filtered = df_filtered[df_filtered[\"overlap_ratio\"] >= best_overlap_ratio]\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Nodeを作成する\n",
    "    # ----------------------------------------------------\n",
    "    df_marker1 = df_filtered[[\"marker1\"]]\n",
    "    df_marker2 = df_filtered[[\"marker2\"]]\n",
    "    df_node_marker1 = pd.merge(df_marker1, df_marker_effect, left_on='marker1', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "    df_node_marker2 = pd.merge(df_marker2, df_marker_effect, left_on='marker2', right_on='marker_symbol', how='inner')[[\"marker_symbol\"]]\n",
    "\n",
    "    df_node = pd.concat([df_node_marker1, df_node_marker2], axis=0).drop_duplicates()\n",
    "    df_node = pd.merge(df_node, marker_mp, how='inner', on='marker_symbol')\n",
    "    df_node = pd.merge(df_node, df_marker_effect, how='inner', on='marker_symbol')\n",
    "\n",
    "    if len(df_node) == 0:\n",
    "        continue\n",
    "\n",
    "    # NodeをJSON形式に変換\n",
    "    node_json = []\n",
    "    for _, row in df_node.iterrows():\n",
    "        node_json.append({\n",
    "            \"data\": {\n",
    "                \"id\": row['marker_symbol'],\n",
    "                \"label\": row['marker_symbol'],\n",
    "                \"annotation\": row['mp_term_name'],\n",
    "                \"node_color\": row['effect_size']\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Edgeを作成する\n",
    "    # ----------------------------------------------------\n",
    "    df_edge = df_filtered[[\"marker1\", \"marker2\", \"overlap_ratio\", \"overlapped_mp\"]]\n",
    "    # EdgeをJSON形式に変換\n",
    "    edge_json = []\n",
    "    for _, row in df_edge.iterrows():\n",
    "        edge_json.append({\n",
    "            \"data\": {\n",
    "                \"source\": row['marker1'],\n",
    "                \"target\": row['marker2'],\n",
    "                \"annotation\": row['overlapped_mp'],\n",
    "                \"edge_size\": row['overlap_ratio']\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # EdgeとNodeを統合して、出力\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    network_json = node_json + edge_json\n",
    "\n",
    "    # Output as JSON\n",
    "    if network_json:\n",
    "        output_json = output_dir / f\"{mp_term}.json.gz\"\n",
    "        with gzip.open(output_json, \"wt\", encoding=\"utf-8\") as f:\n",
    "            json.dump(network_json, f, indent=4)\n",
    "\n",
    "# 1m30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -lhS data/network/mp_term_name/ | head -n 5\n",
    "\n",
    "# version 0.2.2: total 5.3M\n",
    "# version 0.3.0: total 5.5M\n",
    "# version 0.3.1: total 5.1M <- 該当の表現型を含むネットワークのみを表示 （Issue: #54）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遺伝子ごとのネットワークを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_mp_dict = dict(zip(marker_mp.marker_symbol, marker_mp.mp_term_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_symbols = df_overlap.marker1.unique().tolist()\n",
    "gene_symbols += df_overlap.marker2.unique().tolist()\n",
    "gene_symbols = list(set(gene_symbols))\n",
    "gene_symbols.sort()  # 以下のfor文で、どこまで遺伝子が処理されたのか途中経過を見積もるためのソート\n",
    "P(gene_symbols[:3])\n",
    "P(len(gene_symbols))  # 6003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"data\", \"network\", \"gene_symbol\")\n",
    "# remove network directory\n",
    "if output_dir.exists():\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nodes = 200\n",
    "tolerance = 25  # tolerance for the number of nodes\n",
    "\n",
    "for gene_symbol in gene_symbols:\n",
    "    \"\"\"\n",
    "    ノードが多すぎるとWebページが描画できない問題を回避するため、\n",
    "    ノード数を200以下にするために最適なoverlap_ratioを求める\n",
    "    \"\"\"\n",
    "    # 今の処理\n",
    "    df_filtered = df_overlap[(df_overlap[\"marker1\"] == gene_symbol) | (df_overlap[\"marker2\"] == gene_symbol)]\n",
    "\n",
    "    G = nx.from_pandas_edgelist(df_filtered, \"marker1\", \"marker2\")\n",
    "\n",
    "    # ノードAと直接つながっているノードのみを取得\n",
    "    neighbors = list(G.neighbors(gene_symbol))\n",
    "    subgraph_nodes = [gene_symbol] + neighbors\n",
    "    subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "    if len(subgraph.nodes) > number_of_nodes:\n",
    "        # 二分探索の範囲\n",
    "        low, high = df_filtered[\"overlap_ratio\"].min(), df_filtered[\"overlap_ratio\"].max()\n",
    "        best_overlap_ratio = None\n",
    "\n",
    "        while low <= high:\n",
    "            mid = (low + high) / 2\n",
    "\n",
    "            # overlap_ratio >= mid のデータをフィルタリング\n",
    "            df_mid = df_filtered[df_filtered[\"overlap_ratio\"] >= mid]\n",
    "\n",
    "            G = nx.from_pandas_edgelist(df_mid, \"marker1\", \"marker2\")\n",
    "            # ノードAと直接つながっているノードのみを取得\n",
    "            if gene_symbol in G:\n",
    "                neighbors = list(G.neighbors(gene_symbol))\n",
    "            else:\n",
    "            # mid が大きすぎてノードが除外されすぎた（＝subgraph が小さくなりすぎた）と考えて、探索範囲の上限 (high) を下げる\n",
    "                high = mid - 1e-6\n",
    "                continue\n",
    "\n",
    "            subgraph_nodes = [gene_symbol] + neighbors\n",
    "            subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "            node_count = len(subgraph.nodes)\n",
    "            # ターゲットノード数に近い場合、結果を保存\n",
    "            if number_of_nodes - tolerance < node_count < number_of_nodes + tolerance:\n",
    "                best_overlap_ratio = mid\n",
    "                break\n",
    "            elif node_count > number_of_nodes:\n",
    "                # ノード数が多い場合、範囲を上げる\n",
    "                best_overlap_ratio = mid\n",
    "                low = mid + 1e-6\n",
    "            else:\n",
    "                # ノード数が少ない場合、範囲を下げる\n",
    "                best_overlap_ratio = mid\n",
    "                high = mid - 1e-6\n",
    "\n",
    "        df_nodes = df_filtered[df_filtered[\"overlap_ratio\"] >= best_overlap_ratio]\n",
    "        G = nx.from_pandas_edgelist(df_nodes, \"marker1\", \"marker2\")\n",
    "        # ノードAと直接つながっているノードのみを取得\n",
    "        neighbors = list(G.neighbors(gene_symbol))\n",
    "        subgraph_nodes = [gene_symbol] + neighbors\n",
    "        subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "    # nodesを用意\n",
    "    node_json = []\n",
    "    for node in subgraph.nodes():\n",
    "        annotation = marker_mp_dict[node]\n",
    "        node_color = 1 if node == gene_symbol else 0\n",
    "        node_json.append({\n",
    "            \"data\": {\n",
    "                \"id\": node,\n",
    "                \"label\": node,\n",
    "                \"node_color\": node_color,\n",
    "                \"annotation\": annotation\n",
    "                }\n",
    "            })\n",
    "\n",
    "    # edgesを用意\n",
    "    df_edge = df_overlap[\n",
    "        (df_overlap[\"marker1\"].isin(subgraph.nodes())) & (df_overlap[\"marker2\"].isin(subgraph.nodes()))\n",
    "    ]\n",
    "\n",
    "    edge_json = []\n",
    "    for edge in df_edge.itertuples():\n",
    "        edge_json.append(\n",
    "            {\n",
    "                \"data\": {\n",
    "                    \"source\": edge.marker1,\n",
    "                    \"target\": edge.marker2,\n",
    "                    \"edge_size\": edge.overlap_ratio,\n",
    "                    \"annotation\": edge.overlapped_mp,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    network_json = node_json + edge_json\n",
    "\n",
    "    # Output as JSON\n",
    "    if network_json:\n",
    "        output_json = output_dir / f\"{gene_symbol}.json.gz\"\n",
    "        with gzip.open(output_json, \"wt\", encoding=\"utf-8\") as f:\n",
    "            json.dump(network_json, f, indent=4)\n",
    "\n",
    "# 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lhS data/network/gene_symbol/ | head -n 5\n",
    "# version 0.3.0: total 170M\n",
    "# version 0.3.1: total 168M\n",
    "# version 0.3.2: total 145M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data/overlap/available_gene_symbols.txt\").write_text(\"\\n\".join(gene_symbols) + \"\\n\")\n",
    "print(len(gene_symbols))  # 4416 -> 4244 → 6003 → 4139\n",
    "# version 0.2.2: 4139\n",
    "# version 0.3.0: 6812 (Life stageを考慮 + 類似度を追加)\n",
    "# version 0.3.1: 6812\n",
    "# version 0.3.2: 6904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "uname -a # OS name\n",
    "date +\"%Y/%m/%d %H:%M:%S\" # Last update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tsumugi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
