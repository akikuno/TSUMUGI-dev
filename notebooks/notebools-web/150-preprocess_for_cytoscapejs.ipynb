{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run allã§ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹\n",
    "\n",
    "* URL: https://ftp.ebi.ac.uk/pub/databases/impc/all-data-releases/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSUMUGI_VERSION = \"0.3.2\"\n",
    "IMPC_RELEASE = 23.0\n",
    "\n",
    "columns = [\"marker_symbol\", \"marker_accession_id\", \"mp_term_name\", \"mp_term_id\", \"p_value\", \"effect_size\",\n",
    "           \"female_ko_effect_p_value\", \"male_ko_effect_p_value\", \"female_ko_parameter_estimate\",\"sex_effect_p_value\", \"male_ko_parameter_estimate\", # sex differences\n",
    "           \"genotype_effect_p_value\", \"genotype_effect_parameter_estimate\",\n",
    "           \"zygosity\", # zygosity\n",
    "           \"pipeline_name\", \"procedure_name\", # life-stage\n",
    "           \"allele_symbol\", # map to Phendigm\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = print\n",
    "from pprint import pprint as PP\n",
    "from collections import Counter as C\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import shutil\n",
    "import pickle\n",
    "import json\n",
    "import gzip\n",
    "import networkx as nx\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up to top directory\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "while not Path(\"LICENSE\").exists():\n",
    "    os.chdir('../')\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download IMPC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenodigm dataãŒå­˜åœ¨ã—ã¦ã„ãªã„å ´åˆã«ã¯ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ä¿ƒã™\n",
    "\n",
    "if not Path(\"data\", \"phenodigm\", \"impc_phenodigm.csv\").exists():\n",
    "    raise FileNotFoundError(\"Please download impc phenodigm data from https://diseasemodels.research.its.qmul.ac.uk/.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‘ã‚¹ã®è¨­å®š\n",
    "data_dir = Path(\"data/impc\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_path = data_dir / f\"statistical-results-ALL-{IMPC_RELEASE}.csv\"\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£å‡\n",
    "if not csv_path.exists():\n",
    "    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ URL\n",
    "    url = f\"https://ftp.ebi.ac.uk/pub/databases/impc/all-data-releases/release-{IMPC_RELEASE}/results/statistical-results-ALL.csv.gz\"\n",
    "\n",
    "    print(f\"Downloading and extracting: {url}\")\n",
    "\n",
    "    # URL ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—ï¼ˆtqdmã®ãŸã‚ï¼‰\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        total_size = int(response.info().get(\"Content-Length\", -1))\n",
    "        with tqdm.wrapattr(response, \"read\", total=total_size, desc=\"Downloading\", unit=\"B\", unit_scale=True) as r:\n",
    "            with gzip.GzipFile(fileobj=r) as uncompressed:\n",
    "                with open(csv_path, 'wb') as out_file:\n",
    "                    shutil.copyfileobj(uncompressed, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# wc -l data/impc/statistical-results*.csv\n",
    "# Release 22.1: 3165335\n",
    "# Release 23.0: 2159931\n",
    "\n",
    "# 1 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter dataset by P value < 0.0001 (10^-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(\"data\", f\"statistical_filtered-{IMPC_RELEASE}.csv\").exists():\n",
    "    path_df_statistical_filtered = Path(\"data\", \"impc\", f\"statistical-results-ALL-{IMPC_RELEASE}.csv\")\n",
    "    df_statistical_all = pd.read_csv(path_df_statistical_filtered)\n",
    "    df_statistical_all = df_statistical_all[columns]\n",
    "    \n",
    "    # Filter by p_value < 0.0001\n",
    "    threshold = 0.0001\n",
    "    filter_pvalue = df_statistical_all[\"p_value\"] < threshold\n",
    "    filter_female_ko_pvalue = df_statistical_all[\"female_ko_effect_p_value\"] < threshold\n",
    "    filter_male_ko_pvalue = df_statistical_all[\"male_ko_effect_p_value\"] < threshold\n",
    "\n",
    "    df_statistical_filtered = df_statistical_all[filter_pvalue | filter_female_ko_pvalue | filter_male_ko_pvalue]\n",
    "\n",
    "    # Filter by mp_term_id and mp_term_name are not NaN\n",
    "    df_statistical_filtered = df_statistical_filtered.dropna(subset=[\"mp_term_id\"])\n",
    "    df_statistical_filtered = df_statistical_filtered.dropna(subset=[\"mp_term_name\"])\n",
    "\n",
    "    # Filter by effect_size is not NaN\n",
    "    df_statistical_filtered = df_statistical_filtered.dropna(subset=[\"effect_size\"])\n",
    "    df_statistical_filtered.to_csv(f\"data/statistical_filtered-{IMPC_RELEASE}.csv\", index=False) # 2 sec\n",
    "\n",
    "# 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistical_filtered = pd.read_csv(f\"data/statistical_filtered-{IMPC_RELEASE}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_statistical_filtered))\n",
    "# Release 22.0: 54059 rows\n",
    "# Release 22.1: 54059 rows\n",
    "# Release 23.0: 49299 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data by mp_term_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistical_filtered = pd.read_csv(f\"data/statistical_filtered-{IMPC_RELEASE}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/mp_term_nameã‚’ä½œæˆ\n",
    "\n",
    "output_path = Path(\"data\", \"mp_term_name\")\n",
    "if output_path.exists():\n",
    "    shutil.rmtree(output_path)\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åå‰ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã«ã™ã‚‹é–¢æ•°ã‚’å®šç¾©\n",
    "def clean_name(name):\n",
    "    return name.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "# mp_term_nameã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’å–å¾—\n",
    "unique_mp_term_names = df_statistical_filtered['mp_term_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªmp_term_nameã”ã¨ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦CSVã«ä¿å­˜: 5 sec\n",
    "for mp_term_name in unique_mp_term_names:\n",
    "    df_mp_term = df_statistical_filtered[df_statistical_filtered['mp_term_name'] == mp_term_name]\n",
    "    clean_mp_term_name = clean_name(mp_term_name)\n",
    "    df_mp_term.to_csv(f\"data/mp_term_name/{clean_mp_term_name}.csv\", index=False)\n",
    "# 5 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TSUMUGIã«å¿…è¦ãªã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’æ•´ç†ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistical_filtered = pd.read_csv(f\"data/statistical_filtered-{IMPC_RELEASE}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate life stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# life_stageã®åˆæœŸå‰²ã‚Šå½“ã¦\n",
    "def assign_life_stage(pipeline_name):\n",
    "    if pd.isna(pipeline_name):\n",
    "        return \"Early\"\n",
    "    if \"Interval\" in pipeline_name or \"interval\" in pipeline_name:\n",
    "        return \"Interval\"\n",
    "    elif \"Late\" in pipeline_name or \"late\" in pipeline_name:\n",
    "        return \"Late\"\n",
    "    else:\n",
    "        return \"Early\"\n",
    "\n",
    "df_statistical_filtered[\"life_stage\"] = df_statistical_filtered[\"pipeline_name\"].apply(assign_life_stage)\n",
    "\n",
    "# Embryo è¡¨ç¾å‹ã«è©²å½“ã™ã‚‹ procedure_name ã®ä¸€è¦§\n",
    "embryo_phenotyping = [\n",
    "    \"Gross Morphology Embryo E9.5\",\n",
    "    \"Viability E9.5 Secondary Screen\",\n",
    "    \"OPT E9.5\",\n",
    "    \"MicroCT E9.5\",\n",
    "    \"Gross Morphology Placenta E9.5\",\n",
    "    \"Gross Morphology Embryo E12.5\",\n",
    "    \"Embryo LacZ\",\n",
    "    \"Gross Morphology Placenta E12.5\",\n",
    "    \"Viability E12.5 Secondary Screen\",\n",
    "    \"Viability E14.5-E15.5 Secondary Screen\",\n",
    "    \"Gross Morphology Placenta E14.5-E15.5\",\n",
    "    \"MicroCT E14.5-E15.5\",\n",
    "    \"Gross Morphology Embryo E14.5-E15.5\",\n",
    "    \"Viability E18.5 Secondary Screen\",\n",
    "    \"MicroCT E18.5\",\n",
    "    \"Gross Morphology Embryo E18.5\",\n",
    "    \"Gross Morphology Placenta E18.5\"\n",
    "]\n",
    "\n",
    "# life_stageã‚’Embryoã«ä¸Šæ›¸ã\n",
    "df_statistical_filtered.loc[df_statistical_filtered[\"procedure_name\"].isin(embryo_phenotyping), \"life_stage\"] = \"Embryo\"\n",
    "df_annotated = df_statistical_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_annotated))\n",
    "print(df_annotated[\"life_stage\"].value_counts())\n",
    "# 54059\n",
    "# life_stage\n",
    "# Early       45724\n",
    "# Embryo       4253\n",
    "# Late         4024\n",
    "# Interval       58\n",
    "# Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate Sex differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0001\n",
    "\n",
    "# æ¡ä»¶ãƒªã‚¹ãƒˆ\n",
    "conditions = [\n",
    "    (df_annotated[\"sex_effect_p_value\"] < threshold) & (df_annotated[\"female_ko_effect_p_value\"] < threshold) & (df_annotated[\"male_ko_effect_p_value\"] > threshold),\n",
    "    (df_annotated[\"sex_effect_p_value\"] < threshold) & (df_annotated[\"male_ko_effect_p_value\"] < threshold) & (df_annotated[\"female_ko_effect_p_value\"] > threshold)\n",
    "]\n",
    "\n",
    "# æ¡ä»¶ã«å¯¾å¿œã™ã‚‹å€¤\n",
    "choices = [\"female\", \"male\"]\n",
    "\n",
    "# np.selectã§åˆ—ã‚’è¨­å®š\n",
    "df_annotated[\"sexdual_dimorphism\"] = np.select(conditions, choices, default=None)\n",
    "df_annotated = df_annotated.reset_index(drop=True)\n",
    "\n",
    "# çµæœã‚’ç¢ºèª\n",
    "print(IMPC_RELEASE)\n",
    "print(df_annotated[\"sexdual_dimorphism\"].value_counts())\n",
    "\n",
    "# RELEASE 22.1\n",
    "# male      4915\n",
    "# female    4146\n",
    "\n",
    "# RELEASE 23.0\n",
    "# male      5026\n",
    "# female    4344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¢ºèª\n",
    "df_annotated.dropna(subset=[\"sexdual_dimorphism\"])[[\"p_value\", \"sexdual_dimorphism\", \"effect_size\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### éºä¼å‹ã€æ€§å·®ã€ãƒ©ã‚¤ãƒ•ã‚¹ãƒ†ãƒ¼ã‚¸ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ±åˆã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_annotated[\"zygosity\"].value_counts())\n",
    "# RELEASE 22.1\n",
    "# zygosity\n",
    "# homozygote      41444\n",
    "# heterozygote    11921\n",
    "# hemizygote        694\n",
    "\n",
    "# RELEASE 23.0\n",
    "# homozygote      37820\n",
    "# heterozygote    10896\n",
    "# hemizygote        583\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³åˆ—ã‚’è¿½åŠ ï¼ˆinplaceï¼‰\n",
    "def make_annotation(row) -> list[str]:\n",
    "    # éºä¼å‹\n",
    "    if row['zygosity'] == 'homozygote':\n",
    "        annotate = \"Homo\"\n",
    "    elif row['zygosity'] == 'heterozygote':\n",
    "        annotate = \"Hetero\"\n",
    "    else:\n",
    "        annotate = \"Hemi\"\n",
    "\n",
    "    # æ€§åˆ¥\n",
    "    if row['sexdual_dimorphism'] == \"female\":\n",
    "        annotate += \", Female\"\n",
    "    elif row['sexdual_dimorphism'] == \"male\":\n",
    "        annotate += \", Male\"\n",
    "\n",
    "    # life stage\n",
    "    if row['life_stage'] in {\"Embryo\", \"Early\", \"Interval\", \"Late\"}:\n",
    "        annotate += f\", {row['life_stage']}\"\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    annotations.append(f\"{row['mp_term_name']} ({annotate})\")\n",
    "\n",
    "    return annotations\n",
    "\n",
    "df_annotated[\"annotation\"] = df_annotated.apply(make_annotation, axis=1)\n",
    "\n",
    "df_exploded = df_annotated.explode(\"annotation\").reset_index(drop=True)\n",
    "\n",
    "# marker_symbol ã”ã¨ã« annotation ã‚’ãƒªã‚¹ãƒˆåŒ–ï¼†ã‚½ãƒ¼ãƒˆ\n",
    "marker_annotation_map = (\n",
    "    df_exploded\n",
    "    .groupby(\"marker_symbol\")[\"annotation\"]\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¾‹ï¼šRhdã®æ³¨é‡ˆã‚’è¡¨ç¤º\n",
    "print(marker_annotation_map[\"Rhd\"])\n",
    "# ä¾‹ï¼šAmtã®æ³¨é‡ˆã‚’è¡¨ç¤º (Embryo)\n",
    "print(marker_annotation_map[\"Amt\"])\n",
    "# ä¾‹ï¼šSpag4ã®æ³¨é‡ˆã‚’è¡¨ç¤º (é‡è¤‡ãŒå‰Šé™¤ã•ã‚Œã¦ã„ã‚‹ã‹)\n",
    "print(marker_annotation_map[\"Spag4\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data/annotation\").mkdir(exist_ok=True, parents=True)\n",
    "file_path = \"data/annotation/symbol_mptermname.json\"\n",
    "marker_annotation_map.to_json(file_path, indent=4)\n",
    "\n",
    "# json.dump(marker_annotation_map, open(file_path, \"w\"), indent=4, sort_keys=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "grep -c \"Male\" data/annotation/symbol_mptermname.json | sed \"s|^|Male: |\"\n",
    "grep -c \"Female\" data/annotation/symbol_mptermname.json | sed \"s|^|Feale: |\"\n",
    "\n",
    "grep -c \"Homo\" data/annotation/symbol_mptermname.json | sed \"s|^|Homo: |\"\n",
    "grep -c \"Hetero\" data/annotation/symbol_mptermname.json | sed \"s|^|Hetero: |\"\n",
    "grep -c \"Hemi\" data/annotation/symbol_mptermname.json | sed \"s|^|Hemi: |\"\n",
    "\n",
    "grep -c \"Embryo\" data/annotation/symbol_mptermname.json | sed \"s|^|Embryo: |\"\n",
    "grep -c \"Early\" data/annotation/symbol_mptermname.json | sed \"s|^|Early: |\"\n",
    "grep -c \"Interval\" data/annotation/symbol_mptermname.json | sed \"s|^|Interval: |\"\n",
    "grep -c \"Late\" data/annotation/symbol_mptermname.json | sed \"s|^|Late: |\"\n",
    "\n",
    "# RELEASE 22.1\n",
    "# Male: 4915\n",
    "# Feale: 4146\n",
    "# Homo: 41444\n",
    "# Hetero: 11921\n",
    "# Hemi: 694\n",
    "# Embryo: 4253\n",
    "# Early: 45724\n",
    "# Interval: 58\n",
    "# Late: 4024\n",
    "\n",
    "# RELEASE 23.0\n",
    "# Male: 4480\n",
    "# Feale: 3557\n",
    "# Homo: 30977\n",
    "# Hetero: 9625\n",
    "# Hemi: 492\n",
    "# Embryo: 4207\n",
    "# Early: 34324\n",
    "# Interval: 54\n",
    "# Late: 2509"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Phenodigmã‚’ç”¨ã„ãŸãƒ’ãƒˆç–¾æ‚£æƒ…å ±ã‚’å–å¾—ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenodigm = pd.read_csv(Path(\"data\", \"phenodigm\", \"impc_phenodigm.csv\"))\n",
    "P(len(df_phenodigm))\n",
    "# 3405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„è¡Œã«ã¤ã„ã¦ç©ºç™½ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "space_counts = df_phenodigm['Mouse model description'].str.count(' ')\n",
    "\n",
    "# ç©ºç™½ã®æ•°ãŒ2ã§ãªã„è¡Œã‚’æŠ½å‡ºï¼ˆ== split ã—ã¦3ã¤ã«ãªã‚‰ãªã„è¡Œï¼‰\n",
    "invalid_rows = df_phenodigm[space_counts != 2]\n",
    "\n",
    "# çµæœè¡¨ç¤º\n",
    "print(f\"å…¨ä½“ã®ä»¶æ•°: {len(df_phenodigm)}\")\n",
    "print(f\"ç©ºç™½ãŒã¡ã‚‡ã†ã©2ã¤ã§ãªã„è¡Œæ•°: {len(invalid_rows)}\")\n",
    "print(invalid_rows.head())\n",
    "# -> ãŸã£ãŸ2ã¤ã—ã‹ãªãã€`Phex<not yet available>`ãªã®ã§ã€ã“ã®2ã¤ã¯ç„¡è¦–ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenodigm = df_phenodigm[space_counts == 2]\n",
    "P(len(df_phenodigm))\n",
    "# 3403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenodigm[['allele_symbol', 'zygosity', 'life_stage']] = df_phenodigm['Mouse model description'].str.split(' ', n=2, expand=True)\n",
    "df_phenodigm = df_phenodigm.drop(columns=['Mouse model description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(df_phenodigm.columns)\n",
    "P(df_phenodigm[\"allele_symbol\"].head(3))\n",
    "P(df_phenodigm[\"zygosity\"].head(3))\n",
    "P(df_phenodigm[\"life_stage\"].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phenodigmã®è¡¨è¨˜ã¨impcãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜ã‚’æƒãˆã‚‹\n",
    "\n",
    "df_phenodigm = df_phenodigm.replace({'zygosity': {'hom': 'homozygote', 'het': 'heterozygote','hem': 'hemizygote'}})\n",
    "df_phenodigm['life_stage'] = df_phenodigm['life_stage'].str.capitalize()\n",
    "print(df_phenodigm[\"zygosity\"].value_counts())\n",
    "print(df_phenodigm[\"life_stage\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_phenodigm = \\\n",
    "    df_annotated.set_index(['allele_symbol','life_stage','zygosity']) \\\n",
    "    .join(df_phenodigm.set_index(['allele_symbol','life_stage','zygosity']), how='left', rsuffix='_phenodigm') \\\n",
    "    .reset_index()\n",
    "print(len(df_annotated_phenodigm))\n",
    "# 63645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"marker_symbol\", \"Disorder name\", \"life_stage\", \"zygosity\"\n",
    "    ]\n",
    "df_annotated_phenodigm = df_annotated_phenodigm[columns_to_keep].dropna(subset=[\"Disorder name\"]).reset_index(drop=True)\n",
    "df_annotated_phenodigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³åˆ—ã‚’è¿½åŠ ï¼ˆinplaceï¼‰\n",
    "def make_annotation(row) -> list[str]:\n",
    "    # éºä¼å‹\n",
    "    if row['zygosity'] == 'homozygote':\n",
    "        annotate = \"Homo\"\n",
    "    elif row['zygosity'] == 'heterozygote':\n",
    "        annotate = \"Hetero\"\n",
    "    else:\n",
    "        annotate = \"Hemi\"\n",
    "\n",
    "    # life stage\n",
    "    if row['life_stage'] in {\"Embryo\", \"Early\", \"Interval\", \"Late\"}:\n",
    "        annotate += f\", {row['life_stage']}\"\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    annotations.append(f\"{row['Disorder name']} ({annotate})\")\n",
    "\n",
    "    return annotations\n",
    "\n",
    "df_annotated_phenodigm[\"annotation\"] = df_annotated_phenodigm.apply(make_annotation, axis=1)\n",
    "\n",
    "df_exploded = df_annotated_phenodigm.explode(\"annotation\").reset_index(drop=True)\n",
    "\n",
    "# marker_symbol ã”ã¨ã« annotation ã‚’ãƒªã‚¹ãƒˆåŒ–ï¼†ã‚½ãƒ¼ãƒˆ\n",
    "marker_annotation_map = (\n",
    "    df_exploded\n",
    "    .groupby(\"marker_symbol\")[\"annotation\"]\n",
    "    .apply(lambda x: sorted(set(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¾‹ï¼šPhenodigmã®æ³¨é‡ˆã‚’è¡¨ç¤º (Embryo)\n",
    "print(marker_annotation_map[\"Arhgap31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data/annotation\").mkdir(exist_ok=True, parents=True)\n",
    "file_path = \"data/annotation/symbol_disordername.json\"\n",
    "marker_annotation_map.to_json(file_path, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mp term nameã¨IMPCã®Phenotype URLã‚’ç´ä»˜ã‘ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_statistical_filtered[['mp_term_id', 'mp_term_name']].drop_duplicates()\n",
    "# df_select = data[['marker_symbol', 'marker_accession_id', 'mp_term_name', 'mp_term_id']].drop_duplicates()\n",
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_phenotype_url = dict()\n",
    "for index, row in df_select.iterrows():\n",
    "    mp_tern_id = row['mp_term_id']\n",
    "    impc_url = f\"https://www.mousephenotype.org/data/phenotypes/{mp_tern_id}\"\n",
    "    mp_term_name = row['mp_term_name']\n",
    "    dict_phenotype_url[mp_term_name] = impc_url\n",
    "\n",
    "print(dict_phenotype_url[\"small lymph nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/annotation/mptermname_phenotypeurl.tsv', 'w') as f:\n",
    "    for term, url in dict_phenotype_url.items():\n",
    "        f.write(f\"{term}\\t{url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "head -n 3 data/annotation/mptermname_phenotypeurl.tsv\n",
    "wc -l data/annotation/mptermname_phenotypeurl.tsv\n",
    "# Release 22.0: 664\n",
    "# Release 23.0: 659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### marker symbolã¨MGI accession idã‚’ç´ä»˜ã‘ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_statistical_filtered[['marker_symbol', 'marker_accession_id']].drop_duplicates()\n",
    "# df_select = data[['marker_symbol', 'marker_accession_id', 'mp_term_name', 'mp_term_id']].drop_duplicates()\n",
    "df_select\n",
    "# Release 22.1: 7746 rows\n",
    "# Release 23.0: 7934 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_symbol_id = dict()\n",
    "for index, row in df_select.iterrows():\n",
    "    dict_symbol_id[row['marker_symbol']] = row['marker_accession_id']\n",
    "print(dict_symbol_id[\"Ncam1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(dict_symbol_id, open(\"data/annotation/symbol_mgiid.json\", \"w\"), indent=4, sort_keys=True)\n",
    "Path(\"data/annotation/symbol_mgiid.tsv\").write_text(\"\\n\".join([f\"{k}\\t{v}\" for k, v in dict_symbol_id.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 3 data/annotation/symbol_mgiid.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è¡¨ç¾å‹ã®é¡ä¼¼åº¦ã‚’æ±‚ã‚ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"data\", \"annotation\", \"symbol_mptermname.json\")\n",
    "\n",
    "symbol_mptermname = json.load(open(file_path))\n",
    "print(symbol_mptermname[\"Dpf2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç©ºãƒªã‚¹ãƒˆã‚’æŒã¤è¦ç´ ã‚’é™¤å¤–ã—ã¤ã¤ã€å€¤ã‚’ list â†’ set ã«å¤‰æ›ã—ã¦é‡è¤‡ã‚’å‰Šé™¤ã™ã‚‹\n",
    "symbol_mptermname = {k: set(v) for k, v in symbol_mptermname.items() if v}\n",
    "print(symbol_mptermname[\"Dpf2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccardä¿‚æ•°ã§é›†åˆã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gene_pair_mp_similarity = []\n",
    "\n",
    "for a, b in tqdm(combinations(symbol_mptermname, 2), desc=\"Calculating gene pair MP term similarity\"):\n",
    "    shared_mp = sorted(symbol_mptermname[a] & symbol_mptermname[b])\n",
    "    shared_mp_number = len(shared_mp)\n",
    "    union_mp_number = len(symbol_mptermname[a] | symbol_mptermname[b])\n",
    "    overlap_ratio = shared_mp_number / union_mp_number\n",
    "\n",
    "    gene_pair_mp_similarity.append([a, b, round(overlap_ratio, 3), shared_mp_number, shared_mp])\n",
    "\n",
    "## 3 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gene_pair_mp_similarity[:3])\n",
    "print(len(gene_pair_mp_similarity))\n",
    "# Release 22.0: 29996385\n",
    "# Release 22.1: 29996385\n",
    "# Release 23.0: 31470211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é‡è¤‡ã™ã‚‹è¡¨ç¾å‹ãŒé–¾å€¤ä»¥ä¸Šã®ã‚‚ã®ã‚’æŠ½å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 0.2\n",
    "num_shared_mp = 2\n",
    "\n",
    "gene_pair_mp_similarity_filtered = []\n",
    "for record in tqdm(gene_pair_mp_similarity, desc=\"Filtering gene pair MP term similarity\"):\n",
    "    if record[2] >= similarity_threshold and record[3] >= num_shared_mp:\n",
    "        gene_pair_mp_similarity_filtered.append(record)\n",
    "\n",
    "# 5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gene_pair_mp_similarity_filtered[:3])\n",
    "print(len(gene_pair_mp_similarity_filtered))\n",
    "# Release 21.1: 134880\n",
    "# Release 22.0: 133281 <- Homo/Hetero/HemiãŠã‚ˆã³â™‚ãƒ»â™€ã®å®Œå…¨ä¸€è‡´ã‚’è€ƒæ…®ã™ã‚‹ã‚ˆã†ã«ãªã£ãŸãŸã‚ã€æ¸›å°‘\n",
    "# Release 22.1: 133281\n",
    "# v0.3.0: 261,216 <- Similarity_threshodã®oræ¡ä»¶ã‚’ã¤ã‘ãŸãŸã‚ã€å¢—åŠ \n",
    "# Release 23.0 TSUMUGI v0.3.2: 205,460 (similarity >= 0.2 and num phenotype >= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data\", \"overlap\").mkdir(exist_ok=True, parents=True)\n",
    "pickle.dump(gene_pair_mp_similarity, open(\"data/overlap/gene_pair_mp_similarity.pkl\", \"wb\"))\n",
    "pickle.dump(gene_pair_mp_similarity_filtered, open(\"data/overlap/gene_pair_mp_similarity_filtered.pkl\", \"wb\"))\n",
    "\n",
    "# 1 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’CSVå½¢å¼ã§å‡ºåŠ› ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity = pd.DataFrame(gene_pair_mp_similarity)\n",
    "df_similarity.columns = [\"Gene1\", \"Gene2\", \"Jaccard Similarity\", \"Number of shared phenotype\", \"List of shared phenotypes\"]\n",
    "df_similarity.reindex(\n",
    "    columns=[\"Gene1\", \"Gene2\", \"Number of shared phenotype\", \"Jaccard Similarity\", \"List of shared phenotypes\"]\n",
    ")\n",
    "# df_similarity[\"List of shared phenotypes\"] = df_similarity[\"List of shared phenotypes\"].apply(json.dumps)\n",
    "# 30 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"data\", \"TSUMUGI_RawData\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "path_csv = output_dir / Path(f\"TSUMUGI_v{TSUMUGI_VERSION}_raw_data.csv.gz\")\n",
    "path_parquet = output_dir / Path(f\"TSUMUGI_v{TSUMUGI_VERSION}_raw_data.parquet\")\n",
    "\n",
    "def get_head1000_hash(df: pd.DataFrame) -> str:\n",
    "    # head(1000)ã ã‘ã‚’å¯¾è±¡ã«ãƒãƒƒã‚·ãƒ¥åŒ–\n",
    "    csv_bytes = df.head(1000).to_csv(index=False, lineterminator='\\n').encode('utf-8')\n",
    "    return hashlib.md5(csv_bytes).hexdigest()\n",
    "\n",
    "def file_head1000_hash(path: Path) -> str | None:\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        lines = [next(f) for _ in range(1001)]  # 1è¡Œç›®ãŒãƒ˜ãƒƒãƒ€ãƒ¼\n",
    "        csv_content = ''.join(lines).encode('utf-8')\n",
    "        return hashlib.md5(csv_content).hexdigest()\n",
    "\n",
    "# æ¯”è¼ƒ\n",
    "new_hash = get_head1000_hash(df_similarity)\n",
    "existing_hash = file_head1000_hash(path_csv)\n",
    "\n",
    "if new_hash != existing_hash:\n",
    "    df_similarity.to_csv(path_csv, index=False, compression=\"gzip\", lineterminator='\\n')\n",
    "    df_similarity.to_parquet(path_parquet, index=False)\n",
    "    print(\"ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ\")\n",
    "    # 3 min\n",
    "else:\n",
    "    print(\"âœ… å†…å®¹ã«å¤‰æ›´ãŒãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pandas = pd.read_parquet(path_parquet)\n",
    "# print(df_pandas)\n",
    "# # 15 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_polars = pl.read_parquet(path_parquet)\n",
    "# print(df_polars.head())\n",
    "# print(df_polars.shape)\n",
    "# # print(df_polars.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_overlap_filtered = pd.DataFrame(shared_ratios_filtered)\n",
    "# df_overlap_filtered.columns = [\"Gene1\", \"Gene2\", \"Jaccard Similarity\", \"Number of shared phenotype\", \"List of shared phenotypes\"]\n",
    "# df_overlap_filtered.reindex(\n",
    "#     columns=[\"Gene1\", \"Gene2\", \"Number of shared phenotype\", \"Jaccard Similarity\", \"List of shared phenotypes\"]\n",
    "# )\n",
    "# df_overlap_filtered[\"List of shared phenotypes\"] = df_overlap_filtered[\"List of shared phenotypes\"].apply(json.dumps)\n",
    "\n",
    "# df_overlap_filtered.to_csv(\"data/TSUMUGI_filtered_data.csv.gz\", index=False, compression=\"gzip\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¡¨ç¾å‹ã”ã¨ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å‡ºåŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_pair_mp_similarity_filtered = pickle.load(open(\"data/overlap/gene_pair_mp_similarity_filtered.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity = pd.DataFrame(\n",
    "    gene_pair_mp_similarity_filtered, columns=[\"marker1\", \"marker2\", \"phenotype_similarity\", \"shared_mp_number\", \"shared_mp\"]\n",
    ")\n",
    "print(len(df_similarity))\n",
    "# version 0.2.2: 133281  rows Ã— 5 columns\n",
    "# version 0.3.0: 261216  rows Ã— 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marker_phenotype = json.load(open(\"data/annotation/symbol_mptermname.json\"))\n",
    "df_marker_phenotype = pd.DataFrame(df_marker_phenotype.items(), columns=[\"marker_symbol\", \"mp_term_name\"])\n",
    "print(len(df_marker_phenotype))\n",
    "# TSUMUGI v0.2.2: 7626 rows\n",
    "# TSUMUGI v0.3.0: 7746 rows\n",
    "# TSUMUGI v0.3.1: 7746 rows\n",
    "# TSUMUGI v0.3.2: 7954 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_marker_phenotype = dict(zip(df_marker_phenotype.marker_symbol, df_marker_phenotype.mp_term_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_marker_disease = json.load(open(\"data/annotation/symbol_disordername.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"data/network/mp_term_name\")\n",
    "# remove network directory\n",
    "if output_dir.exists():\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_target_phenotypes = list(Path(\"data\", \"mp_term_name\").glob(\"*.csv\"))\n",
    "\n",
    "\"\"\"\n",
    "ãƒãƒ¼ãƒ‰ãŒå¤šã™ãã‚‹ã¨Webãƒšãƒ¼ã‚¸ãŒæç”»ã§ããªã„å•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚ã€\n",
    "ãƒãƒ¼ãƒ‰æ•°ã‚’é–¾å€¤ï¼ˆupper_limitï¼‰ä»¥ä¸‹ã«ã™ã‚‹ãŸã‚ã«æœ€é©ãªphenotype_similarityã‚’æ±‚ã‚ã‚‹\n",
    "\"\"\"\n",
    "number_of_nodes = 125\n",
    "tolerance = 25\n",
    "upper_limit = number_of_nodes + tolerance\n",
    "lower_limit = number_of_nodes - tolerance\n",
    "\n",
    "for path_target_phenotype in tqdm(path_target_phenotypes, desc=\"Processing MP terms\"):\n",
    "\n",
    "    columns = [\"marker_symbol\", \"effect_size\"]\n",
    "    df_marker_effect = pd.read_csv(path_target_phenotype, usecols=columns).dropna(subset=[\"effect_size\"])\n",
    "    df_marker_effect[\"effect_size\"] = df_marker_effect[\"effect_size\"].abs()\n",
    "    # * effect sizeã®çµ¶å¯¾å€¤ãŒæœ€å¤§ã®è¡Œã‚’å–å¾— (Homo/Heteroã§ç•°ãªã‚‹åŠ¹æœé‡ãŒã‚ã‚‹å ´åˆã«ã€ã²ã¨ã¾ãšæœ€å¤§å€¤ã‚’æ¡ç”¨ã™ã‚‹â† ä»Šå¾Œã®è€ƒæ…®äº‹é …)\n",
    "    idx = df_marker_effect.groupby(\"marker_symbol\")[\"effect_size\"].idxmax()\n",
    "    df_max = df_marker_effect.loc[idx]\n",
    "\n",
    "    dict_marker_effect = dict(zip(df_max[\"marker_symbol\"], df_max[\"effect_size\"]))\n",
    "\n",
    "    target_phenotype = path_target_phenotype.stem\n",
    "    target_phenotype_space = target_phenotype.replace(\"_\", \" \")\n",
    "    gene_symbols = df_marker_effect['marker_symbol']\n",
    "\n",
    "    # --- 1. phenotypeã‚’ç”Ÿã˜ã‚‹gene_symbolsã‚’å«ã‚€ã‚¨ãƒƒã‚¸ã®ã¿æŠ½å‡º ---------------------------\n",
    "    df_filtered = df_similarity[\n",
    "        df_similarity['marker1'].isin(gene_symbols) &\n",
    "        df_similarity['marker2'].isin(gene_symbols) &\n",
    "        df_similarity['shared_mp'].apply(lambda lst: any(target_phenotype_space in term for term in lst))\n",
    "    ]\n",
    "\n",
    "    # --- 2. åˆæœŸçŠ¶æ…‹ã®ãƒãƒ¼ãƒ‰ã®æ•°ã‚’ç¢ºèª -------------------------------\n",
    "    nodes = set(pd.concat([df_filtered[\"marker1\"], df_filtered[\"marker2\"]], ignore_index=True))\n",
    "    num_nodes = len(nodes)\n",
    "\n",
    "    if num_nodes > upper_limit:\n",
    "            # --- 3. é›¢æ•£ã‚¹ã‚³ã‚¢å€¤ã§æ¢ç´¢ ----------------------------------------\n",
    "            discrete_scores = (\n",
    "                df_filtered\n",
    "                .loc[:, \"phenotype_similarity\"]\n",
    "                .unique()\n",
    "            )\n",
    "            discrete_scores = np.sort(discrete_scores)[::-1]      # é™é †\n",
    "\n",
    "            best_thr  = None\n",
    "            best_diff = float(\"inf\")\n",
    "\n",
    "            lo, hi = 0, len(discrete_scores) - 1\n",
    "            while lo <= hi:\n",
    "                mid_idx = (lo + hi) // 2\n",
    "                thr = discrete_scores[mid_idx]\n",
    "\n",
    "                df_mid = df_filtered[df_filtered[\"phenotype_similarity\"] >= thr]\n",
    "                nodes = set(pd.concat([df_mid[\"marker1\"], df_mid[\"marker2\"]], ignore_index=True))\n",
    "                num_nodes = len(nodes)\n",
    "\n",
    "                # â–¼ ãƒãƒ¼ãƒ‰æ•°ãŒè¨±å®¹ç¯„å›²ãªã‚‰å€™è£œã«ã™ã‚‹\n",
    "                if num_nodes <= upper_limit:\n",
    "                    diff = abs(num_nodes - number_of_nodes)\n",
    "                    if diff < best_diff:\n",
    "                        best_diff = diff\n",
    "                        best_thr  = thr\n",
    "                    # ã•ã‚‰ã«ãƒãƒ¼ãƒ‰ã‚’æ¸›ã‚‰ã›ã‚‹ã‹ï¼Ÿ â†’ é–¾å€¤ã‚’ **ä¸Šã’ã‚‹**ï¼ˆã‚¹ã‚³ã‚¢ã‚’å¤§ããï¼‰\n",
    "                    lo = mid_idx + 1\n",
    "                else:\n",
    "                    # ãƒãƒ¼ãƒ‰ãŒå¤šã™ã â†’ é–¾å€¤ã‚’ **ä¸Šã’ã‚‹**ï¼ˆã‚¹ã‚³ã‚¢ã‚’å¤§ããï¼‰\n",
    "                    hi = mid_idx - 1\n",
    "\n",
    "            # ------------ æœ€çµ‚ã®é–¾å€¤ ---------------------------------------\n",
    "            if best_thr is None:\n",
    "                # Upper limitä»¥ä¸‹ãŒã©ã†ã—ã¦ã‚‚å­˜åœ¨ã—ãªã„ã‚±ãƒ¼ã‚¹ â†’ æœ€å°ãƒãƒ¼ãƒ‰ã«ãªã‚‹é–¾å€¤\n",
    "                best_thr = discrete_scores[hi + 1]  # hi ã¯æœ€å¾Œã« -1 ã•ã‚Œã¦ã„ã‚‹ã®ã§ +1\n",
    "\n",
    "            df_filtered = df_filtered[df_filtered[\"phenotype_similarity\"] >= best_thr]\n",
    "\n",
    "    # --- 4. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸã‚¨ãƒƒã‚¸ã‹ã‚‰ãƒãƒ¼ãƒ‰ã‚’å…¥æ‰‹ -------------------------------\n",
    "    nodes = set(pd.concat([df_filtered[\"marker1\"], df_filtered[\"marker2\"]], ignore_index=True))\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã®ãŸã‚ã®ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã‚’ä½œæˆ\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Nodeã‚’JSONå½¢å¼ã«å¤‰æ›\n",
    "    # ----------------------------------------------------\n",
    "    node_json = []\n",
    "    for node in nodes:\n",
    "        phenotype = dict_marker_phenotype.get(node, \"\")\n",
    "        disease = dict_marker_disease.get(node, \"\")\n",
    "        node_color = dict_marker_effect[node] if node in dict_marker_effect else 0.0\n",
    "        node_json.append({\n",
    "            \"data\": {\n",
    "                \"id\": node,\n",
    "                \"label\": node,\n",
    "                \"phenotype\": phenotype,\n",
    "                \"disease\": disease,\n",
    "                \"node_color\": node_color,\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # edgesã‚’ç”¨æ„\n",
    "    # ----------------------------------------------------\n",
    "    df_edge = df_filtered[[\"marker1\", \"marker2\", \"phenotype_similarity\", \"shared_mp\"]]\n",
    "    rows = df_edge.to_dict(orient=\"records\")\n",
    "    # Edgeã‚’JSONå½¢å¼ã«å¤‰æ›\n",
    "    edge_json = [\n",
    "        {\n",
    "            \"data\": {\n",
    "                \"source\":   r[\"marker1\"],\n",
    "                \"target\":   r[\"marker2\"],\n",
    "                \"phenotype\": r[\"shared_mp\"],\n",
    "                \"edge_size\": r[\"phenotype_similarity\"],\n",
    "            }\n",
    "        }\n",
    "        for r in rows\n",
    "    ]\n",
    "    # ----------------------------------------------------\n",
    "    # Edgeã¨Nodeã‚’çµ±åˆã—ã¦ã€å‡ºåŠ›\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    network_json = node_json + edge_json\n",
    "\n",
    "    # Output as JSON\n",
    "    if network_json:\n",
    "        output_json = output_dir / f\"{target_phenotype}.json.gz\"\n",
    "        with gzip.open(output_json, \"wt\", encoding=\"utf-8\") as f:\n",
    "            json.dump(network_json, f, indent=4)\n",
    "\n",
    "\n",
    "# 3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -lhS data/network/mp_term_name/ | head -n 5\n",
    "echo \"----------------------\"\n",
    "ls -lhS data/network/mp_term_name/ | tail -n 5\n",
    "\n",
    "# TSUMUGI v0.2.2: total 5.3M\n",
    "# TSUMUGI v0.3.0: total 5.5M\n",
    "# TSUMUGI v0.3.1: total 5.1M <- è©²å½“ã®è¡¨ç¾å‹ã‚’å«ã‚€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã¿ã‚’è¡¨ç¤º ï¼ˆIssue: #54ï¼‰\n",
    "# TSUMUGI v0.3.2: total 3.0M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒæœ€å¤§ã€æœ€å°ã®gene symbolã®nodeæ•°ã‚’ç¢ºèª\n",
    "zcat data/network/mp_term_name/edema.json.gz | grep -c \"node_color\"\n",
    "zcat data/network/mp_term_name/prenatal_lethality_prior_to_heart_atrial_septation.json.gz | grep -c \"node_color\"\n",
    "zcat data/network/mp_term_name/preweaning_lethality,_complete_penetrance.json.gz | grep -c \"node_color\"\n",
    "zcat data/network/mp_term_name/convulsive_seizures.json.gz | grep -c \"node_color\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## éºä¼å­ã”ã¨ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å‡ºåŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_symbols = df_similarity.marker1.unique().tolist()\n",
    "gene_symbols += df_similarity.marker2.unique().tolist()\n",
    "gene_symbols = list(set(gene_symbols))\n",
    "gene_symbols.sort()  # ä»¥ä¸‹ã®foræ–‡ã§ã€ã©ã“ã¾ã§éºä¼å­ãŒå‡¦ç†ã•ã‚ŒãŸã®ã‹é€”ä¸­çµŒéã‚’è¦‹ç©ã‚‚ã‚‹ãŸã‚ã®ã‚½ãƒ¼ãƒˆ\n",
    "P(gene_symbols[:3])\n",
    "P(len(gene_symbols))\n",
    "# version 0.2.2: 4139\n",
    "# version 0.3.0: 6812 (Life stageã‚’è€ƒæ…® + é¡ä¼¼åº¦ã‚’è¿½åŠ )\n",
    "# version 0.3.1: 6812\n",
    "# version 0.3.2: 5583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data/overlap/available_gene_symbols.txt\").write_text(\"\\n\".join(gene_symbols) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"data\", \"network\", \"gene_symbol\")\n",
    "# remove network directory\n",
    "if output_dir.exists():\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "# 10 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nodes = 125\n",
    "tolerance = 25  # tolerance for the number of nodes\n",
    "upper_limit = number_of_nodes + tolerance\n",
    "lower_limit = number_of_nodes - tolerance\n",
    "\n",
    "for gene_symbol in tqdm(gene_symbols, desc=\"Processing Gene Symbols\"):\n",
    "    \"\"\"\n",
    "    ãƒãƒ¼ãƒ‰ãŒå¤šã™ãã‚‹ã¨Webãƒšãƒ¼ã‚¸ãŒæç”»ã§ããªã„å•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚ã€\n",
    "    ãƒãƒ¼ãƒ‰æ•°ã‚’200ä»¥ä¸‹ã«ã™ã‚‹ãŸã‚ã«æœ€é©ãªphenotype_similarityã‚’æ±‚ã‚ã‚‹\n",
    "    \"\"\"\n",
    "    # --- 1. gene_symbol ã‚’å«ã‚€ã‚¨ãƒƒã‚¸ã®ã¿æŠ½å‡º ---------------------------\n",
    "    df_filtered = df_similarity[\n",
    "        (df_similarity[\"marker1\"] == gene_symbol) |\n",
    "        (df_similarity[\"marker2\"] == gene_symbol)\n",
    "    ]\n",
    "\n",
    "    # --- 2. åˆæœŸçŠ¶æ…‹ã®ãƒãƒ¼ãƒ‰ã®æ•°ã‚’ç¢ºèª -------------------------------\n",
    "    nodes = set(pd.concat([df_filtered[\"marker1\"], df_filtered[\"marker2\"]], ignore_index=True))\n",
    "    num_nodes = len(nodes)\n",
    "\n",
    "    if num_nodes > upper_limit:\n",
    "        # --- 3. é›¢æ•£ã‚¹ã‚³ã‚¢å€¤ã§æ¢ç´¢ ----------------------------------------\n",
    "        # gene_symbol ã¨çµã°ã‚ŒãŸã‚¨ãƒƒã‚¸ã®ã‚¹ã‚³ã‚¢ä¸€è¦§ï¼ˆé‡è¤‡ãªã—ï¼‰ã‚’é™é †ã§å–å¾—\n",
    "        discrete_scores = (\n",
    "            df_filtered\n",
    "            .loc[:, \"phenotype_similarity\"]\n",
    "            .unique()\n",
    "        )\n",
    "        discrete_scores = np.sort(discrete_scores)[::-1]      # é™é †\n",
    "\n",
    "        best_thr  = None\n",
    "        best_diff = float(\"inf\")\n",
    "\n",
    "        lo, hi = 0, len(discrete_scores) - 1\n",
    "        while lo <= hi:\n",
    "            mid_idx = (lo + hi) // 2\n",
    "            thr = discrete_scores[mid_idx]\n",
    "\n",
    "            df_mid = df_filtered[df_filtered[\"phenotype_similarity\"] >= thr]\n",
    "            # gene_symbol ã‚’å«ã‚€ã‚¨ãƒƒã‚¸ã®ã¿æŠ½å‡º\n",
    "            df_mid = df_mid[\n",
    "                (df_mid[\"marker1\"] == gene_symbol) |\n",
    "                (df_mid[\"marker2\"] == gene_symbol)\n",
    "            ]\n",
    "            nodes = set(pd.concat([df_mid[\"marker1\"], df_mid[\"marker2\"]], ignore_index=True))\n",
    "\n",
    "            if gene_symbol not in nodes:\n",
    "                # gene_symbol ãŒè½ã¡ãŸ â†’ é–¾å€¤ãŒé«˜ã™ãã‚‹ï¼ˆã‚¹ã‚³ã‚¢ã‚’ä¸‹ã’ã‚‹ï¼‰\n",
    "                lo = mid_idx + 1\n",
    "                continue\n",
    "\n",
    "            num_nodes = len(nodes)\n",
    "            # â–¼ ãƒãƒ¼ãƒ‰æ•°ãŒè¨±å®¹ç¯„å›²ãªã‚‰å€™è£œã«ã™ã‚‹\n",
    "            if num_nodes <= upper_limit:\n",
    "                diff = abs(num_nodes - number_of_nodes)\n",
    "                if diff < best_diff:\n",
    "                    best_diff = diff\n",
    "                    best_thr  = thr\n",
    "                # ã•ã‚‰ã«ãƒãƒ¼ãƒ‰ã‚’æ¸›ã‚‰ã›ã‚‹ã‹ï¼Ÿ â†’ é–¾å€¤ã‚’ **ä¸Šã’ã‚‹**ï¼ˆã‚¹ã‚³ã‚¢ã‚’å¤§ããï¼‰\n",
    "                lo = mid_idx + 1\n",
    "            else:\n",
    "                # ãƒãƒ¼ãƒ‰ãŒå¤šã™ã â†’ é–¾å€¤ã‚’ **ä¸Šã’ã‚‹**ï¼ˆã‚¹ã‚³ã‚¢ã‚’å¤§ããï¼‰\n",
    "                hi = mid_idx - 1\n",
    "\n",
    "        # ------------ æœ€çµ‚ã®é–¾å€¤ ---------------------------------------\n",
    "        if best_thr is None:\n",
    "            # Upper limit ä»¥ä¸‹ãŒã©ã†ã—ã¦ã‚‚å­˜åœ¨ã—ãªã„æ¥µç«¯ã‚±ãƒ¼ã‚¹ â†’ æœ€å°ãƒãƒ¼ãƒ‰ã«ãªã‚‹é–¾å€¤\n",
    "            best_thr = discrete_scores[hi + 1]  # hi ã¯æœ€å¾Œã« -1 ã•ã‚Œã¦ã„ã‚‹ã®ã§ +1\n",
    "\n",
    "        df_filtered = df_filtered[df_filtered[\"phenotype_similarity\"] >= best_thr]\n",
    "        # gene_symbol ã‚’å«ã‚€ã‚¨ãƒƒã‚¸ã®ã¿æŠ½å‡º\n",
    "        df_filtered = df_filtered[\n",
    "            (df_filtered[\"marker1\"] == gene_symbol) |\n",
    "            (df_filtered[\"marker2\"] == gene_symbol)\n",
    "        ]\n",
    "\n",
    "    nodes = set(pd.concat([df_filtered[\"marker1\"], df_filtered[\"marker2\"]], ignore_index=True))\n",
    "\n",
    "    # ------------\n",
    "    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã®ãŸã‚ã®ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã‚’ä½œæˆ\n",
    "    # ------------\n",
    "\n",
    "    # nodesã‚’ç”¨æ„\n",
    "    node_json = []\n",
    "    for node in nodes:\n",
    "        phenotype = dict_marker_phenotype[node]\n",
    "        disease = dict_marker_disease.get(node, \"\")\n",
    "        # ãƒãƒ¼ãƒ‰ã®è‰²ã‚’æ±ºå®šï¼ˆgene_symbol ã®å ´åˆã¯ 1ã€ãã‚Œä»¥å¤–ã¯ 0ï¼‰\n",
    "        node_color = 1.0 if node == gene_symbol else 0.0\n",
    "\n",
    "        node_json.append({\n",
    "            \"data\": {\n",
    "                \"id\": node,\n",
    "                \"label\": node,\n",
    "                \"node_color\": node_color,\n",
    "                \"phenotype\": phenotype,\n",
    "                \"disease\": disease,\n",
    "                }\n",
    "            })\n",
    "\n",
    "    # edgesã‚’ç”¨æ„\n",
    "    rows = df_similarity[(df_similarity[\"marker1\"].isin(nodes)) & (df_similarity[\"marker2\"].isin(nodes))].to_dict(orient=\"records\")\n",
    "\n",
    "    # Edgeã‚’JSONå½¢å¼ã«å¤‰æ›\n",
    "    edge_json = [\n",
    "        {\n",
    "            \"data\": {\n",
    "                \"source\":   r[\"marker1\"],\n",
    "                \"target\":   r[\"marker2\"],\n",
    "                \"phenotype\": r[\"shared_mp\"],\n",
    "                \"edge_size\": r[\"phenotype_similarity\"],\n",
    "            }\n",
    "        }\n",
    "        for r in rows\n",
    "    ]\n",
    "\n",
    "    network_json = node_json + edge_json\n",
    "\n",
    "    # Output as JSON\n",
    "    if network_json:\n",
    "        output_json = output_dir / f\"{gene_symbol}.json.gz\"\n",
    "        with gzip.open(output_json, \"wt\", encoding=\"utf-8\") as f:\n",
    "            json.dump(network_json, f, indent=4)\n",
    "\n",
    "# 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available_mp_termsã‚’ä½œæˆ\n",
    "\n",
    "mp_terms = {}\n",
    "for path_mp_term in Path(\"data\", \"mp_term_name\").glob(\"*.csv\"):\n",
    "    mp_term = path_mp_term.stem\n",
    "    if not Path(\"data\", \"network\", \"mp_term_name\", f\"{mp_term}.json.gz\").exists():\n",
    "        continue\n",
    "    mp_term_name_space = mp_term.replace(\"_\", \" \")\n",
    "    mp_terms[mp_term_name_space] = mp_term\n",
    "\n",
    "json.dump(mp_terms, open(\"data/overlap/available_mp_terms.json\", \"w\"), indent=2)\n",
    "pd.DataFrame(mp_terms.keys()).to_csv(\"data/overlap/available_mp_terms.txt\", index=False, header=False, sep=\"\\t\")\n",
    "\n",
    "print(len(mp_terms))\n",
    "\n",
    "# TSUMUGI v0.3.2: 440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lhS data/network/gene_symbol/ | head -n 5\n",
    "echo \"----------------------\"\n",
    "ls -lhS data/network/gene_symbol/ | tail -n 5\n",
    "# 30 sec\n",
    "# version 0.3.0: total 170M\n",
    "# version 0.3.1: total 168M\n",
    "# version 0.3.2: total 50M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒæœ€å¤§ã€æœ€å°ã®gene symbolã®nodeæ•°ã‚’ç¢ºèª\n",
    "zcat data/network/gene_symbol/Dstn.json.gz | grep -c \"node_color\"\n",
    "zcat data/network/gene_symbol/Rab10.json.gz | grep -c \"node_color\"\n",
    "zcat data/network/gene_symbol/Plekha8.json.gz | grep -c \"node_color\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "uname -a # OS name\n",
    "date +\"%Y/%m/%d %H:%M:%S\" # Last update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tsumugi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
