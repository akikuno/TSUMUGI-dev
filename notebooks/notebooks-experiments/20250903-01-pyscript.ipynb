{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyscriptを動かす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# `LICENSE`が見える階層まで移動する\n",
    "target_dir = \"LICENSE\"\n",
    "path_current = Path.cwd()\n",
    "while path_current.stem:\n",
    "    if any(True for p in path_current.iterdir() if p.stem == target_dir):\n",
    "        break\n",
    "    path_current = path_current.parent\n",
    "    if not path_current.stem:\n",
    "        raise FileNotFoundError(f\"{target_dir} directory not found\")\n",
    "\n",
    "os.chdir(path_current)\n",
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(path_current))\n",
    "sys.path.append(str(Path.joinpath(path_current, \"src\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "P = print\n",
    "PP = pprint\n",
    "C = Counter\n",
    "\n",
    "from collections.abc import Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験\n",
    "\n",
    "- 実験内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import csv\n",
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "from directory_manager import make_directories\n",
    "from io_handler import download_file, load_csv_as_dicts, save_csv\n",
    "\n",
    "IMPC_RELEASE = 23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########################################################\n",
    "# Preparation\n",
    "###########################################################\n",
    "\n",
    "ROOT_DIR = Path(\"TSUMUGI\")\n",
    "sub_dirs: list[str] = [\".temp\"]\n",
    "\n",
    "make_directories(ROOT_DIR, sub_dirs)\n",
    "\n",
    "TEMPDIR = ROOT_DIR / Path(\".temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(TEMPDIR, \"impc_phenodigm.csv\").exists():\n",
    "    url_phenodigm = \"https://github.com/whri-phenogenomics/disease_models/raw/main/disease_models_app/data/phenodigm_matches_dr20.1.txt\"\n",
    "\n",
    "    error_message = \"Please manually download impc phenodigm data (impc_phenodigm.csv) from https://diseasemodels.research.its.qmul.ac.uk/.\"\n",
    "\n",
    "    phenodigm_tsv = download_file(url_phenodigm, error_message)\n",
    "    reader = csv.reader(io.StringIO(phenodigm_tsv), delimiter=\"\\t\")\n",
    "    phenodigm_csv = (row for row in reader)\n",
    "    save_csv(phenodigm_csv, Path(TEMPDIR, \"impc_phenodigm.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(TEMPDIR, f\"statistical_all_{IMPC_RELEASE}.csv\").exists():\n",
    "    url_impc = f\"https://ftp.ebi.ac.uk/pub/databases/impc/all-data-releases/release-{IMPC_RELEASE}/results/statistical-results-ALL.csv.gz\"\n",
    "\n",
    "    error_message = \"Please manually download impc statistical data (statistical_results_ALL.csv) from https://ftp.ebi.ac.uk/pub/databases/impc/all-data-releases/release-23.0/results/.\"\n",
    "\n",
    "    statistical_all = download_file(url_impc, error_message)\n",
    "    reader = csv.reader(io.StringIO(statistical_all), delimiter=\",\")\n",
    "    statistical_all_rows = (row for row in reader)\n",
    "    save_csv(statistical_all_rows, Path(TEMPDIR, f\"statistical_all_{IMPC_RELEASE}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Filter significant genes\n",
    "# significant genesはmp_term_nameが存在する列であることを利用\n",
    "# =========================================\n",
    "\n",
    "columns = [\n",
    "    \"marker_symbol\",\n",
    "    \"marker_accession_id\",\n",
    "    \"mp_term_name\",\n",
    "    \"mp_term_id\",\n",
    "    \"p_value\",\n",
    "    \"effect_size\",\n",
    "    \"female_ko_effect_p_value\",\n",
    "    \"male_ko_effect_p_value\",\n",
    "    \"female_ko_parameter_estimate\",\n",
    "    \"sex_effect_p_value\",\n",
    "    \"male_ko_parameter_estimate\",  # sex differences\n",
    "    \"genotype_effect_p_value\",\n",
    "    \"genotype_effect_parameter_estimate\",\n",
    "    \"zygosity\",  # zygosity\n",
    "    \"pipeline_name\",\n",
    "    \"procedure_name\",  # life-stage\n",
    "    \"allele_symbol\",  # map to Phendigm\n",
    "]\n",
    "\n",
    "records: Iterator[dict[str, str]] = load_csv_as_dicts(Path(TEMPDIR, f\"statistical_all_{IMPC_RELEASE}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_columns(records: Iterator[dict[str, str]], columns: list[str]) -> Iterator[dict[str, str]]:\n",
    "    for record in records:\n",
    "        yield {col: record.get(col, \"\") for col in columns}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_subset = subset_columns(records, columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_subset = list(records_subset)\n",
    "P(len(records_subset))\n",
    "\n",
    "# for record in records_subset:\n",
    "#     p_value = record.get(\"p_value\")\n",
    "#     if not p_value:\n",
    "#         print(record)\n",
    "#         print(p_value is None)\n",
    "#         print(p_value == \"\")\n",
    "#         print(f\"p_value is missing or empty in record: {p_value}\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embryo 表現型に該当する procedure_name の一覧\n",
    "embryo_phenotyping = [\n",
    "    \"Gross Morphology Embryo E9.5\",\n",
    "    \"Viability E9.5 Secondary Screen\",\n",
    "    \"OPT E9.5\",\n",
    "    \"MicroCT E9.5\",\n",
    "    \"Gross Morphology Placenta E9.5\",\n",
    "    \"Gross Morphology Embryo E12.5\",\n",
    "    \"Embryo LacZ\",\n",
    "    \"Gross Morphology Placenta E12.5\",\n",
    "    \"Viability E12.5 Secondary Screen\",\n",
    "    \"Viability E14.5-E15.5 Secondary Screen\",\n",
    "    \"Gross Morphology Placenta E14.5-E15.5\",\n",
    "    \"MicroCT E14.5-E15.5\",\n",
    "    \"Gross Morphology Embryo E14.5-E15.5\",\n",
    "    \"Viability E18.5 Secondary Screen\",\n",
    "    \"MicroCT E18.5\",\n",
    "    \"Gross Morphology Embryo E18.5\",\n",
    "    \"Gross Morphology Placenta E18.5\",\n",
    "]\n",
    "\n",
    "{record[\"pipeline_name\"] for record in records_subset if record[\"procedure_name\"] in embryo_phenotyping}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_significant_phenotypes(\n",
    "    records: Iterator[dict[str, str]], threshold: float = 10**(-4)\n",
    ") -> list[dict[str, str | float]]:\n",
    "    significants = []\n",
    "    for record in records:\n",
    "        # mp_term_nameが空文字なものはSkip\n",
    "        if not record.get(\"mp_term_name\"):\n",
    "            continue\n",
    "\n",
    "        p_value = record.get(\"p_value\")\n",
    "        female_ko_effect_p_value = record.get(\"female_ko_effect_p_value\")\n",
    "        male_ko_effect_p_value = record.get(\"male_ko_effect_p_value\")\n",
    "        effect_size = record.get(\"effect_size\")\n",
    "\n",
    "        # すべてfloatに変換. 空文字はInfに変換\n",
    "        p_value = float(p_value) if p_value else float(\"inf\")\n",
    "        female_ko_effect_p_value = float(female_ko_effect_p_value) if female_ko_effect_p_value else float(\"inf\")\n",
    "        male_ko_effect_p_value = float(male_ko_effect_p_value) if male_ko_effect_p_value else float(\"inf\")\n",
    "        effect_size = float(effect_size) if effect_size else float(\"inf\")\n",
    "\n",
    "        if p_value == float(\"inf\") and effect_size != float(\"inf\"):\n",
    "            significants.append(record)\n",
    "        elif p_value < threshold or female_ko_effect_p_value < threshold or male_ko_effect_p_value < threshold:\n",
    "            significants.append(record)\n",
    "\n",
    "    # --- 重複削除（順序を気にしないので一気にsetで処理） ---\n",
    "    unique_significants = [\n",
    "        dict(t) for t in {frozenset(r.items()) for r in significants}\n",
    "    ]\n",
    "\n",
    "    return unique_significants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significants = extract_significant_phenotypes(records_subset, threshold=10**(-4))\n",
    "P(len(significants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Iterator\n",
    "\n",
    "INF = float(\"inf\")\n",
    "\n",
    "\n",
    "def subset_columns(records: Iterator[dict[str, str]], columns: list[str]) -> Iterator[dict[str, str]]:\n",
    "    \"\"\"Yield dicts keeping only the requested columns; missing keys become empty strings.\"\"\"\n",
    "    for record in records:\n",
    "        yield {col: record.get(col, \"\") for col in columns}\n",
    "\n",
    "\n",
    "def _to_float_or_inf(x) -> float:\n",
    "    \"\"\"Convert a string to float; empty/None becomes +Inf.\"\"\"\n",
    "    return float(x) if x not in (None, \"\") else INF\n",
    "\n",
    "\n",
    "def _normalized_record(record: dict[str, str]) -> dict[str, float | str]:\n",
    "    \"\"\"Return a shallow-copied record with numeric fields coerced to float/Inf.\"\"\"\n",
    "    out = dict(record)  # avoid mutating the input iterator's backing data\n",
    "    out[\"p_value\"] = _to_float_or_inf(record.get(\"p_value\"))\n",
    "    out[\"female_ko_effect_p_value\"] = _to_float_or_inf(record.get(\"female_ko_effect_p_value\"))\n",
    "    out[\"male_ko_effect_p_value\"] = _to_float_or_inf(record.get(\"male_ko_effect_p_value\"))\n",
    "    out[\"effect_size\"] = _to_float_or_inf(record.get(\"effect_size\"))\n",
    "    return out\n",
    "\n",
    "\n",
    "def _is_significant(rec: dict[str, float | str], threshold: float) -> bool:\n",
    "    \"\"\"Significance rule:\n",
    "    - If p_value is Inf and effect_size is finite -> keep.\n",
    "    - OR any of the three p-values is below threshold -> keep.\"\"\"\n",
    "    if rec[\"p_value\"] == INF and rec[\"effect_size\"] != INF:\n",
    "        return True\n",
    "    return (\n",
    "        rec[\"p_value\"] < threshold\n",
    "        or rec[\"female_ko_effect_p_value\"] < threshold\n",
    "        or rec[\"male_ko_effect_p_value\"] < threshold\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_significant_phenotypes(\n",
    "    records: Iterator[dict[str, str]], threshold: float = 1e-4\n",
    ") -> list[dict[str, float | str]]:\n",
    "    \"\"\"Filter significant phenotype records and drop exact duplicates (key+value match).\"\"\"\n",
    "    significants: list[dict[str, float | str]] = []\n",
    "\n",
    "    for record in records:\n",
    "        # Skip when 'mp_term_name' is empty\n",
    "        if not record.get(\"mp_term_name\"):\n",
    "            continue\n",
    "\n",
    "        # Normalize numeric fields and evaluate significance\n",
    "        rec = _normalized_record(record)\n",
    "        if _is_significant(rec, threshold):\n",
    "            significants.append(rec)\n",
    "\n",
    "    # Deduplicate by full key-value equality; ordering does not matter\n",
    "    # Use a sorted tuple of items as a stable, hashable fingerprint.\n",
    "    seen: set[tuple[tuple[str, float | str], ...]] = set()\n",
    "    unique: list[dict[str, float | str]] = []\n",
    "    for rec in significants:\n",
    "        fingerprint = tuple(sorted(rec.items()))\n",
    "        if fingerprint not in seen:\n",
    "            seen.add(fingerprint)\n",
    "            unique.append(rec)\n",
    "\n",
    "    return unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significants = extract_significant_phenotypes(records_subset, threshold=10**(-4))\n",
    "P(len(significants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {record[\"marker_symbol\"] for record in significants}\n",
    "P(len(symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_term_names = {record[\"mp_term_name\"] for record in significants}\n",
    "P(len(mp_term_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exoc6 = [record for record in significants if record[\"marker_symbol\"] == \"Exoc6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{record[\"mp_term_name\"] for record in exoc6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [record for record in records_subset if record[\"marker_symbol\"] == \"Exoc6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10**(-4)\n",
    "\n",
    "significants = []\n",
    "for record in records:\n",
    "    # mp_term_nameが空文字なものはSkip\n",
    "    if not record.get(\"mp_term_name\"):\n",
    "        continue\n",
    "\n",
    "    p_value = record.get(\"p_value\")\n",
    "    female_ko_effect_p_value = record.get(\"female_ko_effect_p_value\")\n",
    "    male_ko_effect_p_value = record.get(\"male_ko_effect_p_value\")\n",
    "    effect_size = record.get(\"effect_size\")\n",
    "\n",
    "    # すべてfloatに変換. 空文字はInfに変換\n",
    "    p_value = float(p_value) if p_value else float(\"inf\")\n",
    "    female_ko_effect_p_value = float(female_ko_effect_p_value) if female_ko_effect_p_value else float(\"inf\")\n",
    "    male_ko_effect_p_value = float(male_ko_effect_p_value) if male_ko_effect_p_value else float(\"inf\")\n",
    "    effect_size = float(effect_size) if effect_size else float(\"inf\")\n",
    "\n",
    "    if p_value == float(\"inf\") and effect_size != float(\"inf\"):\n",
    "        significants.append(record)\n",
    "    elif p_value < threshold or female_ko_effect_p_value < threshold or male_ko_effect_p_value < threshold:\n",
    "        print(record[\"mp_term_name\"])\n",
    "        significants.append(record)\n",
    "\n",
    "    if record[\"mp_term_name\"] == \"hyperactivity\":\n",
    "        print(record)\n",
    "# --- 重複削除（順序を気にしないので一気にsetで処理） ---\n",
    "unique_significants = [\n",
    "    dict(t) for t in {frozenset(r.items()) for r in significants}\n",
    "]\n",
    "\n",
    "{record[\"mp_term_name\"] for record in unique_significants}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tsumugi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
