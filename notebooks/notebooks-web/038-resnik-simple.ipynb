{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnik Similarity Implementation\n",
    "\n",
    "This notebook implements Resnik similarity calculation for MP ontology terms using the mp.obo file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロジェクトルートに移動\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "while not Path(\"LICENSE\").exists():\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "print(f\"Project root: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_obo_file(file_path: str) -> dict[str, dict]:\n",
    "    \"\"\"Parse OBO file and extract term information.\"\"\"\n",
    "    terms = {}\n",
    "    current_term = None\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line == \"[Term]\":\n",
    "                current_term = {}\n",
    "                continue\n",
    "\n",
    "            if line.startswith(\"[\") and line.endswith(\"]\") and line != \"[Term]\":\n",
    "                current_term = None\n",
    "                continue\n",
    "\n",
    "            if current_term is None:\n",
    "                continue\n",
    "\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "\n",
    "                if key == \"id\":\n",
    "                    current_term[\"id\"] = value\n",
    "                elif key == \"name\":\n",
    "                    current_term[\"name\"] = value\n",
    "                elif key == \"is_a\":\n",
    "                    if \"is_a\" not in current_term:\n",
    "                        current_term[\"is_a\"] = []\n",
    "                    parent_id = value.split(\"!\")[0].strip()\n",
    "                    current_term[\"is_a\"].append(parent_id)\n",
    "                elif key == \"is_obsolete\":\n",
    "                    current_term[\"is_obsolete\"] = value.lower() == \"true\"\n",
    "\n",
    "            if line == \"\" and current_term and \"id\" in current_term:\n",
    "                if not current_term.get(\"is_obsolete\", False):\n",
    "                    terms[current_term[\"id\"]] = current_term\n",
    "                current_term = None\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parent_child_relations(\n",
    "    terms: dict[str, dict],\n",
    ") -> tuple[dict[str, list[str]], dict[str, list[str]]]:\n",
    "    \"\"\"Build parent-child relationships from terms.\"\"\"\n",
    "    parents = defaultdict(list)  # term_id -> [parent_ids]\n",
    "    children = defaultdict(list)  # term_id -> [child_ids]\n",
    "\n",
    "    for term_id, term_data in terms.items():\n",
    "        if \"is_a\" in term_data:\n",
    "            for parent_id in term_data[\"is_a\"]:\n",
    "                parents[term_id].append(parent_id)\n",
    "                children[parent_id].append(term_id)\n",
    "\n",
    "    return dict(parents), dict(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ancestors(term_id: str, parents: dict[str, list[str]]) -> set[str]:\n",
    "    \"\"\"Get all ancestor terms for a given term.\"\"\"\n",
    "    ancestors = set()\n",
    "    queue = [term_id]\n",
    "\n",
    "    while queue:\n",
    "        current = queue.pop(0)\n",
    "        if current in parents:\n",
    "            for parent in parents[current]:\n",
    "                if parent not in ancestors:\n",
    "                    ancestors.add(parent)\n",
    "                    queue.append(parent)\n",
    "\n",
    "    return ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_descendants(term_id: str, children: dict[str, list[str]]) -> set[str]:\n",
    "    \"\"\"Get all descendant terms for a given term.\"\"\"\n",
    "    descendants = set()\n",
    "    queue = [term_id]\n",
    "\n",
    "    while queue:\n",
    "        current = queue.pop(0)\n",
    "        if current in children:\n",
    "            for child in children[current]:\n",
    "                if child not in descendants:\n",
    "                    descendants.add(child)\n",
    "                    queue.append(child)\n",
    "\n",
    "    return descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_content(\n",
    "    term_id: str, children: dict[str, list[str]], total_terms: int\n",
    ") -> float:\n",
    "    \"\"\"Calculate information content for a term based on its descendants.\"\"\"\n",
    "    descendants = get_all_descendants(term_id, children)\n",
    "    # Include the term itself in the count\n",
    "    term_count = len(descendants) + 1\n",
    "    probability = term_count / total_terms\n",
    "    return -math.log(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_ancestors(\n",
    "    term1_id: str, term2_id: str, parents: dict[str, list[str]]\n",
    ") -> set[str]:\n",
    "    \"\"\"Find common ancestors of two terms.\"\"\"\n",
    "    ancestors1 = get_all_ancestors(term1_id, parents)\n",
    "    ancestors1.add(term1_id)  # Include the term itself\n",
    "\n",
    "    ancestors2 = get_all_ancestors(term2_id, parents)\n",
    "    ancestors2.add(term2_id)  # Include the term itself\n",
    "\n",
    "    return ancestors1.intersection(ancestors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnik_similarity(\n",
    "    term1_id: str,\n",
    "    term2_id: str,\n",
    "    parents: dict[str, list[str]],\n",
    "    children: dict[str, list[str]],\n",
    "    total_terms: int,\n",
    ") -> float:\n",
    "    \"\"\"Calculate Resnik similarity between two terms.\"\"\"\n",
    "    if term1_id == term2_id:\n",
    "        return calculate_information_content(term1_id, children, total_terms)\n",
    "\n",
    "    common_ancestors = find_common_ancestors(term1_id, term2_id, parents)\n",
    "\n",
    "    if not common_ancestors:\n",
    "        return 0.0\n",
    "\n",
    "    # Find the most informative common ancestor (MICA)\n",
    "    max_ic = 0.0\n",
    "    for ancestor in common_ancestors:\n",
    "        ic = calculate_information_content(ancestor, children, total_terms)\n",
    "        max_ic = max(max_ic, ic)\n",
    "\n",
    "    return max_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_term_by_name(name: str, terms: dict[str, dict]) -> str | None:\n",
    "    \"\"\"Find term ID by name.\"\"\"\n",
    "    for term_id, term_data in terms.items():\n",
    "        if term_data.get(\"name\") == name:\n",
    "            return term_id\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the ontology\n",
    "obo_file = \"./data/ontology/mp.obo\"\n",
    "mp_terms = parse_obo_file(obo_file)\n",
    "print(f\"Loaded {len(mp_terms)} terms\")\n",
    "\n",
    "# Build relationships\n",
    "parents, children = build_parent_child_relations(mp_terms)\n",
    "total_terms = len(mp_terms)\n",
    "\n",
    "print(f\"Built relationships for {len(parents)} terms with parents\")\n",
    "print(f\"Built relationships for {len(children)} terms with children\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the target terms\n",
    "term1_name = \"preweaning lethality, complete penetrance\"\n",
    "term2_name = \"preweaning lethality\"\n",
    "\n",
    "term1_id = find_term_by_name(term1_name, mp_terms)\n",
    "term2_id = find_term_by_name(term2_name, mp_terms)\n",
    "\n",
    "print(f\"Term 1: {term1_name} -> {term1_id}\")\n",
    "print(f\"Term 2: {term2_name} -> {term2_id}\")\n",
    "\n",
    "if term1_id:\n",
    "    print(f\"Term 1 data: {mp_terms[term1_id]}\")\n",
    "if term2_id:\n",
    "    print(f\"Term 2 data: {mp_terms[term2_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Resnik similarity\n",
    "if term1_id and term2_id:\n",
    "    similarity = resnik_similarity(term1_id, term2_id, parents, children, total_terms)\n",
    "    print(\n",
    "        f\"\\nResnik similarity between '{term1_name}' and '{term2_name}': {similarity:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Also calculate individual information content\n",
    "    ic1 = calculate_information_content(term1_id, children, total_terms)\n",
    "    ic2 = calculate_information_content(term2_id, children, total_terms)\n",
    "\n",
    "    print(f\"Information content of '{term1_name}': {ic1:.4f}\")\n",
    "    print(f\"Information content of '{term2_name}': {ic2:.4f}\")\n",
    "\n",
    "    # Show common ancestors\n",
    "    common_ancestors = find_common_ancestors(term1_id, term2_id, parents)\n",
    "    print(f\"\\nCommon ancestors: {len(common_ancestors)}\")\n",
    "    for ancestor in sorted(common_ancestors):\n",
    "        ancestor_name = mp_terms[ancestor].get(\"name\", \"Unknown\")\n",
    "        ancestor_ic = calculate_information_content(ancestor, children, total_terms)\n",
    "        print(f\"  {ancestor}: {ancestor_name} (IC: {ancestor_ic:.4f})\")\n",
    "else:\n",
    "    print(\"Could not find one or both terms in the ontology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アノテーションによる重み付け\n",
    "\n",
    "実際の入力データは以下のように、基礎表現型のあとに、括弧書きで(genotype, sex, life-stage)の順番でアノテーションがあります。\n",
    "\n",
    "```python\n",
    "term1_name = \"preweaning lethality, complete penetrance (Homo, Male, Early)\"\n",
    "term2_name = \"preweaning lethality (Homo, Female, Early)\"\n",
    "```\n",
    "\n",
    "genotypeはHomo, Hetero, Hemi\n",
    "sexはFemale, Male\n",
    "life-stageはEmbryo, Early, Interval, Late\n",
    "のカテゴリがあります。\n",
    "\n",
    "このアノテーションの類似度も、Resnik類似度に加味したいです。\n",
    "具体的な戦略としては以下のように考えています\n",
    "1. アノテーションの3項目がすべて同じ → 何もしない（x1.0）\n",
    "2. アノテーションの3項目のうち、2つが同じ → x0.75\n",
    "3. アノテーションの3項目のうち、1つが同じ → x0.5\n",
    "4. アノテーションの3項目のうち、すべて異なる → x0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(term_name: str) -> tuple[str, tuple[str, str, str] | None]:\n",
    "    \"\"\"Parse annotation from term name.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (base_phenotype, (genotype, sex, life_stage)) or (base_phenotype, None)\n",
    "\n",
    "    Handles both 3-component and 2-component annotations:\n",
    "    - 3-component: (genotype, sex, life-stage)\n",
    "    - 2-component: (genotype, life-stage) -> sex becomes \"None\"\n",
    "    \"\"\"\n",
    "    # First try 3-component pattern: (genotype, sex, life-stage)\n",
    "    match = re.search(r\"(.+?)\\s*\\(([^,]+),\\s*([^,]+),\\s*([^)]+)\\)\", term_name)\n",
    "\n",
    "    if match:\n",
    "        base_phenotype = match.group(1).strip()\n",
    "        genotype = match.group(2).strip()\n",
    "        sex = match.group(3).strip()\n",
    "        life_stage = match.group(4).strip()\n",
    "        return base_phenotype, (genotype, sex, life_stage)\n",
    "\n",
    "    # Try 2-component pattern: (genotype, life-stage)\n",
    "    match = re.search(r\"(.+?)\\s*\\(([^,]+),\\s*([^)]+)\\)\", term_name)\n",
    "\n",
    "    if match:\n",
    "        base_phenotype = match.group(1).strip()\n",
    "        genotype = match.group(2).strip()\n",
    "        life_stage = match.group(3).strip()\n",
    "        # Set sex to \"None\" when missing\n",
    "        return base_phenotype, (genotype, \"None\", life_stage)\n",
    "\n",
    "    # No annotation found\n",
    "    return term_name, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_annotation_weight(\n",
    "    annotation1: tuple[str, str, str] | None, annotation2: tuple[str, str, str] | None\n",
    ") -> float:\n",
    "    \"\"\"Calculate weight based on annotation similarity.\n",
    "\n",
    "    Args:\n",
    "        annotation1: (genotype, sex, life_stage) or None\n",
    "        annotation2: (genotype, sex, life_stage) or None\n",
    "\n",
    "    Returns:\n",
    "        float: Weight multiplier based on similarity\n",
    "    \"\"\"\n",
    "    # If either annotation is missing, use neutral weight\n",
    "    if annotation1 is None or annotation2 is None:\n",
    "        return 1.0\n",
    "\n",
    "    # Count matching annotation items\n",
    "    matches = sum(1 for a1, a2 in zip(annotation1, annotation2) if a1 == a2)\n",
    "\n",
    "    # Apply weight based on number of matches\n",
    "    if matches == 3:\n",
    "        return 1.0  # All same\n",
    "    elif matches == 2:\n",
    "        return 0.75  # 2 same\n",
    "    elif matches == 1:\n",
    "        return 0.5  # 1 same\n",
    "    else:\n",
    "        return 0.25  # All different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_resnik_similarity(\n",
    "    term1_name: str,\n",
    "    term2_name: str,\n",
    "    mp_terms: dict[str, dict],\n",
    "    parents: dict[str, list[str]],\n",
    "    children: dict[str, list[str]],\n",
    "    total_terms: int,\n",
    ") -> tuple[float, float, str, str, dict[str, str]]:\n",
    "    \"\"\"Calculate weighted Resnik similarity considering annotations.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (weighted_similarity, base_similarity, base_phenotype1, base_phenotype2, common_ancestors_info)\n",
    "    \"\"\"\n",
    "    # Parse annotations\n",
    "    base_phenotype1, annotation1 = parse_annotation(term1_name)\n",
    "    base_phenotype2, annotation2 = parse_annotation(term2_name)\n",
    "\n",
    "    # Find term IDs for base phenotypes\n",
    "    term1_id = find_term_by_name(base_phenotype1, mp_terms)\n",
    "    term2_id = find_term_by_name(base_phenotype2, mp_terms)\n",
    "\n",
    "    if not term1_id or not term2_id:\n",
    "        return 0.0, 0.0, base_phenotype1, base_phenotype2, {}\n",
    "\n",
    "    # Calculate base Resnik similarity and get common ancestors\n",
    "    if term1_id == term2_id:\n",
    "        base_similarity = calculate_information_content(term1_id, children, total_terms)\n",
    "        # When terms are identical, the MICA is the term itself\n",
    "        common_ancestors_info = {\n",
    "            term1_id: mp_terms[term1_id].get(\"name\", \"Unknown\"),\n",
    "            \"mica_id\": term1_id,\n",
    "            \"mica_name\": mp_terms[term1_id].get(\"name\", \"Unknown\"),\n",
    "            \"mica_ic\": base_similarity\n",
    "        }\n",
    "    else:\n",
    "        # Find common ancestors\n",
    "        common_ancestors = find_common_ancestors(term1_id, term2_id, parents)\n",
    "        \n",
    "        if not common_ancestors:\n",
    "            return 0.0, 0.0, base_phenotype1, base_phenotype2, {}\n",
    "        \n",
    "        # Find the most informative common ancestor (MICA)\n",
    "        max_ic = 0.0\n",
    "        mica_id = None\n",
    "        mica_name = None\n",
    "        \n",
    "        # Collect all common ancestors with their names and IC\n",
    "        common_ancestors_info = {}\n",
    "        for ancestor in common_ancestors:\n",
    "            ic = calculate_information_content(ancestor, children, total_terms)\n",
    "            ancestor_name = mp_terms[ancestor].get(\"name\", \"Unknown\")\n",
    "            common_ancestors_info[ancestor] = ancestor_name\n",
    "            \n",
    "            if ic > max_ic:\n",
    "                max_ic = ic\n",
    "                mica_id = ancestor\n",
    "                mica_name = ancestor_name\n",
    "        \n",
    "        base_similarity = max_ic\n",
    "        \n",
    "        # Add MICA info to the dictionary\n",
    "        common_ancestors_info[\"mica_id\"] = mica_id\n",
    "        common_ancestors_info[\"mica_name\"] = mica_name\n",
    "        common_ancestors_info[\"mica_ic\"] = max_ic\n",
    "\n",
    "    # Calculate annotation weight\n",
    "    weight = calculate_annotation_weight(annotation1, annotation2)\n",
    "\n",
    "    # Apply weight to similarity\n",
    "    weighted_similarity = base_similarity * weight\n",
    "\n",
    "    return weighted_similarity, base_similarity, base_phenotype1, base_phenotype2, common_ancestors_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parsing with missing sex annotation\n",
    "print(\"Testing 2-component annotation parsing:\")\n",
    "\n",
    "test_2_component = \"preweaning lethality (Homo, Early)\"\n",
    "base, annotation = parse_annotation(test_2_component)\n",
    "\n",
    "print(f\"Term: '{test_2_component}'\")\n",
    "print(f\"Base phenotype: '{base}'\")\n",
    "print(f\"Annotation: {annotation}\")\n",
    "\n",
    "# Test with another 2-component example\n",
    "test_cases_2comp = [\n",
    "    \"preweaning lethality (Homo, Early)\",\n",
    "    \"preweaning lethality (Hetero, Late)\",\n",
    "    \"preweaning lethality, complete penetrance (Hemi, Interval)\",\n",
    "]\n",
    "\n",
    "print(\"\\nTesting various 2-component cases:\")\n",
    "for term in test_cases_2comp:\n",
    "    base, ann = parse_annotation(term)\n",
    "    print(f\"  '{term}' -> Base: '{base}', Annotation: {ann}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different annotation similarity cases\n",
    "test_cases = [\n",
    "    # All same (should get 1.25x)\n",
    "    (\n",
    "        \"preweaning lethality (Homo, Male, Early)\",\n",
    "        \"preweaning lethality, complete penetrance (Homo, Male, Early)\",\n",
    "    ),\n",
    "    # 2 same (should get 1.0x)\n",
    "    (\n",
    "        \"preweaning lethality (Homo, Male, Early)\",\n",
    "        \"preweaning lethality, complete penetrance (Homo, Female, Early)\",\n",
    "    ),\n",
    "    # 1 same (should get 0.75x)\n",
    "    (\n",
    "        \"preweaning lethality (Homo, Male, Early)\",\n",
    "        \"preweaning lethality, complete penetrance (Hetero, Female, Early)\",\n",
    "    ),\n",
    "    # All different (should get 0.5x)\n",
    "    (\n",
    "        \"preweaning lethality (Homo, Male, Early)\",\n",
    "        \"preweaning lethality, complete penetrance (Hetero, Female, Late)\",\n",
    "    ),\n",
    "    # No sex annotation (should get 1.0x)\n",
    "    (\n",
    "        \"preweaning lethality (Homo, Early)\",\n",
    "        \"preweaning lethality, complete penetrance (Homo, Male, Early)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"Testing different annotation similarity cases:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (term1, term2) in enumerate(test_cases, 1):\n",
    "    weighted_sim, base_sim, base1, base2, ancestors_info = weighted_resnik_similarity(\n",
    "        term1, term2, mp_terms, parents, children, total_terms\n",
    "    )\n",
    "\n",
    "    _, ann1 = parse_annotation(term1)\n",
    "    _, ann2 = parse_annotation(term2)\n",
    "    weight = calculate_annotation_weight(ann1, ann2)\n",
    "\n",
    "    matches = \"N/A\"\n",
    "    if ann1 and ann2:\n",
    "        matches = sum(1 for a1, a2 in zip(ann1, ann2) if a1 == a2)\n",
    "\n",
    "    print(f\"\\nCase {i}:\")\n",
    "    print(f\"  Term 1: {term1}\")\n",
    "    print(f\"  Term 2: {term2}\")\n",
    "    print(f\"  Annotation 1: {ann1}\")\n",
    "    print(f\"  Annotation 2: {ann2}\")\n",
    "    print(f\"  Matches: {matches}/3\")\n",
    "    print(f\"  Weight: {weight:.2f}x\")\n",
    "    print(f\"  Base similarity: {base_sim:.4f}\")\n",
    "    print(f\"  Weighted similarity: {weighted_sim:.4f}\")\n",
    "    \n",
    "    # Display MICA information\n",
    "    if ancestors_info:\n",
    "        print(f\"  Most Informative Common Ancestor (MICA):\")\n",
    "        print(f\"    ID: {ancestors_info.get('mica_id', 'N/A')}\")\n",
    "        print(f\"    Name: {ancestors_info.get('mica_name', 'N/A')}\")\n",
    "        print(f\"    IC: {ancestors_info.get('mica_ic', 0):.4f}\")\n",
    "        \n",
    "        # Display all common ancestors\n",
    "        print(f\"  All common ancestors ({len(ancestors_info) - 3}):\")\n",
    "        for ancestor_id, ancestor_name in sorted(ancestors_info.items()):\n",
    "            if not ancestor_id.startswith(\"mica_\"):\n",
    "                print(f\"    {ancestor_id}: {ancestor_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSUMUGIで解析可能なすべての表現型情報について、Resnik類似度のスコアを付与する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表現型\n",
    "import json\n",
    "\n",
    "file_path = Path(\"data\", \"annotation\", \"symbol_mptermname.json\")\n",
    "\n",
    "symbol_mptermname = json.load(open(file_path))\n",
    "print(symbol_mptermname[\"Dpf2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mpternames = set()\n",
    "for terms in symbol_mptermname.values():\n",
    "    for term in terms:\n",
    "        all_mpternames.add(term)\n",
    "print(f\"Total unique MP term names after deduplication: {len(all_mpternames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_mpternames)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1_name = 'abnormal QT variability (Hemi, Early)'\n",
    "term2_name = 'abnormal QT variability (Hetero, Early)'\n",
    "# term2_name = 'abnormal adrenal gland morphology (Hemi, Late)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sim, base_sim, base1, base2, ancestors_info = weighted_resnik_similarity(\n",
    "    term1_name,\n",
    "    term2_name,\n",
    "    mp_terms,\n",
    "    parents,\n",
    "    children,\n",
    "    total_terms,\n",
    ")\n",
    "print(f\"Weighted similarity: {weighted_sim:.4f}\")\n",
    "print(f\"Base similarity: {base_sim:.4f}\")\n",
    "print(f\"Base phenotype 1: {base1}\")\n",
    "print(f\"Base phenotype 2: {base2}\")\n",
    "\n",
    "# Display common ancestor information\n",
    "if ancestors_info:\n",
    "    print(f\"\\nMost Informative Common Ancestor (MICA):\")\n",
    "    print(f\"  ID: {ancestors_info.get('mica_id', 'N/A')}\")\n",
    "    print(f\"  Name: {ancestors_info.get('mica_name', 'N/A')}\")\n",
    "    print(f\"  IC: {ancestors_info.get('mica_ic', 0):.4f}\")\n",
    "    \n",
    "    print(f\"\\nAll common ancestors ({len(ancestors_info) - 3}):\")\n",
    "    for ancestor_id, ancestor_name in sorted(ancestors_info.items()):\n",
    "        if not ancestor_id.startswith(\"mica_\"):\n",
    "            print(f\"  {ancestor_id}: {ancestor_name}\")\n",
    "else:\n",
    "    print(\"\\nNo common ancestors found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "cache_similarities = {}\n",
    "for term1, term2 in tqdm(combinations(all_mpternames, 2), desc=\"Calculating similarities\", total=len(all_mpternames) * (len(all_mpternames) - 1) // 2):\n",
    "    weighted_sim, base_sim, base1, base2, ancestors_info = weighted_resnik_similarity(\n",
    "        term1,\n",
    "        term2,\n",
    "        mp_terms,\n",
    "        parents,\n",
    "        children,\n",
    "        total_terms,\n",
    "    )\n",
    "    cache_similarities[frozenset([term1, term2])] = {\n",
    "        \"weighted_similarity\": weighted_sim,\n",
    "        \"base_similarity\": base_sim,\n",
    "        \"base_phenotype1\": base1,\n",
    "        \"base_phenotype2\": base2,\n",
    "        \"common_ancestors_info\": ancestors_info,\n",
    "    }\n",
    "\n",
    "print(f\"Cached {len(cache_similarities)} term pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the cache to a file\n",
    "with open(\"data/overlap/resnik_similarity.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cache_similarities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1 = \"scoliosis (Homo, Early)\"\n",
    "term1 = \"increased grip strength (Homo, Early)\"\n",
    "term2 = \"increased grip strength (Hetero, Early)\"\n",
    "print(cache_similarities[frozenset([term1, term2])])\n",
    "print(cache_similarities[frozenset([term2, term1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tsumugi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
