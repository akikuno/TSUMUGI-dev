import math

import numpy as np
import pytest

from TSUMUGI.similarity_calculator import (
    apply_phenodigm_scaling,
    build_term_hierarchy,
    calculate_information_content,
    calculate_jaccard_indices,
    calculate_num_shared_phenotypes,
    calculate_resnik_similarity,
    find_all_ancestor_terms,
    find_all_descendant_terms,
    find_common_ancestors,
)


@pytest.fixture
def sample_ontology():
    """
    ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã™ã‚‹ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã€‚
    Hierarchy:
          A (root)
         / \\
        B   C
       / \\ /
      D   E
          |
          F
    """
    ontology_terms = {
        "A": {"id": "A", "name": "Root"},
        "B": {"id": "B", "name": "Term B", "is_a": ["A"]},
        "C": {"id": "C", "name": "Term C", "is_a": ["A"]},
        "D": {"id": "D", "name": "Term D", "is_a": ["B"]},
        "E": {"id": "E", "name": "Term E", "is_a": ["B", "C"]},
        "F": {"id": "F", "name": "Term F", "is_a": ["E"]},
    }
    parent_map, child_map = build_term_hierarchy(ontology_terms)
    return {
        "ontology_terms": ontology_terms,
        "parent_map": parent_map,
        "child_map": child_map,
        "total_term_count": len(ontology_terms),
    }


def test_build_term_hierarchy(sample_ontology):
    expected_parent_map = {
        "B": ["A"],
        "C": ["A"],
        "D": ["B"],
        "E": ["B", "C"],
        "F": ["E"],
    }
    expected_child_map = {
        "A": ["B", "C"],
        "B": ["D", "E"],
        "C": ["E"],
        "E": ["F"],
    }
    assert sample_ontology["parent_map"] == expected_parent_map
    assert sample_ontology["child_map"] == expected_child_map


@pytest.mark.parametrize(
    "term_id, expected_ancestors",
    [
        ("F", {"E", "B", "C", "A"}),
        ("D", {"B", "A"}),
        ("B", {"A"}),
        ("A", set()),
        ("Z", set()),  # å­˜åœ¨ã—ãªã„ID
    ],
)
def test_find_all_ancestor_terms(sample_ontology, term_id, expected_ancestors):
    result = find_all_ancestor_terms(term_id, sample_ontology["parent_map"])
    assert result == expected_ancestors


@pytest.mark.parametrize(
    "term1, term2, expected_common",
    [
        ("D", "F", {"D", "B", "A", "F", "E", "C"}),  # è‡ªåˆ†è‡ªèº«ã‚‚å«ã‚€
        ("D", "E", {"D", "B", "A", "E", "C"}),
        ("B", "C", {"B", "C", "A"}),
        ("F", "F", {"F", "E", "B", "C", "A"}),  # è‡ªåˆ†è‡ªèº«
        ("A", "F", {"A", "F", "E", "B", "C"}),
        ("D", "C", {"D", "B", "A", "C"}),
    ],
)
def test_find_common_ancestors(sample_ontology, term1, term2, expected_common):
    # é–¢æ•°ã®ä»•æ§˜ä¸Šã€è‡ªåˆ†è‡ªèº«ã‚‚ç¥–å…ˆé›†åˆã«å«ã¾ã‚Œã‚‹ãŸã‚ã€æœŸå¾…å€¤ã‚‚ãã‚Œã«åˆã‚ã›ã‚‹
    ancestors1 = find_all_ancestor_terms(term1, sample_ontology["parent_map"]) | {term1}
    ancestors2 = find_all_ancestor_terms(term2, sample_ontology["parent_map"]) | {term2}
    expected = ancestors1.intersection(ancestors2)

    result = find_common_ancestors(term1, term2, sample_ontology["parent_map"])
    assert result == expected


@pytest.mark.parametrize(
    "term_id, expected_descendants",
    [
        ("A", {"B", "C", "D", "E", "F"}),
        ("B", {"D", "E", "F"}),
        ("C", {"E", "F"}),
        ("F", set()),  # ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰
        ("Z", set()),  # å­˜åœ¨ã—ãªã„ID
    ],
)
def test_find_all_descendant_terms(sample_ontology, term_id, expected_descendants):
    result = find_all_descendant_terms(term_id, sample_ontology["child_map"])
    assert result == expected_descendants


@pytest.mark.parametrize(
    "term_id, num_descendants",
    [
        ("A", 5),  # B, C, D, E, F
        ("B", 3),  # D, E, F
        ("C", 2),  # E, F
        ("F", 0),  # Leaf node
    ],
)
def test_calculate_information_content(sample_ontology, term_id, num_descendants):
    total = sample_ontology["total_term_count"]
    # å­å­«ã®æ•° + è‡ªåˆ†è‡ªèº«(1)
    term_count = num_descendants + 1
    expected_ic = -math.log(term_count / total)

    result = calculate_information_content(term_id, sample_ontology["child_map"], total)
    assert result == pytest.approx(expected_ic)


@pytest.mark.parametrize(
    "term1, term2, mica_id",
    [
        ("D", "E", "B"),  # MICA is B
        ("D", "F", "B"),  # MICA is B
        ("B", "C", "A"),  # MICA is A
        ("F", "F", "F"),  # Same term
    ],
)
def test_calculate_resnik_similarity(sample_ontology, term1, term2, mica_id):
    # This dictionary is correct for the main function call below
    maps = {
        "parent_term_map": sample_ontology["parent_map"],
        "child_term_map": sample_ontology["child_map"],
        "total_term_count": sample_ontology["total_term_count"],
    }

    # FIX: Call calculate_information_content with only the specific arguments it needs,
    # instead of unpacking the entire 'maps' dictionary.
    expected_similarity = calculate_information_content(
        mica_id, sample_ontology["child_map"], sample_ontology["total_term_count"]
    )

    # This call was already correct as it uses all the arguments in 'maps'
    result = calculate_resnik_similarity(term1, term2, **maps)
    assert result == pytest.approx(expected_similarity)


def test_apply_phenodigm_scaling_identical_phenotypes():
    """
    Test Case 1: å®Œå…¨ã«ä¸€è‡´ã™ã‚‹è¡¨ç¾å‹ã‚»ãƒƒãƒˆã‚’æŒã¤å ´åˆã€ã‚¹ã‚³ã‚¢ãŒ100ã«ãªã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ ğŸ’¯
    """
    # --- ãƒ‡ãƒ¼ã‚¿æº–å‚™ ---
    gene1_mp_term_ids = {"MP:A", "MP:B"}
    gene2_mp_term_ids = {"MP:A", "MP:B"}

    term_pair_similarity_map = {
        frozenset(["MP:A"]): {"MP:A": 2.0},
        frozenset(["MP:B"]): {"MP:B": 4.0},
        frozenset(["MP:A", "MP:B"]): {"MP:A": 1.0},
    }

    weighted_similarity_matrix = np.array([[2.0, 1.0], [1.0, 4.0]])

    # --- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ ---
    result = apply_phenodigm_scaling(
        weighted_similarity_matrix, gene1_mp_term_ids, gene2_mp_term_ids, term_pair_similarity_map
    )

    # --- æ¤œè¨¼ ---
    # ã‚¹ã‚³ã‚¢ãŒ100ã«ãªã‚‹ã¯ãš
    assert result == 100


def test_apply_phenodigm_scaling_disjoint_phenotypes():
    """
    Test Case 2: å®Œå…¨ã«ç„¡é–¢ä¿‚ãªè¡¨ç¾å‹ã‚»ãƒƒãƒˆã‚’æŒã¤å ´åˆã€ã‚¹ã‚³ã‚¢ãŒ0ã«ãªã‚‹ã“ã¨ã‚’ãƒ†ã‚¹ãƒˆ ğŸ…¾ï¸
    """
    # --- ãƒ‡ãƒ¼ã‚¿æº–å‚™ ---
    gene1_mp_term_ids = {"MP:A", "MP:B"}
    gene2_mp_term_ids = {"MP:C", "MP:D"}

    term_pair_similarity_map = {
        frozenset(["MP:A"]): {"MP:A": 2.0},
        frozenset(["MP:B"]): {"MP:B": 4.0},
        frozenset(["MP:C"]): {"MP:C": 3.0},
        frozenset(["MP:D"]): {"MP:D": 5.0},
    }

    weighted_similarity_matrix = np.array([[0.0, 0.0], [0.0, 0.0]])

    # --- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ ---
    result = apply_phenodigm_scaling(
        weighted_similarity_matrix, gene1_mp_term_ids, gene2_mp_term_ids, term_pair_similarity_map
    )

    # --- æ¤œè¨¼ ---
    # ã‚¹ã‚³ã‚¢ãŒ0ã«ãªã‚‹ã¯ãš
    assert result == 0


def test_apply_phenodigm_scaling_average_score_50():
    """
    Test Case 3: å®Ÿæ¸¬å€¤ãŒç†è«–å€¤ã®ã¡ã‚‡ã†ã©åŠåˆ†ã§ã€ã‚¹ã‚³ã‚¢ãŒ50ã«ãªã‚‹ã‚±ãƒ¼ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ ğŸŒ—
    """
    # --- ãƒ‡ãƒ¼ã‚¿æº–å‚™ ---
    gene1_mp_term_ids = {"MP:A"}
    gene2_mp_term_ids = {"MP:B"}

    term_pair_similarity_map = {
        frozenset(["MP:A"]): {"MP:A": 4.0},  # IC(A)
        frozenset(["MP:B"]): {"MP:B": 4.0},  # IC(B)
        # sim(A,B)ã¯ weighted_similarity_matrix ã§ç›´æ¥æŒ‡å®š
    }

    weighted_similarity_matrix = np.array([[2.0]])

    # --- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ ---
    result = apply_phenodigm_scaling(
        weighted_similarity_matrix, gene1_mp_term_ids, gene2_mp_term_ids, term_pair_similarity_map
    )

    # --- æ¤œè¨¼ ---
    # æ­£è¦åŒ–ã‚¹ã‚³ã‚¢ãŒãã‚Œãã‚Œ0.5ã«ãªã‚Šã€æœ€çµ‚ã‚¹ã‚³ã‚¢ã¯50ã«ãªã‚‹ã¯ãš
    # phenodigm_score = 100 * ( (2/4) + (2/4) ) / 2 = 50.0
    assert result == 50


# ----------------------------------------------------------------------------
# Test Data Setup
# ----------------------------------------------------------------------------

# Case 1: Basic scenario with partial overlap
records_basic = [
    {"marker_symbol": "GeneA", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"},  # P1 for GeneA
    {"marker_symbol": "GeneA", "mp_term_id": "MP:2", "zygosity": "het", "life_stage": "A"},  # P2 for GeneA
    {"marker_symbol": "GeneB", "mp_term_id": "MP:2", "zygosity": "het", "life_stage": "A"},  # P2 for GeneB
    {"marker_symbol": "GeneB", "mp_term_id": "MP:3", "zygosity": "hom", "life_stage": "A"},  # P3 for GeneB
    {"marker_symbol": "GeneC", "mp_term_id": "MP:3", "zygosity": "hom", "life_stage": "A"},  # P3 for GeneC
]
expected_num_shared_basic = {
    frozenset(["GeneA", "GeneB"]): 1,
    frozenset(["GeneA", "GeneC"]): 0,
    frozenset(["GeneB", "GeneC"]): 1,
}
expected_jaccard_basic = {
    frozenset(["GeneA", "GeneB"]): 33,  # 1/3
    frozenset(["GeneA", "GeneC"]): 0,  # 0/3
    frozenset(["GeneB", "GeneC"]): 50,  # 1/2
}

# Case 2: Genes with no overlapping phenotypes
records_no_overlap = [
    {"marker_symbol": "GeneX", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"},
    {"marker_symbol": "GeneY", "mp_term_id": "MP:2", "zygosity": "het", "life_stage": "A"},
]
expected_num_shared_no_overlap = {frozenset(["GeneX", "GeneY"]): 0}
expected_jaccard_no_overlap = {frozenset(["GeneX", "GeneY"]): 0}

# Case 3: Genes with identical phenotype sets
records_full_overlap = [
    {"marker_symbol": "GeneX", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"},
    {"marker_symbol": "GeneX", "mp_term_id": "MP:2", "zygosity": "het", "life_stage": "A"},
    {"marker_symbol": "GeneY", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"},
    {"marker_symbol": "GeneY", "mp_term_id": "MP:2", "zygosity": "het", "life_stage": "A"},
]
expected_num_shared_full_overlap = {frozenset(["GeneX", "GeneY"]): 2}
expected_jaccard_full_overlap = {frozenset(["GeneX", "GeneY"]): 100}

# Case 4: One gene's phenotypes are a subset of another's
records_subset = [
    {"marker_symbol": "GeneX", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"},
    {"marker_symbol": "GeneY", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"},
    {"marker_symbol": "GeneY", "mp_term_id": "MP:2", "zygosity": "het", "life_stage": "A"},
]
expected_num_shared_subset = {frozenset(["GeneX", "GeneY"]): 1}
expected_jaccard_subset = {frozenset(["GeneX", "GeneY"]): 50}  # 1/2

# Case 5: Input with duplicate records, which should be ignored
records_duplicates = [
    {"marker_symbol": "GeneA", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"},
    {"marker_symbol": "GeneA", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"},  # Duplicate
    {"marker_symbol": "GeneB", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"},
]
expected_num_shared_duplicates = {frozenset(["GeneA", "GeneB"]): 1}
expected_jaccard_duplicates = {frozenset(["GeneA", "GeneB"]): 100}


@pytest.mark.parametrize(
    "records_significants, expected_output",
    [
        (records_basic, expected_num_shared_basic),
        (records_no_overlap, expected_num_shared_no_overlap),
        (records_full_overlap, expected_num_shared_full_overlap),
        (records_subset, expected_num_shared_subset),
        (records_duplicates, expected_num_shared_duplicates),
        ([], {}),  # Empty input
        ([{"marker_symbol": "GeneA", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"}], {}),  # Single gene
    ],
    ids=[
        "basic_case",
        "no_overlap",
        "full_overlap",
        "subset",
        "with_duplicates",
        "empty_input",
        "single_gene",
    ],
)
def test_calculate_num_shared_phenotypes(records_significants, expected_output):
    """
    Tests the calculation of the number of shared phenotypes for various scenarios.
    """
    result = calculate_num_shared_phenotypes(records_significants)
    assert result == expected_output


@pytest.mark.parametrize(
    "records_significants, expected_output",
    [
        (records_basic, expected_jaccard_basic),
        (records_no_overlap, expected_jaccard_no_overlap),
        (records_full_overlap, expected_jaccard_full_overlap),
        (records_subset, expected_jaccard_subset),
        (records_duplicates, expected_jaccard_duplicates),
        ([], {}),  # Empty input
        ([{"marker_symbol": "GeneA", "mp_term_id": "MP:1", "zygosity": "hom", "life_stage": "E"}], {}),  # Single gene
    ],
    ids=[
        "basic_case",
        "no_overlap",
        "full_overlap",
        "subset",
        "with_duplicates",
        "empty_input",
        "single_gene",
    ],
)
def test_calculate_jaccard_indices(records_significants, expected_output):
    """
    Tests the calculation of Jaccard indices for various scenarios.
    """
    result = calculate_jaccard_indices(records_significants)
    assert result == expected_output
